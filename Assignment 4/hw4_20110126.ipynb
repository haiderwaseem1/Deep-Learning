{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 437 - Deep Learning - Assignment 4\n",
    "\n",
    "*__Submission Instructions:__*\n",
    "- Rename this notebook to `hw4_rollnumber.ipynb` before submission on LMS.\n",
    "- Code for all the tasks must be written in this notebook (you do not need to submit any other files).\n",
    "- The output of all cells must be present in the version of the notebook you submit.\n",
    "- The university honor code should be maintained. Any violation, if found, will result in disciplinary action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import seaborn as sns\n",
    "from keras.models import load_model\n",
    "from keras.applications import vgg16\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Flatten, Dense, Dropout, Input, Conv1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "your_id = 20110126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this assignment you will be exploring a few important concepts used in the deep learning projects:\n",
    "- Working with satellite imagery data\n",
    "- Dataset annotation\n",
    "- Fine-tuning / Transfer Learning\n",
    "- Unsupervised feature representation with Autoencoder\n",
    "- Comparison of end-to-end trained model with finetuned model\n",
    "\n",
    "We will be using two datasets, the links are provided to you. You will also be working with three pretrained models, which have been provided to you. You are **highly** encouraged to explore the datasets and model architectures in order to get the most out of this assignment. \n",
    "\n",
    "**_Datasets:_**\n",
    "- Brick Kiln (Nepal) - available [here](https://drive.google.com/drive/folders/1dQEA0fxepVnELPnz-gAAYFb9hJSV4Azc)\n",
    "- UC Merced Land Use - available [here](http://weegee.vision.ucmerced.edu/datasets/landuse.html)\n",
    "\n",
    "**_Pretrained Models:_** \n",
    "Can be found [here](https://drive.google.com/open?id=1Ekvk3JUW3eI5sgITxzNklXrJXnCfTKBu)\n",
    "- ResNet18 pretrained on Brick Kiln (Lahore) - available as `InceptionResNet-v2-2classes`\n",
    "- Autoencoder pretrained on GT Cross View and fine tuned on UC Merced - available as `encoder_gt`\n",
    "- VGG16 pretrained on ImageNet - available in `keras.applications` (consult relevant documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_classes = 2\n",
    "input_shape = (224,224,3)\n",
    "nepal_mainDir = 'Data/Nepal_Brick_Kilns/'\n",
    "dir_no_kilns_nepal = 'Data/Nepal_Brick_Kilns/NoKilns/'\n",
    "dir_kilns_nepal = 'Data/Nepal_Brick_Kilns/Kilns/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Let's start with a binary classification problem. \n",
    "\n",
    "The Brick Kiln (Nepal) dataset you have been given consists of 100 tiles at zoom level 17. A script to break up these tiles into 64 sub-tiles of zoom 20 has also been given to you. Your job is to:\n",
    "- Split 100 images into 6400 images using the script\n",
    "- Manually annotate the dataset by moving the kiln pictures into one folder and non-kiln picutures into other folder.\n",
    "- Code up a generator to properly load the images and corresponding binary labels into a model. You have to resize images into 224X224X3\n",
    "\n",
    "*Scale images between 0 and 1 and apply mean subtraction in the generator*\n",
    "\n",
    "*Each of you has been given unique 100 tiles, so for the love of God do not get annotated data from someone else.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_folders = os.listdir(nepal_mainDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_folders = os.listdir(nepal_mainDir)\n",
    "labels_total = [] #each index contains paths to one class\n",
    "paths_to_images = []  #each index contains labels to one class\n",
    "\n",
    "for i in range(len(paths_to_folders)): #completing path\n",
    "    paths_to_folders[i] = nepal_mainDir + paths_to_folders[i]\n",
    "paths_to_folders = paths_to_folders[1:]\n",
    "\n",
    "for i in range(len(paths_to_folders)):\n",
    "    paths_to_images.append(os.listdir(paths_to_folders[i]))\n",
    "    \n",
    "for i in range(len(paths_to_images)):\n",
    "    l = []\n",
    "    for j in range(len(paths_to_images[i])):\n",
    "        paths_to_images[i][j] = paths_to_folders[i] + '/' + paths_to_images[i][j]\n",
    "        l.append(i)\n",
    "    labels_total.append(l)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train ,input_test, label_train, label_test = [],[],[],[]\n",
    "input_val, label_val = [],[]\n",
    "\n",
    "for i in range(len(paths_to_images)):\n",
    "    x_train ,x_test, y_train, y_test = train_test_split(paths_to_images[i], labels_total[i], test_size=0.2)\n",
    "    input_train.append(x_train)\n",
    "    input_test.append(x_test)\n",
    "    label_train.append(y_train)\n",
    "    label_test.append(y_test)\n",
    "\n",
    "x  = input_train\n",
    "y = label_train\n",
    "input_train, label_train = [],[]\n",
    "\n",
    "for i in range(len(x)):\n",
    "    x_train ,x_val, y_train, y_val = train_test_split(x[i], y[i], test_size=0.1)\n",
    "    input_train.append(x_train)\n",
    "    input_val.append(x_val)\n",
    "    label_train.append(y_train)\n",
    "    label_val.append(y_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_for_generator = []\n",
    "input_val_for_generator = []\n",
    "input_test_for_generator = []\n",
    "label_train_for_generator = []\n",
    "label_val_for_generator = []\n",
    "label_test_for_generator = []\n",
    "\n",
    "for i in range(len(input_val)):\n",
    "    for j in range(len(input_val[i])):\n",
    "        input_val_for_generator.append(input_val[i][j])\n",
    "        label_val_for_generator.append(label_val[i][j])\n",
    "        \n",
    "for i in range(len(input_test)):\n",
    "    for j in range(len(input_test[i])):\n",
    "        input_test_for_generator.append(input_test[i][j])\n",
    "        label_test_for_generator.append(label_test[i][j])\n",
    "        \n",
    "for i in range(len(input_train)):\n",
    "    for j in range(len(input_train[i])):\n",
    "        input_train_for_generator.append(input_train[i][j])\n",
    "        label_train_for_generator.append(label_train[i][j])\n",
    "\n",
    "#randomly shuffling data before sending into generator    \n",
    "c = list(zip(input_val_for_generator, label_val_for_generator))\n",
    "random.shuffle(c)\n",
    "input_val_for_generator, label_val_for_generator = zip(*c)\n",
    "\n",
    "\n",
    "c = list(zip(input_test_for_generator, label_test_for_generator))\n",
    "random.shuffle(c)\n",
    "input_test_for_generator, label_test_for_generator = zip(*c)\n",
    "\n",
    "c = list(zip(input_train_for_generator, label_train_for_generator))\n",
    "random.shuffle(c)\n",
    "input_train_for_generator, label_train_for_generator = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images for training:  5482\n",
      "Total Images for validation:  610\n",
      "Total Images for testing:  1524\n",
      "Total Images for testing:  7616\n"
     ]
    }
   ],
   "source": [
    "print (\"Total Images for training: \", len(label_train_for_generator))\n",
    "print (\"Total Images for validation: \", len(label_val_for_generator))\n",
    "print (\"Total Images for testing: \", len(label_test_for_generator))\n",
    "print (\"Total Images for testing: \", len(input_test_for_generator)+len(input_train_for_generator)+len(input_val_for_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brick_kiln_generator(path_images, y_labels, batch_size = 16, processing = False):\n",
    "    total_pictures = len(path_images)\n",
    "    #print (total_pictures)\n",
    "    indexes = np.arange(0,total_pictures,batch_size) #setting start index of each batch\n",
    "    \n",
    "    if total_pictures % batch_size != 0:\n",
    "        indexes = indexes[:-1]  #dropping last index if last batch does not complete the batch size requirement\n",
    "    #print (len(indexes))\n",
    "\n",
    "    while True:\n",
    "        np.random.shuffle(indexes) #shuffles indexes so order of data given to model in each loop is different\n",
    "        for index in indexes:\n",
    "            path = path_images[index : index + batch_size]\n",
    "            labels = y_labels[index : index + batch_size]\n",
    "            labels_categorical = to_categorical(labels, num_classes=2)\n",
    "            \n",
    "            x_array = np.zeros((batch_size,256,256,3))\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                img = cv2.imread(path[i])\n",
    "                x_array[i] = cv2.resize(img,(256,256))\n",
    "            \n",
    "            if processing == True:\n",
    "                x_array = x_array/255.0\n",
    "                x_array = x_array - np.mean(x_array)\n",
    "\n",
    "            batch_x = x_array\n",
    "            batch_y = np.array(labels_categorical)\n",
    "            yield batch_x, batch_y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_task1 = brick_kiln_generator(input_train_for_generator, label_train_for_generator)\n",
    "val_generator_task1 = brick_kiln_generator(input_val_for_generator, label_val_for_generator)\n",
    "test_generator_task1 = brick_kiln_generator(input_test_for_generator, label_test_for_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('Best_models/' + model_name + '-{epoch:02d}-{val_loss:.2f}.h5', \n",
    "                             monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Now you will evaluate performance of a pretrained (on Brick Kiln Lahore dataset) ResNet18 model using the generator made in Task1. You will:\n",
    "- Obtain predictions for the entire dataset\n",
    "- Construct a binary confusion matrix and visualize it as a heatmap\n",
    "\n",
    "*You can use scikit-learn's `metrics.confusion_matrix` function. Consult the relevant documentation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using data sent by TA on mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_task2_test = 'task2_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_paths = os.listdir(dir_task2_test)\n",
    "labels_test = [] #each index contains paths to one class\n",
    "image_paths = []  #each index contains labels to one class\n",
    "\n",
    "folders_paths = folders_paths[0:1] + folders_paths[2:] #removing .DS folder\n",
    "\n",
    "for i in range(len(folders_paths)): #completing path\n",
    "    folders_paths[i] = dir_task2_test + folders_paths[i]\n",
    "\n",
    "for i in range(len(folders_paths)):\n",
    "    image_paths.append(os.listdir(folders_paths[i]))\n",
    "    \n",
    "for i in range(len(image_paths)):\n",
    "    l = []\n",
    "    for j in range(len(image_paths[i])):\n",
    "        image_paths[i][j] = folders_paths[i] + '/' + image_paths[i][j]\n",
    "        l.append(i)\n",
    "    labels_test.append(l)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_task2_testing = []\n",
    "labels_task2_testing = []\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(image_paths)):\n",
    "    for j in range(len(image_paths[i])):\n",
    "        input_task2_testing.append(image_paths[i][j])\n",
    "        labels_task2_testing.append(counter)  \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_images = np.zeros((len(input_task2_testing),256,256,3))\n",
    "for i in range(len(input_task2_testing)):\n",
    "    testing_images[i] = cv2.imread(input_task2_testing[i])\n",
    "testing_labels = to_categorical(labels_task2_testing, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lahore_ResNet18 = load_model('Lahore_Model/InceptionResNet-v2-2classes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 127, 127, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 127, 127, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 127, 127, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 125, 125, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 125, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 125, 125, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 125, 125, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 125, 125, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 125, 125, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 62, 62, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 62, 62, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 62, 62, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 60, 60, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 60, 60, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 60, 60, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 29, 29, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 29, 29, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 29, 29, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 29, 29, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 29, 29, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 29, 29, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 29, 29, 96)   18432       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 29, 29, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 29, 29, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 29, 29, 64)   12288       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 29, 29, 96)   288         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 29, 29, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 29, 29, 96)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 29, 29, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 29, 29, 320)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 29, 29, 32)   96          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 29, 29, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 29, 29, 48)   13824       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 29, 29, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 29, 29, 48)   144         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 29, 29, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 29, 29, 48)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 29, 29, 32)   9216        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 29, 29, 64)   27648       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 29, 29, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 29, 29, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 29, 29, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 29, 29, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 29, 29, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 29, 29, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 29, 29, 32)   96          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 29, 29, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 29, 29, 48)   13824       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 29, 29, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 29, 29, 48)   144         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 29, 29, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 29, 29, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 29, 29, 32)   9216        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 29, 29, 64)   27648       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 29, 29, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 29, 29, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 29, 29, 64)   192         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 29, 29, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 29, 29, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 29, 29, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 29, 29, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 29, 29, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 29, 29, 32)   96          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 29, 29, 32)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 29, 29, 48)   13824       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 29, 29, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 29, 29, 48)   144         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 29, 29, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 29, 29, 48)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 29, 29, 32)   9216        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 29, 29, 64)   27648       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 29, 29, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 29, 29, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 29, 29, 64)   192         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 29, 29, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 29, 29, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 29, 29, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_25[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 29, 29, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 29, 29, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 29, 29, 32)   96          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 29, 29, 32)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 29, 29, 48)   13824       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 29, 29, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 29, 29, 48)   144         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 29, 29, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 29, 29, 48)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 29, 29, 32)   9216        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 29, 29, 64)   27648       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 29, 29, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 29, 29, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 29, 29, 64)   192         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 29, 29, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 29, 29, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 29, 29, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_31[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 29, 29, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 29, 29, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 29, 29, 32)   96          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 29, 29, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 29, 29, 48)   13824       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 29, 29, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 29, 29, 48)   144         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 29, 29, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 29, 29, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 29, 29, 32)   9216        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 29, 29, 64)   27648       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 29, 29, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 29, 29, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 29, 29, 64)   192         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 29, 29, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 29, 29, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 29, 29, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_37[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 29, 29, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 29, 29, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 29, 29, 32)   96          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 29, 29, 32)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 29, 29, 48)   13824       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 29, 29, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 29, 29, 48)   144         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 29, 29, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 29, 29, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 29, 29, 32)   9216        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 29, 29, 64)   27648       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 29, 29, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 29, 29, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 29, 29, 64)   192         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 29, 29, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 29, 29, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 29, 29, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_43[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 29, 29, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 29, 29, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 29, 29, 32)   96          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 29, 29, 32)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 29, 29, 48)   13824       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 29, 29, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 29, 29, 48)   144         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 29, 29, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 29, 29, 48)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 29, 29, 32)   9216        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 29, 29, 64)   27648       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 29, 29, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 29, 29, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 29, 29, 64)   192         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 29, 29, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 29, 29, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 29, 29, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_49[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 29, 29, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 29, 29, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 29, 29, 32)   96          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 29, 29, 32)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 29, 29, 48)   13824       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 29, 29, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 29, 29, 48)   144         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 29, 29, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 29, 29, 48)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 29, 29, 32)   9216        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 29, 29, 64)   27648       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 29, 29, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 29, 29, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 29, 29, 64)   192         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 29, 29, 32)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 29, 29, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 29, 29, 64)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_55[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 29, 29, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 29, 29, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 29, 29, 32)   96          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 29, 29, 32)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 29, 29, 48)   13824       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 29, 29, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 29, 29, 48)   144         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 29, 29, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 29, 29, 48)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 29, 29, 32)   9216        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 29, 29, 64)   27648       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 29, 29, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 29, 29, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 29, 29, 64)   192         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 29, 29, 32)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 29, 29, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 29, 29, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_61[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 29, 29, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 29, 29, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 29, 29, 32)   96          conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 29, 29, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 29, 29, 48)   13824       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 29, 29, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 29, 29, 48)   144         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 29, 29, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 29, 29, 48)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 29, 29, 32)   9216        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 29, 29, 64)   27648       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 29, 29, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 29, 29, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 29, 29, 64)   192         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 29, 29, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 29, 29, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 29, 29, 64)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 29, 29, 128)  0           activation_67[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 29, 29, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 29, 29, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 29, 29, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 29, 29, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 29, 29, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 29, 29, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 29, 29, 256)  589824      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 29, 29, 256)  768         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 29, 29, 256)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 14, 14, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 14, 14, 384)  884736      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 14, 14, 384)  1152        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 14, 14, 384)  1152        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 384)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 384)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 14, 14, 1088) 0           activation_73[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 14, 14, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 14, 14, 128)  384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 14, 14, 128)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 14, 14, 160)  143360      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 14, 14, 160)  480         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 14, 14, 160)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 14, 14, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 14, 14, 192)  215040      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 14, 14, 192)  576         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 14, 14, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 14, 14, 192)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 14, 14, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_77[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 14, 14, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 14, 14, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 14, 14, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 14, 14, 128)  384         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 14, 14, 128)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 14, 14, 160)  143360      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 14, 14, 160)  480         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 14, 14, 160)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 14, 14, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 14, 14, 192)  215040      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 14, 14, 192)  576         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 14, 14, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 14, 14, 192)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 14, 14, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_81[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 14, 14, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 14, 14, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 14, 14, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 14, 14, 128)  384         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 14, 14, 128)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 14, 14, 160)  143360      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 14, 14, 160)  480         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 14, 14, 160)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 14, 14, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 14, 14, 192)  215040      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 14, 14, 192)  576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 14, 14, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 14, 14, 192)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 14, 14, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_85[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 14, 14, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 14, 14, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 14, 14, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 14, 14, 128)  384         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 14, 14, 128)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 14, 14, 160)  143360      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 14, 14, 160)  480         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 14, 14, 160)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 14, 14, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 14, 14, 192)  215040      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 14, 14, 192)  576         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 14, 14, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 14, 14, 192)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 14, 14, 192)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_89[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 14, 14, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 14, 14, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 14, 14, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 14, 14, 128)  384         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 14, 14, 128)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 14, 14, 160)  143360      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 14, 14, 160)  480         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 14, 14, 160)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 14, 14, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 14, 14, 192)  215040      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 14, 14, 192)  576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 14, 14, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 14, 14, 192)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 14, 14, 192)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_93[0][0]              \n",
      "                                                                 activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 14, 14, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 14, 14, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 14, 14, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 14, 14, 128)  384         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 14, 14, 128)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 14, 14, 160)  143360      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 14, 14, 160)  480         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 14, 14, 160)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 14, 14, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 14, 14, 192)  215040      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 14, 14, 192)  576         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 14, 14, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 14, 14, 192)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 14, 14, 192)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_97[0][0]              \n",
      "                                                                 activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 14, 14, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 14, 14, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 14, 14, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 14, 14, 128)  384         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 14, 14, 128)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 14, 14, 160)  143360      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 14, 14, 160)  480         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 14, 14, 160)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 14, 14, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 14, 14, 192)  215040      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 14, 14, 192)  576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 14, 14, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 14, 14, 192)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 14, 14, 192)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 14, 14, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 14, 14, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 14, 14, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 14, 14, 128)  384         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 14, 14, 128)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 14, 14, 160)  143360      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 14, 14, 160)  480         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 14, 14, 160)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 14, 14, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 14, 14, 192)  215040      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 14, 14, 192)  576         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 14, 14, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 14, 14, 192)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 14, 14, 192)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_105[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 14, 14, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 14, 14, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 14, 14, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 14, 14, 128)  384         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 14, 14, 128)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 14, 14, 160)  143360      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 14, 14, 160)  480         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 14, 14, 160)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 14, 14, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 14, 14, 192)  215040      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 14, 14, 192)  576         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 14, 14, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 14, 14, 192)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 14, 14, 192)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 14, 14, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 14, 14, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 14, 14, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 14, 14, 128)  384         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 14, 14, 128)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 14, 14, 160)  143360      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 14, 14, 160)  480         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 14, 14, 160)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 14, 14, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 14, 14, 192)  215040      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 14, 14, 192)  576         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 14, 14, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 14, 14, 192)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 14, 14, 192)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_113[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 14, 14, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 14, 14, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 14, 14, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 14, 14, 128)  384         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 14, 14, 128)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 14, 14, 160)  143360      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 14, 14, 160)  480         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 14, 14, 160)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 14, 14, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 14, 14, 192)  215040      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 14, 14, 192)  576         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 14, 14, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 14, 14, 192)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 14, 14, 192)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_117[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 14, 14, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 14, 14, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 14, 14, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 14, 14, 128)  384         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 14, 14, 128)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 14, 14, 160)  143360      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 14, 14, 160)  480         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 14, 14, 160)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 14, 14, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 14, 14, 192)  215040      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 14, 14, 192)  576         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 14, 14, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 14, 14, 192)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 14, 14, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 14, 14, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 14, 14, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 14, 14, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 14, 14, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 14, 14, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 14, 14, 160)  143360      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 14, 14, 160)  480         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 14, 14, 160)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 14, 14, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 14, 14, 192)  215040      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 14, 14, 192)  576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 14, 14, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 14, 14, 192)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 14, 14, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 14, 14, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 14, 14, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 14, 14, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 14, 14, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 14, 14, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 14, 14, 160)  143360      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 14, 14, 160)  480         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 14, 14, 160)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 14, 14, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 14, 14, 192)  215040      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 14, 14, 192)  576         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 14, 14, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 14, 14, 192)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 14, 14, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_129[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 14, 14, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 14, 14, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 14, 14, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 14, 14, 128)  384         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 14, 14, 128)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 14, 14, 160)  143360      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 14, 14, 160)  480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 14, 14, 160)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 14, 14, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 14, 14, 192)  215040      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 14, 14, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 14, 14, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 14, 14, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 14, 14, 192)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_133[0][0]             \n",
      "                                                                 activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 14, 14, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 14, 14, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 14, 14, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 14, 14, 128)  384         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 14, 14, 128)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 14, 14, 160)  143360      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 14, 14, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 14, 14, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 14, 14, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 14, 14, 192)  215040      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 14, 14, 192)  576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 14, 14, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 14, 14, 192)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 14, 14, 192)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_137[0][0]             \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 14, 14, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 14, 14, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 14, 14, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 14, 14, 128)  384         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 14, 14, 128)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 14, 14, 160)  143360      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 14, 14, 160)  480         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 14, 14, 160)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 14, 14, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 14, 14, 192)  215040      activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 14, 14, 192)  576         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 14, 14, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 14, 14, 192)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 14, 14, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_141[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 14, 14, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 14, 14, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 14, 14, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 14, 14, 128)  384         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 14, 14, 128)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 14, 14, 160)  143360      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 14, 14, 160)  480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 14, 14, 160)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 14, 14, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 14, 14, 192)  215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 14, 14, 192)  576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 14, 14, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 14, 14, 192)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 14, 14, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 14, 14, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 14, 14, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 14, 14, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 14, 14, 128)  384         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 14, 14, 128)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 14, 14, 160)  143360      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 14, 14, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 14, 14, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 14, 14, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 14, 14, 192)  215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 14, 14, 192)  576         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 14, 14, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 14, 14, 192)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 14, 14, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_149[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 14, 14, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 14, 14, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 14, 14, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 14, 14, 128)  384         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 14, 14, 128)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 14, 14, 160)  143360      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 14, 14, 160)  480         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 14, 14, 160)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 14, 14, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 14, 14, 192)  215040      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 14, 14, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 14, 14, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 14, 14, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 14, 14, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_153[0][0]             \n",
      "                                                                 activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 14, 14, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 14, 14, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 14, 14, 256)  768         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 14, 14, 256)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 14, 14, 288)  663552      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 14, 14, 256)  768         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 14, 14, 256)  768         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 14, 14, 288)  864         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 14, 14, 256)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 14, 14, 256)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 14, 14, 288)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 6, 6, 384)    884736      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 6, 6, 288)    663552      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 6, 6, 320)    829440      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 6, 6, 384)    1152        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 6, 6, 288)    864         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 6, 6, 320)    960         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 6, 6, 384)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 6, 6, 288)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 6, 6, 320)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 6, 6, 2080)   0           activation_158[0][0]             \n",
      "                                                                 activation_160[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 6, 6, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 6, 6, 192)    576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 6, 6, 192)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 6, 6, 224)    129024      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 6, 6, 224)    672         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 6, 6, 224)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 6, 6, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 6, 6, 256)    172032      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 6, 6, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 6, 6, 256)    768         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 6, 6, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 6, 6, 256)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_164[0][0]             \n",
      "                                                                 activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 6, 6, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 6, 6, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 6, 6, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 6, 6, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 6, 6, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 6, 6, 224)    129024      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 6, 6, 224)    672         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 6, 6, 224)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 6, 6, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 6, 6, 256)    172032      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 6, 6, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 6, 6, 256)    768         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 6, 6, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 6, 6, 256)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_168[0][0]             \n",
      "                                                                 activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 6, 6, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 6, 6, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 6, 6, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 6, 6, 192)    576         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 6, 6, 192)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 6, 6, 224)    129024      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 6, 6, 224)    672         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 6, 6, 224)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 6, 6, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 6, 6, 256)    172032      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 6, 6, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 6, 6, 256)    768         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 6, 6, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 6, 6, 256)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_172[0][0]             \n",
      "                                                                 activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 6, 6, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 6, 6, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 6, 6, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_177 (BatchN (None, 6, 6, 192)    576         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 6, 6, 192)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 6, 6, 224)    129024      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 6, 6, 224)    672         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 6, 6, 224)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 6, 6, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 6, 6, 256)    172032      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 6, 6, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 6, 6, 256)    768         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 6, 6, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 6, 6, 256)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_176[0][0]             \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 6, 6, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 6, 6, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 6, 6, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 6, 6, 192)    576         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 6, 6, 192)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 6, 6, 224)    129024      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 6, 6, 224)    672         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 6, 6, 224)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 6, 6, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 6, 6, 256)    172032      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 6, 6, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 6, 6, 256)    768         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 6, 6, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 6, 6, 256)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_180[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 6, 6, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 6, 6, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 6, 6, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 6, 6, 192)    576         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 6, 6, 192)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 6, 6, 224)    129024      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 6, 6, 224)    672         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 6, 6, 224)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 6, 6, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 6, 6, 256)    172032      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 6, 6, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 6, 6, 256)    768         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 6, 6, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 6, 6, 256)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_184[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 6, 6, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 6, 6, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 6, 6, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 6, 6, 192)    576         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 6, 6, 192)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 6, 6, 224)    129024      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 6, 6, 224)    672         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 6, 6, 224)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 6, 6, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 6, 6, 256)    172032      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 6, 6, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 6, 6, 256)    768         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 6, 6, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 6, 6, 256)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_188[0][0]             \n",
      "                                                                 activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 6, 6, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 6, 6, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 6, 6, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 6, 6, 192)    576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 6, 6, 192)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 6, 6, 224)    129024      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 6, 6, 224)    672         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 6, 6, 224)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 6, 6, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 6, 6, 256)    172032      activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 6, 6, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 6, 6, 256)    768         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 6, 6, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 6, 6, 256)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_192[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 6, 6, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 6, 6, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 6, 6, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 6, 6, 192)    576         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 6, 6, 192)    0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 6, 6, 224)    129024      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 6, 6, 224)    672         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 6, 6, 224)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 6, 6, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 6, 6, 256)    172032      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 6, 6, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 6, 6, 256)    768         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 6, 6, 192)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 6, 6, 256)    0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_196[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 6, 6, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 6, 6, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 6, 6, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 6, 6, 192)    576         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 6, 6, 192)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 6, 6, 224)    129024      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 6, 6, 224)    672         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 6, 6, 224)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 6, 6, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 6, 6, 256)    172032      activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 6, 6, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 6, 6, 256)    768         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 6, 6, 192)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 6, 6, 256)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 6, 6, 448)    0           activation_200[0][0]             \n",
      "                                                                 activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 6, 6, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 6, 6, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 6, 6, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 6, 6, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 6, 6, 1536)   0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1536)         0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            3074        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 54,339,810\n",
      "Trainable params: 54,279,266\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lahore_ResNet18.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 256, 256, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "28/28 [==============================] - 31s 1s/step\n"
     ]
    }
   ],
   "source": [
    "pred_task2 = lahore_ResNet18.predict(testing_images,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  1],\n",
       "       [ 0, 14]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_task2 = confusion_matrix(testing_labels.argmax(axis=1), pred_task2.argmax(axis=1))\n",
    "cm_task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a487522b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(cm_task2 ,annot = True, cmap = \"Blues_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Next you will employ Transfer Learning and finetune the pretrained ResNet18 model you used in Task2 to better fit the Brick Kiln (Nepal) dataset. You will:\n",
    "- Freeze everything except the FC layers and train it using the generator from Task1 (using appropriate hyperparameters)\n",
    "- Construct a binary confusion matrix and visualize it as a heatmap\n",
    "- Compare this confusion matrix with the one made in Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 127, 127, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 127, 127, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 127, 127, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 125, 125, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 125, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 125, 125, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 125, 125, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 125, 125, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 125, 125, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 62, 62, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 62, 62, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 62, 62, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 60, 60, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 60, 60, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 60, 60, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 29, 29, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 29, 29, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 29, 29, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 29, 29, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 29, 29, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 29, 29, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 29, 29, 96)   18432       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 29, 29, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 29, 29, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 29, 29, 64)   12288       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 29, 29, 96)   288         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 29, 29, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 29, 29, 96)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 29, 29, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 29, 29, 320)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 29, 29, 32)   96          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 29, 29, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 29, 29, 48)   13824       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 29, 29, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 29, 29, 48)   144         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 29, 29, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 29, 29, 48)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 29, 29, 32)   9216        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 29, 29, 64)   27648       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 29, 29, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 29, 29, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 29, 29, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 29, 29, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 29, 29, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 29, 29, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 29, 29, 32)   96          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 29, 29, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 29, 29, 48)   13824       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 29, 29, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 29, 29, 48)   144         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 29, 29, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 29, 29, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 29, 29, 32)   9216        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 29, 29, 64)   27648       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 29, 29, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 29, 29, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 29, 29, 64)   192         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 29, 29, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 29, 29, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 29, 29, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 29, 29, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 29, 29, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 29, 29, 32)   96          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 29, 29, 32)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 29, 29, 48)   13824       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 29, 29, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 29, 29, 48)   144         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 29, 29, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 29, 29, 48)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 29, 29, 32)   9216        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 29, 29, 64)   27648       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 29, 29, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 29, 29, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 29, 29, 64)   192         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 29, 29, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 29, 29, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 29, 29, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_25[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 29, 29, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 29, 29, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 29, 29, 32)   96          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 29, 29, 32)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 29, 29, 48)   13824       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 29, 29, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 29, 29, 48)   144         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 29, 29, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_35 (Activation)      (None, 29, 29, 48)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 29, 29, 32)   9216        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 29, 29, 64)   27648       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 29, 29, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 29, 29, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 29, 29, 64)   192         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 29, 29, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 29, 29, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 29, 29, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_31[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 29, 29, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 29, 29, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 29, 29, 32)   96          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 29, 29, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 29, 29, 48)   13824       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 29, 29, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 29, 29, 48)   144         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 29, 29, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 29, 29, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 29, 29, 32)   9216        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 29, 29, 64)   27648       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 29, 29, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 29, 29, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 29, 29, 64)   192         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 29, 29, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 29, 29, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 29, 29, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_37[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 29, 29, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 29, 29, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 29, 29, 32)   96          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 29, 29, 32)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 29, 29, 48)   13824       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 29, 29, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 29, 29, 48)   144         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 29, 29, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 29, 29, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 29, 29, 32)   9216        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 29, 29, 64)   27648       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 29, 29, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 29, 29, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 29, 29, 64)   192         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 29, 29, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 29, 29, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 29, 29, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_43[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 29, 29, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 29, 29, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 29, 29, 32)   96          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 29, 29, 32)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 29, 29, 48)   13824       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 29, 29, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 29, 29, 48)   144         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 29, 29, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 29, 29, 48)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 29, 29, 32)   9216        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 29, 29, 64)   27648       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 29, 29, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 29, 29, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 29, 29, 64)   192         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 29, 29, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 29, 29, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 29, 29, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_49[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 29, 29, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 29, 29, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 29, 29, 32)   96          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 29, 29, 32)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 29, 29, 48)   13824       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 29, 29, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 29, 29, 48)   144         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 29, 29, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 29, 29, 48)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 29, 29, 32)   9216        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 29, 29, 64)   27648       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 29, 29, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 29, 29, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 29, 29, 64)   192         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 29, 29, 32)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 29, 29, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 29, 29, 64)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_55[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 29, 29, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 29, 29, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 29, 29, 32)   96          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 29, 29, 32)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 29, 29, 48)   13824       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 29, 29, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 29, 29, 48)   144         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 29, 29, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 29, 29, 48)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 29, 29, 32)   9216        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 29, 29, 64)   27648       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 29, 29, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 29, 29, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 29, 29, 64)   192         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 29, 29, 32)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 29, 29, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 29, 29, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_61[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 29, 29, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 29, 29, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 29, 29, 32)   96          conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 29, 29, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 29, 29, 48)   13824       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 29, 29, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 29, 29, 48)   144         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 29, 29, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 29, 29, 48)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 29, 29, 32)   9216        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 29, 29, 64)   27648       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 29, 29, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 29, 29, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 29, 29, 64)   192         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 29, 29, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 29, 29, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 29, 29, 64)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 29, 29, 128)  0           activation_67[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 29, 29, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 29, 29, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 29, 29, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 29, 29, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 29, 29, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 29, 29, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 29, 29, 256)  589824      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 29, 29, 256)  768         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 29, 29, 256)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 14, 14, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 14, 14, 384)  884736      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 14, 14, 384)  1152        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 14, 14, 384)  1152        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 384)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 384)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 14, 14, 1088) 0           activation_73[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 14, 14, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 14, 14, 128)  384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 14, 14, 128)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 14, 14, 160)  143360      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 14, 14, 160)  480         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 14, 14, 160)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 14, 14, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 14, 14, 192)  215040      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 14, 14, 192)  576         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 14, 14, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 14, 14, 192)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 14, 14, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_77[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 14, 14, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 14, 14, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 14, 14, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 14, 14, 128)  384         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 14, 14, 128)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 14, 14, 160)  143360      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 14, 14, 160)  480         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 14, 14, 160)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 14, 14, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 14, 14, 192)  215040      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 14, 14, 192)  576         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 14, 14, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 14, 14, 192)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 14, 14, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_81[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 14, 14, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 14, 14, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 14, 14, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 14, 14, 128)  384         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 14, 14, 128)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 14, 14, 160)  143360      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 14, 14, 160)  480         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 14, 14, 160)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 14, 14, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 14, 14, 192)  215040      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 14, 14, 192)  576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 14, 14, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 14, 14, 192)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 14, 14, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_85[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 14, 14, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 14, 14, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 14, 14, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 14, 14, 128)  384         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 14, 14, 128)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 14, 14, 160)  143360      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 14, 14, 160)  480         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 14, 14, 160)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 14, 14, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 14, 14, 192)  215040      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 14, 14, 192)  576         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 14, 14, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 14, 14, 192)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 14, 14, 192)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_89[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 14, 14, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 14, 14, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 14, 14, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 14, 14, 128)  384         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 14, 14, 128)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 14, 14, 160)  143360      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 14, 14, 160)  480         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 14, 14, 160)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 14, 14, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 14, 14, 192)  215040      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 14, 14, 192)  576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 14, 14, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 14, 14, 192)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 14, 14, 192)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_93[0][0]              \n",
      "                                                                 activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 14, 14, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 14, 14, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 14, 14, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 14, 14, 128)  384         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 14, 14, 128)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 14, 14, 160)  143360      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 14, 14, 160)  480         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 14, 14, 160)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 14, 14, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 14, 14, 192)  215040      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 14, 14, 192)  576         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 14, 14, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 14, 14, 192)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 14, 14, 192)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_97[0][0]              \n",
      "                                                                 activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 14, 14, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 14, 14, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 14, 14, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 14, 14, 128)  384         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 14, 14, 128)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 14, 14, 160)  143360      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 14, 14, 160)  480         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 14, 14, 160)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 14, 14, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 14, 14, 192)  215040      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 14, 14, 192)  576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 14, 14, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 14, 14, 192)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 14, 14, 192)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 14, 14, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 14, 14, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 14, 14, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 14, 14, 128)  384         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 14, 14, 128)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 14, 14, 160)  143360      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 14, 14, 160)  480         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 14, 14, 160)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 14, 14, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 14, 14, 192)  215040      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 14, 14, 192)  576         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 14, 14, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 14, 14, 192)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 14, 14, 192)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_105[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 14, 14, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 14, 14, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 14, 14, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 14, 14, 128)  384         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 14, 14, 128)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 14, 14, 160)  143360      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 14, 14, 160)  480         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 14, 14, 160)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 14, 14, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 14, 14, 192)  215040      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 14, 14, 192)  576         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 14, 14, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 14, 14, 192)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 14, 14, 192)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 14, 14, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 14, 14, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 14, 14, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 14, 14, 128)  384         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 14, 14, 128)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 14, 14, 160)  143360      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 14, 14, 160)  480         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 14, 14, 160)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 14, 14, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 14, 14, 192)  215040      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 14, 14, 192)  576         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 14, 14, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 14, 14, 192)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 14, 14, 192)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_113[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 14, 14, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 14, 14, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 14, 14, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 14, 14, 128)  384         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 14, 14, 128)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 14, 14, 160)  143360      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 14, 14, 160)  480         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 14, 14, 160)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 14, 14, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 14, 14, 192)  215040      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 14, 14, 192)  576         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 14, 14, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 14, 14, 192)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 14, 14, 192)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_117[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 14, 14, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 14, 14, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 14, 14, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 14, 14, 128)  384         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 14, 14, 128)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 14, 14, 160)  143360      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 14, 14, 160)  480         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 14, 14, 160)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 14, 14, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 14, 14, 192)  215040      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 14, 14, 192)  576         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 14, 14, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 14, 14, 192)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 14, 14, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 14, 14, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 14, 14, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 14, 14, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 14, 14, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 14, 14, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 14, 14, 160)  143360      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 14, 14, 160)  480         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 14, 14, 160)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 14, 14, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 14, 14, 192)  215040      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 14, 14, 192)  576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 14, 14, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 14, 14, 192)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 14, 14, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 14, 14, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 14, 14, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 14, 14, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 14, 14, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 14, 14, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 14, 14, 160)  143360      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 14, 14, 160)  480         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 14, 14, 160)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 14, 14, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 14, 14, 192)  215040      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 14, 14, 192)  576         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 14, 14, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 14, 14, 192)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 14, 14, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_129[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 14, 14, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 14, 14, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 14, 14, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 14, 14, 128)  384         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 14, 14, 128)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 14, 14, 160)  143360      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 14, 14, 160)  480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 14, 14, 160)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 14, 14, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 14, 14, 192)  215040      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 14, 14, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 14, 14, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 14, 14, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 14, 14, 192)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_133[0][0]             \n",
      "                                                                 activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 14, 14, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 14, 14, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 14, 14, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 14, 14, 128)  384         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 14, 14, 128)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 14, 14, 160)  143360      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 14, 14, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 14, 14, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 14, 14, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 14, 14, 192)  215040      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 14, 14, 192)  576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 14, 14, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 14, 14, 192)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 14, 14, 192)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_137[0][0]             \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 14, 14, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 14, 14, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 14, 14, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 14, 14, 128)  384         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 14, 14, 128)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 14, 14, 160)  143360      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 14, 14, 160)  480         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 14, 14, 160)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 14, 14, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 14, 14, 192)  215040      activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 14, 14, 192)  576         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 14, 14, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 14, 14, 192)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 14, 14, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_141[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 14, 14, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 14, 14, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 14, 14, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 14, 14, 128)  384         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 14, 14, 128)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 14, 14, 160)  143360      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 14, 14, 160)  480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 14, 14, 160)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 14, 14, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 14, 14, 192)  215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 14, 14, 192)  576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 14, 14, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 14, 14, 192)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 14, 14, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 14, 14, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 14, 14, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 14, 14, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 14, 14, 128)  384         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 14, 14, 128)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 14, 14, 160)  143360      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 14, 14, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 14, 14, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 14, 14, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 14, 14, 192)  215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 14, 14, 192)  576         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 14, 14, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 14, 14, 192)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 14, 14, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_149[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 14, 14, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 14, 14, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 14, 14, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 14, 14, 128)  384         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 14, 14, 128)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 14, 14, 160)  143360      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 14, 14, 160)  480         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 14, 14, 160)  0           batch_normalization_155[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 14, 14, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 14, 14, 192)  215040      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 14, 14, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 14, 14, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 14, 14, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 14, 14, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_153[0][0]             \n",
      "                                                                 activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 14, 14, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 14, 14, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 14, 14, 256)  768         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 14, 14, 256)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 14, 14, 288)  663552      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 14, 14, 256)  768         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 14, 14, 256)  768         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 14, 14, 288)  864         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 14, 14, 256)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 14, 14, 256)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 14, 14, 288)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 6, 6, 384)    884736      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 6, 6, 288)    663552      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 6, 6, 320)    829440      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 6, 6, 384)    1152        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 6, 6, 288)    864         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 6, 6, 320)    960         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 6, 6, 384)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 6, 6, 288)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 6, 6, 320)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 6, 6, 2080)   0           activation_158[0][0]             \n",
      "                                                                 activation_160[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 6, 6, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 6, 6, 192)    576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 6, 6, 192)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 6, 6, 224)    129024      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 6, 6, 224)    672         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 6, 6, 224)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 6, 6, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 6, 6, 256)    172032      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 6, 6, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 6, 6, 256)    768         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 6, 6, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 6, 6, 256)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_164[0][0]             \n",
      "                                                                 activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 6, 6, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 6, 6, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 6, 6, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 6, 6, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 6, 6, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 6, 6, 224)    129024      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 6, 6, 224)    672         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 6, 6, 224)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 6, 6, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 6, 6, 256)    172032      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 6, 6, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 6, 6, 256)    768         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 6, 6, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 6, 6, 256)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_168[0][0]             \n",
      "                                                                 activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 6, 6, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 6, 6, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 6, 6, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 6, 6, 192)    576         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 6, 6, 192)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 6, 6, 224)    129024      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 6, 6, 224)    672         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 6, 6, 224)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 6, 6, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 6, 6, 256)    172032      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 6, 6, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 6, 6, 256)    768         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 6, 6, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 6, 6, 256)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_172[0][0]             \n",
      "                                                                 activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 6, 6, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 6, 6, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 6, 6, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 6, 6, 192)    576         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 6, 6, 192)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 6, 6, 224)    129024      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 6, 6, 224)    672         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 6, 6, 224)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 6, 6, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 6, 6, 256)    172032      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 6, 6, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 6, 6, 256)    768         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 6, 6, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 6, 6, 256)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_176[0][0]             \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 6, 6, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 6, 6, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 6, 6, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 6, 6, 192)    576         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 6, 6, 192)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 6, 6, 224)    129024      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 6, 6, 224)    672         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 6, 6, 224)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 6, 6, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 6, 6, 256)    172032      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 6, 6, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 6, 6, 256)    768         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 6, 6, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 6, 6, 256)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_180[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 6, 6, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 6, 6, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 6, 6, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 6, 6, 192)    576         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 6, 6, 192)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 6, 6, 224)    129024      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 6, 6, 224)    672         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 6, 6, 224)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 6, 6, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 6, 6, 256)    172032      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 6, 6, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 6, 6, 256)    768         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 6, 6, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 6, 6, 256)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_184[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 6, 6, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 6, 6, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 6, 6, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 6, 6, 192)    576         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 6, 6, 192)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 6, 6, 224)    129024      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 6, 6, 224)    672         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 6, 6, 224)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 6, 6, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 6, 6, 256)    172032      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 6, 6, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 6, 6, 256)    768         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 6, 6, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 6, 6, 256)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_188[0][0]             \n",
      "                                                                 activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 6, 6, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 6, 6, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 6, 6, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 6, 6, 192)    576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 6, 6, 192)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 6, 6, 224)    129024      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 6, 6, 224)    672         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 6, 6, 224)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 6, 6, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 6, 6, 256)    172032      activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 6, 6, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 6, 6, 256)    768         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 6, 6, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 6, 6, 256)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_192[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 6, 6, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 6, 6, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 6, 6, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 6, 6, 192)    576         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 6, 6, 192)    0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 6, 6, 224)    129024      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 6, 6, 224)    672         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 6, 6, 224)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 6, 6, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 6, 6, 256)    172032      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 6, 6, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 6, 6, 256)    768         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 6, 6, 192)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 6, 6, 256)    0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_196[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 6, 6, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 6, 6, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 6, 6, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 6, 6, 192)    576         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 6, 6, 192)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 6, 6, 224)    129024      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 6, 6, 224)    672         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 6, 6, 224)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 6, 6, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 6, 6, 256)    172032      activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_200 (BatchN (None, 6, 6, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 6, 6, 256)    768         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 6, 6, 192)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 6, 6, 256)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 6, 6, 448)    0           activation_200[0][0]             \n",
      "                                                                 activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 6, 6, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 6, 6, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 6, 6, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 6, 6, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 6, 6, 1536)   0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1536)         0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            3074        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 54,339,810\n",
      "Trainable params: 3,074\n",
      "Non-trainable params: 54,336,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in lahore_ResNet18.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "lahore_ResNet18.compile(loss='categorical_crossentropy', \n",
    "              optimizer=adam, \n",
    "              metrics=['accuracy'])\n",
    "lahore_ResNet18.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_task1 = brick_kiln_generator(input_train_for_generator, label_train_for_generator)\n",
    "val_generator_task1 = brick_kiln_generator(input_val_for_generator, label_val_for_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "342/342 [==============================] - 2014s 6s/step - loss: 0.2207 - acc: 0.9748 - val_loss: 0.0972 - val_acc: 0.9918\n",
      "Epoch 2/10\n",
      "342/342 [==============================] - 60321s 176s/step - loss: 0.1196 - acc: 0.9925 - val_loss: 0.0757 - val_acc: 0.9918\n",
      "Epoch 3/10\n",
      "342/342 [==============================] - 2098s 6s/step - loss: 0.0928 - acc: 0.9923 - val_loss: 0.0587 - val_acc: 0.9918\n",
      "Epoch 4/10\n",
      "342/342 [==============================] - 6231s 18s/step - loss: 0.0247 - acc: 0.9934 - val_loss: 0.0723 - val_acc: 0.9918\n",
      "Epoch 5/10\n",
      "342/342 [==============================] - 1972s 6s/step - loss: 0.0198 - acc: 0.9940 - val_loss: 0.0875 - val_acc: 0.9918\n",
      "Epoch 6/10\n",
      "342/342 [==============================] - 2041s 6s/step - loss: 0.0183 - acc: 0.9943 - val_loss: 0.0886 - val_acc: 0.9918\n",
      "Epoch 7/10\n",
      "342/342 [==============================] - 2033s 6s/step - loss: 0.0191 - acc: 0.9952 - val_loss: 0.1095 - val_acc: 0.9918\n",
      "Epoch 8/10\n",
      "342/342 [==============================] - 2046s 6s/step - loss: 0.0172 - acc: 0.9945 - val_loss: 0.1004 - val_acc: 0.9918\n",
      "Epoch 9/10\n",
      "342/342 [==============================] - 2054s 6s/step - loss: 0.0140 - acc: 0.9960 - val_loss: 0.1004 - val_acc: 0.9918\n",
      "Epoch 10/10\n",
      "342/342 [==============================] - 2038s 6s/step - loss: 0.0154 - acc: 0.9951 - val_loss: 0.1056 - val_acc: 0.9918\n"
     ]
    }
   ],
   "source": [
    "model_name = 'task3_trained'\n",
    "\n",
    "task3_train = lahore_ResNet18.fit_generator(train_generator_task1, \n",
    "                                     epochs=10, \n",
    "                                     steps_per_epoch=len(label_train_for_generator)//batch_size,\n",
    "                                     validation_data= val_generator_task1,\n",
    "                                     validation_steps=len(label_val_for_generator)//batch_size, \n",
    "                                     callbacks=callbacks, verbose=1)\n",
    "\n",
    "#10 epochs = 8 hours\n",
    "lahore_ResNet18.save(model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "16/16 [==============================] - 6s 345ms/step\n",
      "1\n",
      "16/16 [==============================] - 6s 353ms/step\n",
      "2\n",
      "16/16 [==============================] - 5s 343ms/step\n",
      "3\n",
      "16/16 [==============================] - 6s 375ms/step\n",
      "4\n",
      "16/16 [==============================] - 6s 371ms/step\n",
      "5\n",
      "16/16 [==============================] - 5s 343ms/step\n",
      "6\n",
      "16/16 [==============================] - 6s 369ms/step\n",
      "7\n",
      "16/16 [==============================] - 6s 359ms/step\n",
      "8\n",
      "16/16 [==============================] - 6s 360ms/step\n",
      "9\n",
      "16/16 [==============================] - 5s 334ms/step\n",
      "10\n",
      "16/16 [==============================] - 5s 330ms/step\n",
      "11\n",
      "16/16 [==============================] - 5s 331ms/step\n",
      "12\n",
      "16/16 [==============================] - 6s 375ms/step\n",
      "13\n",
      "16/16 [==============================] - 7s 410ms/step\n",
      "14\n",
      "16/16 [==============================] - 8s 470ms/step\n",
      "15\n",
      "16/16 [==============================] - 7s 429ms/step\n",
      "16\n",
      "16/16 [==============================] - 7s 442ms/step\n",
      "17\n",
      "16/16 [==============================] - 7s 433ms/step\n",
      "18\n",
      "16/16 [==============================] - 7s 442ms/step\n",
      "19\n",
      "16/16 [==============================] - 7s 410ms/step\n",
      "20\n",
      "16/16 [==============================] - 6s 403ms/step\n",
      "21\n",
      "16/16 [==============================] - 7s 418ms/step\n",
      "22\n",
      "16/16 [==============================] - 6s 366ms/step\n",
      "23\n",
      "16/16 [==============================] - 7s 420ms/step\n",
      "24\n",
      "16/16 [==============================] - 6s 388ms/step\n",
      "25\n",
      "16/16 [==============================] - 6s 371ms/step\n",
      "26\n",
      "16/16 [==============================] - 6s 399ms/step\n",
      "27\n",
      "16/16 [==============================] - 6s 391ms/step\n",
      "28\n",
      "16/16 [==============================] - 7s 415ms/step\n",
      "29\n",
      "16/16 [==============================] - 6s 388ms/step\n",
      "30\n",
      "16/16 [==============================] - 6s 354ms/step\n",
      "31\n",
      "16/16 [==============================] - 6s 368ms/step\n",
      "32\n",
      "16/16 [==============================] - 6s 364ms/step\n",
      "33\n",
      "16/16 [==============================] - 7s 414ms/step\n",
      "34\n",
      "16/16 [==============================] - 6s 396ms/step\n",
      "35\n",
      "16/16 [==============================] - 7s 412ms/step\n",
      "36\n",
      "16/16 [==============================] - 5s 337ms/step\n",
      "37\n",
      "16/16 [==============================] - 6s 350ms/step\n",
      "38\n",
      "16/16 [==============================] - 5s 325ms/step\n",
      "39\n",
      "16/16 [==============================] - 5s 336ms/step\n",
      "40\n",
      "16/16 [==============================] - 5s 321ms/step\n",
      "41\n",
      "16/16 [==============================] - 5s 322ms/step\n",
      "42\n",
      "16/16 [==============================] - 5s 343ms/step\n",
      "43\n",
      "16/16 [==============================] - 6s 398ms/step\n",
      "44\n",
      "16/16 [==============================] - 7s 410ms/step\n",
      "45\n",
      "16/16 [==============================] - 6s 404ms/step\n",
      "46\n",
      "16/16 [==============================] - 7s 448ms/step\n",
      "47\n",
      "16/16 [==============================] - 6s 396ms/step\n",
      "48\n",
      "16/16 [==============================] - 6s 400ms/step\n",
      "49\n",
      "16/16 [==============================] - 7s 434ms/step\n",
      "50\n",
      "16/16 [==============================] - 7s 419ms/step\n",
      "51\n",
      "16/16 [==============================] - 6s 387ms/step\n",
      "52\n",
      "16/16 [==============================] - 6s 372ms/step\n",
      "53\n",
      "16/16 [==============================] - 6s 394ms/step\n",
      "54\n",
      "16/16 [==============================] - 6s 390ms/step\n",
      "55\n",
      "16/16 [==============================] - 6s 376ms/step\n",
      "56\n",
      "16/16 [==============================] - 6s 404ms/step\n",
      "57\n",
      "16/16 [==============================] - 7s 430ms/step\n",
      "58\n",
      "16/16 [==============================] - 7s 438ms/step\n",
      "59\n",
      "16/16 [==============================] - 7s 407ms/step\n",
      "60\n",
      "16/16 [==============================] - 7s 433ms/step\n",
      "61\n",
      "16/16 [==============================] - 5s 320ms/step\n",
      "62\n",
      "16/16 [==============================] - 7s 410ms/step\n",
      "63\n",
      "16/16 [==============================] - 6s 401ms/step\n",
      "64\n",
      "16/16 [==============================] - 7s 418ms/step\n",
      "65\n",
      "16/16 [==============================] - 6s 404ms/step\n",
      "66\n",
      "16/16 [==============================] - 6s 387ms/step\n",
      "67\n",
      "16/16 [==============================] - 6s 365ms/step\n",
      "68\n",
      "16/16 [==============================] - 7s 421ms/step\n",
      "69\n",
      "16/16 [==============================] - 6s 372ms/step\n",
      "70\n",
      "16/16 [==============================] - 6s 368ms/step\n",
      "71\n",
      "16/16 [==============================] - 6s 386ms/step\n",
      "72\n",
      "16/16 [==============================] - 6s 349ms/step\n",
      "73\n",
      "16/16 [==============================] - 5s 339ms/step\n",
      "74\n",
      "16/16 [==============================] - 5s 342ms/step\n",
      "75\n",
      "16/16 [==============================] - 5s 339ms/step\n",
      "76\n",
      "16/16 [==============================] - 6s 345ms/step\n",
      "77\n",
      "16/16 [==============================] - 6s 358ms/step\n",
      "78\n",
      "16/16 [==============================] - 5s 337ms/step\n",
      "79\n",
      "16/16 [==============================] - 6s 381ms/step\n",
      "80\n",
      "16/16 [==============================] - 7s 416ms/step\n",
      "81\n",
      "16/16 [==============================] - 7s 414ms/step\n",
      "82\n",
      "16/16 [==============================] - 6s 376ms/step\n",
      "83\n",
      "16/16 [==============================] - 7s 424ms/step\n",
      "84\n",
      "16/16 [==============================] - 6s 394ms/step\n",
      "85\n",
      "16/16 [==============================] - 7s 450ms/step\n",
      "86\n",
      "16/16 [==============================] - 6s 400ms/step\n",
      "87\n",
      "16/16 [==============================] - 7s 418ms/step\n",
      "88\n",
      "16/16 [==============================] - 7s 451ms/step\n",
      "89\n",
      "16/16 [==============================] - 6s 391ms/step\n",
      "90\n",
      "16/16 [==============================] - 6s 381ms/step\n",
      "91\n",
      "16/16 [==============================] - 6s 390ms/step\n",
      "92\n",
      "16/16 [==============================] - 6s 378ms/step\n",
      "93\n",
      "16/16 [==============================] - 6s 371ms/step\n",
      "94\n",
      "16/16 [==============================] - 6s 372ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator_task1 = brick_kiln_generator(input_test_for_generator, label_test_for_generator)\n",
    "#94 iterations\n",
    "\n",
    "predictions_task3 = []\n",
    "actual_values_task3 = []\n",
    "for i in range(len(y_test)//batch_size):\n",
    "    x, y = next(test_generator_task1)\n",
    "    print(i)\n",
    "    pred = lahore_ResNet18.predict(x,verbose = 1)\n",
    "    actual_values_task3.append(y)\n",
    "    predictions_task3.append(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_total_task3 = []\n",
    "labels_total_task3 = []\n",
    "\n",
    "for epoch in predictions_task3:\n",
    "    for val in epoch:\n",
    "        preds_total_task3.append(val)\n",
    "        \n",
    "for epoch in actual_values_task3:\n",
    "    for val in epoch:\n",
    "        labels_total_task3.append(val)        \n",
    "\n",
    "preds_total_task3 = np.array(preds_total_task3)\n",
    "labels_total_task3 = np.array(labels_total_task3)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1508,    0],\n",
       "       [  12,    0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_task3 = confusion_matrix(labels_total_task3.argmax(axis=1), preds_total_task3.argmax(axis=1))\n",
    "cm_task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a45e38208>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm_task3, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Now we will look at a multiclass classification problem.\n",
    "\n",
    "The UC Merced Land Use dataset consists of 21 classes, ranging from airplanes to forests to tennis courts. Let's add kilns to it since you worked so hard to annotate the dataset in Task1. You will:\n",
    "- Download the dataset and add a new folder (following the already existing folder structure) corresponding to brick kilns\n",
    "- Code up a generator to properly load the images and corresponding 22-class labels into a model. You have to resize images into 224X224X3 for VGG16\n",
    "\n",
    "*Scale images between 0 and 1 and apply mean subtraction in the generator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 22\n",
    "input_shape = (224,224,3)\n",
    "dir_main_landuse = 'Data/LandUseDataset/Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_folders = os.listdir(dir_main_landuse)\n",
    "labels_total = [] #each index contains paths to one class\n",
    "paths_to_images = []  #each index contains labels to one class\n",
    "\n",
    "for i in range(len(paths_to_folders)): #completing path\n",
    "    paths_to_folders[i] = dir_main_landuse + paths_to_folders[i]\n",
    "    \n",
    "# paths_to_folders = paths_to_folders[0:4] + paths_to_folders[5:]  #removing .DS folder\n",
    "paths_to_folders = paths_to_folders[1:]\n",
    "\n",
    "for i in range(len(paths_to_folders)):\n",
    "    paths_to_images.append(os.listdir(paths_to_folders[i]))\n",
    "    \n",
    "for i in range(len(paths_to_images)):\n",
    "    l = []\n",
    "    for j in range(len(paths_to_images[i])):\n",
    "        paths_to_images[i][j] = paths_to_folders[i] + '/' + paths_to_images[i][j]\n",
    "        l.append(i)\n",
    "    labels_total.append(l)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train ,input_test, label_train, label_test = [],[],[],[]\n",
    "input_val, label_val = [],[]\n",
    "\n",
    "for i in range(len(paths_to_images)):\n",
    "    x_train ,x_test, y_train, y_test = train_test_split(paths_to_images[i], labels_total[i], test_size=0.2)\n",
    "    input_train.append(x_train)\n",
    "    input_test.append(x_test)\n",
    "    label_train.append(y_train)\n",
    "    label_test.append(y_test)\n",
    "\n",
    "x  = input_train\n",
    "y = label_train\n",
    "input_train, label_train = [],[]\n",
    "\n",
    "for i in range(len(x)):\n",
    "    x_train ,x_val, y_train, y_val = train_test_split(x[i], y[i], test_size=0.1)\n",
    "    input_train.append(x_train)\n",
    "    input_val.append(x_val)\n",
    "    label_train.append(y_train)\n",
    "    label_val.append(y_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_for_generator = []\n",
    "input_val_for_generator = []\n",
    "input_test_for_generator = []\n",
    "label_train_for_generator = []\n",
    "label_val_for_generator = []\n",
    "label_test_for_generator = []\n",
    "\n",
    "for i in range(len(input_val)):\n",
    "    for j in range(len(input_val[i])):\n",
    "        input_val_for_generator.append(input_val[i][j])\n",
    "        label_val_for_generator.append(label_val[i][j])\n",
    "        \n",
    "for i in range(len(input_test)):\n",
    "    for j in range(len(input_test[i])):\n",
    "        input_test_for_generator.append(input_test[i][j])\n",
    "        label_test_for_generator.append(label_test[i][j])\n",
    "        \n",
    "for i in range(len(input_train)):\n",
    "    for j in range(len(input_train[i])):\n",
    "        input_train_for_generator.append(input_train[i][j])\n",
    "        label_train_for_generator.append(label_train[i][j])\n",
    "\n",
    "#randomly shuffling data before sending into generator\n",
    "c = list(zip(input_val_for_generator, label_val_for_generator))\n",
    "random.shuffle(c)\n",
    "input_val_for_generator, label_val_for_generator = zip(*c)\n",
    "\n",
    "\n",
    "c = list(zip(input_test_for_generator, label_test_for_generator))\n",
    "random.shuffle(c)\n",
    "input_test_for_generator, label_test_for_generator = zip(*c)\n",
    "\n",
    "c = list(zip(input_train_for_generator, label_train_for_generator))\n",
    "random.shuffle(c)\n",
    "input_train_for_generator, label_train_for_generator = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images for training:  1554\n",
      "Total Images for validation:  173\n",
      "Total Images for testing:  432\n"
     ]
    }
   ],
   "source": [
    "print (\"Total Images for training: \", len(input_train_for_generator))\n",
    "print (\"Total Images for validation: \", len(input_val_for_generator))\n",
    "print (\"Total Images for testing: \", len(input_test_for_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_use_generator(path_all_images, class_labels, batch_size = 64):\n",
    "    total_pictures = len(path_all_images)\n",
    "    indexes = np.arange(0,total_pictures,batch_size) #setting start index of each batch\n",
    "    \n",
    "    if total_pictures % batch_size != 0:\n",
    "        indexes = indexes[:-1]  #dropping last index if last batch does not complete the batch size requirement\n",
    "        \n",
    "    while True:\n",
    "        np.random.shuffle(indexes) #shuffles indexes so order of data given to model in each epoch is different\n",
    "        for index in indexes:\n",
    "            path = path_all_images[index : index + batch_size]\n",
    "            labels = class_labels[index : index + batch_size]\n",
    "            \n",
    "            x_array = np.zeros((batch_size,224,224,3))\n",
    "            batch_labels = to_categorical(labels, num_classes = 22)\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                img = cv2.imread(path[i])\n",
    "                x_array[i] = cv2.resize(img,(224,224))\n",
    "                \n",
    "            x_array = x_array.astype('float32')/255.0\n",
    "                \n",
    "            batch_x = x_array  \n",
    "            batch_y = np.array(batch_labels)\n",
    "            yield batch_x, batch_y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Next you will again employ Transfer Learning and finetune the pretrained (on ImageNet) VGG16 to better fit the modified Land Use dataset. You will:\n",
    "- Change the number of nodes in the last FC layer according to the number of classes i.e. 22 \n",
    "- Freeze everything except the FC layers and train it using the generator from Task4 (using appropriate hyperparameters)\n",
    "- Construct a multi-class confusion matrix and visualize it as a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 22)                551958    \n",
      "=================================================================\n",
      "Total params: 15,266,646\n",
      "Trainable params: 551,958\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_imagenet = vgg16.VGG16(include_top=False, weights='imagenet')\n",
    "for l in vgg_imagenet.layers:\n",
    "    l.trainable = False\n",
    "\n",
    "im =  Input(shape=(224,224,3))\n",
    "vgg = vgg_imagenet(im)\n",
    "flat = Flatten()(vgg)\n",
    "# fc2 = Dense(1024, activation='relu')(flat)\n",
    "# dropout2 = Dropout(0.2)(fc2)\n",
    "output = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "my_model = Model(im,output)\n",
    "\n",
    "my_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=0.00001), \n",
    "              metrics=['accuracy'])\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_task4 = land_use_generator(input_train_for_generator, label_train_for_generator)\n",
    "val_generator_task4 = land_use_generator(input_val_for_generator, label_val_for_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "24/24 [==============================] - 766s 32s/step - loss: 3.2352 - acc: 0.0482 - val_loss: 3.0573 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.05729, saving model to Best_models/ -01-3.06.h5\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 710s 30s/step - loss: 2.9702 - acc: 0.1120 - val_loss: 2.8721 - val_acc: 0.2109\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.05729 to 2.87209, saving model to Best_models/ -02-2.87.h5\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 707s 29s/step - loss: 2.7820 - acc: 0.2311 - val_loss: 2.7187 - val_acc: 0.3359\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.87209 to 2.71865, saving model to Best_models/ -03-2.72.h5\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 804s 34s/step - loss: 2.6159 - acc: 0.3757 - val_loss: 2.5749 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.71865 to 2.57494, saving model to Best_models/ -04-2.57.h5\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 721s 30s/step - loss: 2.4681 - acc: 0.4753 - val_loss: 2.4465 - val_acc: 0.5078\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.57494 to 2.44647, saving model to Best_models/ -05-2.45.h5\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 717s 30s/step - loss: 2.3304 - acc: 0.5534 - val_loss: 2.3293 - val_acc: 0.5625\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.44647 to 2.32925, saving model to Best_models/ -06-2.33.h5\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 718s 30s/step - loss: 2.2035 - acc: 0.6315 - val_loss: 2.2183 - val_acc: 0.6328\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.32925 to 2.21825, saving model to Best_models/ -07-2.22.h5\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 718s 30s/step - loss: 2.0851 - acc: 0.6764 - val_loss: 2.1159 - val_acc: 0.6484\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.21825 to 2.11591, saving model to Best_models/ -08-2.12.h5\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 716s 30s/step - loss: 1.9741 - acc: 0.7305 - val_loss: 2.0218 - val_acc: 0.6797\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.11591 to 2.02180, saving model to Best_models/ -09-2.02.h5\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 719s 30s/step - loss: 1.8726 - acc: 0.7435 - val_loss: 1.9339 - val_acc: 0.6641\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.02180 to 1.93389, saving model to Best_models/ -10-1.93.h5\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 718s 30s/step - loss: 1.7777 - acc: 0.7747 - val_loss: 1.8508 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.93389 to 1.85079, saving model to Best_models/ -11-1.85.h5\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 717s 30s/step - loss: 1.6902 - acc: 0.7956 - val_loss: 1.7756 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.85079 to 1.77558, saving model to Best_models/ -12-1.78.h5\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 719s 30s/step - loss: 1.6097 - acc: 0.8132 - val_loss: 1.7068 - val_acc: 0.7266\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.77558 to 1.70679, saving model to Best_models/ -13-1.71.h5\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 722s 30s/step - loss: 1.5351 - acc: 0.8288 - val_loss: 1.6397 - val_acc: 0.7344\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.70679 to 1.63966, saving model to Best_models/ -14-1.64.h5\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 723s 30s/step - loss: 1.4652 - acc: 0.8392 - val_loss: 1.5826 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.63966 to 1.58255, saving model to Best_models/ -15-1.58.h5\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 721s 30s/step - loss: 1.4011 - acc: 0.8483 - val_loss: 1.5277 - val_acc: 0.7344\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.58255 to 1.52766, saving model to Best_models/ -16-1.53.h5\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 722s 30s/step - loss: 1.3415 - acc: 0.8581 - val_loss: 1.4746 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.52766 to 1.47461, saving model to Best_models/ -17-1.47.h5\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 724s 30s/step - loss: 1.2861 - acc: 0.8672 - val_loss: 1.4276 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.47461 to 1.42757, saving model to Best_models/ -18-1.43.h5\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 808s 34s/step - loss: 1.2341 - acc: 0.8711 - val_loss: 1.3825 - val_acc: 0.7656\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.42757 to 1.38249, saving model to Best_models/ -19-1.38.h5\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 822s 34s/step - loss: 1.1851 - acc: 0.8763 - val_loss: 1.3409 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.38249 to 1.34094, saving model to Best_models/ -20-1.34.h5\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 809s 34s/step - loss: 1.1404 - acc: 0.8815 - val_loss: 1.3023 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.34094 to 1.30230, saving model to Best_models/ -21-1.30.h5\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 773s 32s/step - loss: 1.0989 - acc: 0.8822 - val_loss: 1.2658 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.30230 to 1.26583, saving model to Best_models/ -22-1.27.h5\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 728s 30s/step - loss: 1.0580 - acc: 0.8893 - val_loss: 1.2323 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.26583 to 1.23231, saving model to Best_models/ -23-1.23.h5\n",
      "Epoch 24/25\n",
      "24/24 [==============================] - 732s 30s/step - loss: 1.0216 - acc: 0.8900 - val_loss: 1.1989 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.23231 to 1.19893, saving model to Best_models/ -24-1.20.h5\n",
      "Epoch 25/25\n",
      "24/24 [==============================] - 727s 30s/step - loss: 0.9867 - acc: 0.8978 - val_loss: 1.1684 - val_acc: 0.8203\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.19893 to 1.16839, saving model to Best_models/ -25-1.17.h5\n"
     ]
    }
   ],
   "source": [
    "model_name = 'task5_trained2'\n",
    "\n",
    "task5_train2 = my_model.fit_generator(train_generator_task4, \n",
    "                                     epochs=25, \n",
    "                                     steps_per_epoch=len(label_train_for_generator)//batch_size,\n",
    "                                     validation_data= val_generator_task4,\n",
    "                                     validation_steps=len(label_val_for_generator)//batch_size, \n",
    "                                     callbacks=callbacks, verbose=1)\n",
    "  \n",
    "#2.5 hours per 10 epochs\n",
    "my_model.save(model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = load_model('task5_trained2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "32/32 [==============================] - 14s 450ms/step\n",
      "1\n",
      "32/32 [==============================] - 13s 412ms/step\n",
      "2\n",
      "32/32 [==============================] - 13s 412ms/step\n",
      "3\n",
      "32/32 [==============================] - 13s 413ms/step\n",
      "4\n",
      "32/32 [==============================] - 13s 412ms/step\n",
      "5\n",
      "32/32 [==============================] - 14s 422ms/step\n",
      "6\n",
      "32/32 [==============================] - 13s 416ms/step\n",
      "7\n",
      "32/32 [==============================] - 13s 417ms/step\n",
      "8\n",
      "32/32 [==============================] - 13s 414ms/step\n",
      "9\n",
      "32/32 [==============================] - 13s 414ms/step\n",
      "10\n",
      "32/32 [==============================] - 13s 411ms/step\n",
      "11\n",
      "32/32 [==============================] - 13s 412ms/step\n",
      "12\n",
      "32/32 [==============================] - 13s 413ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator_task4 = land_use_generator(input_test_for_generator, label_test_for_generator)\n",
    "\n",
    "predictions_task5 = []\n",
    "actual_values_task5 = []\n",
    "for i in range(len(input_test_for_generator)//batch_size):\n",
    "    x, y = next(test_generator_task4)\n",
    "    print(i)\n",
    "    pred = my_model.predict(x ,verbose = 1)\n",
    "    actual_values_task5.append(y)\n",
    "    predictions_task5.append(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_total_task5 = []\n",
    "labels_total_task5 = []\n",
    "\n",
    "for epoch in predictions_task5:\n",
    "    for val in epoch:\n",
    "        preds_total_task5.append(val)\n",
    "        \n",
    "for epoch in actual_values_task5:\n",
    "    for val in epoch:\n",
    "        labels_total_task5.append(val)        \n",
    "\n",
    "preds_total_task5 = np.array(preds_total_task5)\n",
    "labels_total_task5 = np.array(labels_total_task5)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 20,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0, 19,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 18,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 20,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 16,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 18,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 20,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 20,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0, 19,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        18,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0, 12,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         1,  0, 18,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0, 19,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0, 19,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,\n",
       "         0,  0,  0,  0,  0, 18]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_task5 = confusion_matrix(labels_total_task5.argmax(axis=1), preds_total_task5.argmax(axis=1))\n",
    "cm_task5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a43c259b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABhEAAAaACAYAAABmMn1lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XuwnXV97/HPyl4hG7KDtEoRUESBI94QA4bRQlQkB6TFjI4zZFq5lEstXggqLZB0YknRcGu1B1Ao2oiMU1qKhbTKEYs0BC+ApWBTlWphvESHqR6EJEIue63zR09SPP2RrGjWejbP7/WayUw3kJ3vu0+H6fjxWbvT7/f7AQAAAAAA+P9Ma/oAAAAAAABgajIiAAAAAAAARUYEAAAAAACgyIgAAAAAAAAUGREAAAAAAIAiIwIAAAAAAFDUbfoAAAAAAABg59q0aVMWLVqUNWvWZOPGjTnrrLNy4IEH5vzzz0+n08lBBx2UD3zgA5k2bdvvGhgRAAAAAACgZVasWJE99tgjl112WR599NG85S1vycEHH5xzzjknRxxxRJYsWZLbb7898+bN2+b38XFGAAAAAADQMscdd1wWLly49euxsbH867/+a+bMmZMkmTt3br785S9v9/sM9U2EDf921zC//ZQ08+UnNn0CAAAAALCTbd64pukTWmXTjx9q+oRWmP6cFz3t35s5c2aSZN26dTn77LNzzjnn5JJLLkmn09n699euXbvdP8ObCAAAAAAA0EI/+tGPcvLJJ2f+/Pk54YQTfu7nH6xfvz677777dr+HEQEAAAAAAFrmxz/+cU477bT8/u//ft72trclSV760pfm7rvvTpLceeedOfzww7f7fTr9fr8/rCN9nBEAAAAA0AY+zmjn8nFGO8e2Ps7ooosuyq233poXvei//pnFixfnoosuyqZNm/KiF70oF110UcbGxrb5ZxgRdjIjAgAAAAC0jxFh5zIi7BzbGhF2Fh9nBAAAAAAAFBkRAAAAAACAom7TBwAAAAAAUJneZNMXMCBvIgAAAAAAAEVGBAAAAAAAoMiIAAAAAAAAFBkRAAAAAACAIiMCAAAAAABQ1G36AAAAAAAAKtPvNX0BA/ImAgAAAAAAUGREAAAAAAAAiowIAAAAAABAkREBAAAAAAAoMiIAAAAAAABFRgQAAAAAAKCo2/QBAAAAAABUptdr+gIG5E0EAAAAAACgyIgAAAAAAAAUGREAAAAAAIAiIwIAAAAAAFBkRAAAAAAAAIq6TR8AAAAAAEBd+v1e0ycwIG8iAAAAAAAARUYEAAAAAACgyIgAAAAAAAAUGREAAAAAAIAiIwIAAAAAAFDUbfoAAAAAAAAq0+s1fQEDas2bCF9/8KGcdsGlSZJvfOe7+a33XZRTzrs4y675dHot/j/ITqeTq668OHfduSK3f+HGHHDA/k2fNHSaNbdVbc219SaaNbeXZs1tVVtzbb2JZs3tpVlzW9XYDFNBK0aEv7jp1vzRFZ/Mhk2bkiRLr7ouf3Dmglx3yfmZ2G3XfG7l3Q1fODzz5x+X8fEZOXLum7No8bJcdumSpk8aOs2a26q25tp6E82a20uz5raqrbm23kSz5vbSrLmtamyGqWDgEWEq/7f5n//cPfPhRe/a+vUjP340h77kwCTJoS85KP/8jW83ddrQHfnaOfn8bXckSe6+574cNvuQhi8aPs2a26q25tp6E82a20uz5raqrbm23kSz5vbSrLmtamyGqWCbI8L3v//9vPOd78zcuXNzzDHH5PWvf31+93d/Nw8//PCo7hvIvF8/PN2xsa1fP++5e+Zr//JgkmTlPffniSc3NHXa0M3afSKPP7Z269eTk72MPeV/F22kWXNb1dZcW2+iOdHcVpo1t1VtzbX1JpoTzW2lWXNb1dgMU8E2f7Dy4sWL8/73vz+vfOUrt/61+++/PxdccEFuuOGGoR/3i1q68LRccu1fZvlnbs3LDnphdpk+vemThmbt4+syMWti69fTpk3L5ORkgxcNn2bNbVVbc229ieZEc1tp1txWtTXX1ptoTjS3lWbNbVVjM0wF23wTYePGjT83ICTJoYceOtSDdoZVX3sgS88+NVd94Jw8tnZdXvOqlzZ90tB86Sv35k3HHZ0kOWLO7Kxe/c2GLxo+zZrbqrbm2noTzZrbS7PmtqqtubbeRLPm9tKsua1qbIapYJtvIrz4xS/OBRdckKOOOiqzZs3K+vXrs3Llyrz4xS8e1X2/kP322SvvuvDPMj5jl7z6FQfnqMPb+/loN998a45549ysWnlLOp1OTj/zvU2fNHSaNbdVbc219SaaNbeXZs1tVVtzbb2JZs3tpVlzW9XY3Gr9qfszePl5nX6/33+6v9nv9/MP//AP+ad/+qesW7cuExMTmT17dubNm5dOp7Pdb77h3+7aqcc+E8x8+YlNnwAAAAAA7GSbN65p+oRW2fj9B5o+oRV2ef4rt/8P/ZK2+SZCp9PJvHnzMm/evKEfAgAAAAAATC3b/JkIAAAAAABAvYwIAAAAAABAkREBAAAAAAAo2ubPRAAAAAAAgJ2uN9n0BQzImwgAAAAAAECREQEAAAAAACgyIgAAAAAAAEVGBAAAAAAAoMiIAAAAAAAAFHWbPgAAAAAAgMr0e01fwIC8iQAAAAAAABQZEQAAAAAAgCIjAgAAAAAAUGREAAAAAAAAiowIAAAAAABAkREBAAAAAAAo6jZ9AAAAAAAAlen1mr6AAXkTAQAAAAAAKDIiAAAAAAAARUYEAAAAAACgyIgAAAAAAAAUGREAAAAAAICibtMHAAAAAABQl36/1/QJDMibCAAAAAAAQJERAQAAAAAAKDIiAAAAAAAARUYEAAAAAACgyIgAAAAAAAAUGREAAAAAAICibtMHAAAAAABQmV6v6QsYkDcRAAAAAACAIiMCAAAAAABQNNSPM5r58hOH+e2npPWr/6rpE0aqxmcMAEwte4zPbPqEkfvpk+ubPgEAAKiENxEAAAAAAIAiIwIAAAAAAFA01I8zAgAAAACA/6bfa/oCBuRNBAAAAAAAoMiIAAAAAAAAFBkRAAAAAACAIiMCAAAAAABQZEQAAAAAAACKuk0fAAAAAABAZXqTTV/AgLyJAAAAAAAAFBkRAAAAAACAIiMCAAAAAABQZEQAAAAAAACKjAgAAAAAAECREQEAAAAAACjqNn0AAAAAAACV6feavoABeRMBAAAAAAAoMiIAAAAAAABFRgQAAAAAAKDIiAAAAAAAABQZEQAAAAAAgKJu0wcAAAAAAFCZXq/pCxiQNxEAAAAAAIAiIwIAAAAAAFBkRAAAAAAAAIqMCAAAAAAAQJERAQAAAAAAKOo2fQAAAAAAAJXp95q+gAF5EwEAAAAAACgyIgAAAAAAAEVGBAAAAAAAoMiIAAAAAAAAFLVqROh0Ornqyotz150rcvsXbswBB+zf9ElD9fUHH8ppF1yaJPnGd76b33rfRTnlvIuz7JpPp9dr7w8mqe05J5o1t1NtvYlmze1VY/MWsw8/JLd89vqmzxiJGp9zbc219SaaNbeXZs1tVWMzTAWtGhHmzz8u4+MzcuTcN2fR4mW57NIlTZ80NH9x0635oys+mQ2bNiVJll51Xf7gzAW57pLzM7HbrvncyrsbvnB4anrOW2jW3Ea19SaaNbdXjc1J8p6FZ+QjV3wwM8ZnNH3KSNT4nGtrrq030ay5vTRrbqsam2EqaNWIcORr5+Tzt92RJLn7nvty2OxDGr5oeJ7/3D3z4UXv2vr1Iz9+NIe+5MAkyaEvOSj//I1vN3Xa0NX0nLfQrLmNautNNGturxqbk+Thh7+XU9/+7qbPGJkan3NtzbX1Jpo1t5dmzW1VY3Or9Xp+7YxfI9CqEWHW7hN5/LG1W7+enOxlbGyswYuGZ96vH57uU9qe99w987V/eTBJsvKe+/PEkxuaOm3oanrOW2jW3Ea19SaaE81tVWNzkvz9ituyadPmps8YmRqfc23NtfUmmhPNbaVZc1vV2AxTQbfpA3amtY+vy8Ssia1fT5s2LZOTkw1eNDpLF56WS679yyz/zK152UEvzC7Tpzd90tDU+Jw1a26j2noTzYnmtqqxuUY1PufammvrTTQnmttKs+a2qrEZpoJtvolw0kknZcGCBT/368QTT8yCBQtGdd8O+dJX7s2bjjs6SXLEnNlZvfqbDV80Oqu+9kCWnn1qrvrAOXls7bq85lUvbfqkoanxOWvW3Ea19SaaNbdXjc01qvE519ZcW2+iWXN7adbcVjU2w1SwzTcRzj333PzhH/5hrrrqqmfEq0E333xrjnnj3KxaeUs6nU5OP/O9TZ80Mvvts1fedeGfZXzGLnn1Kw7OUYe39zPhanzOmjW3UW29iWbN7VVjc41qfM61NdfWm2jW3F6aNbdVjc0wFXT6/X5/W//Axz/+8bzgBS/IvHnzdvibd3fZ9xc+7Jlq/eq/avqEkZr58hObPgEAqNwe4zObPmHkfvrk+qZPAACozuaNa5o+oVU2fP3zTZ/QCjMOOXbof8Z2fybCGWecMfQjAAAAAACoR7/v51k8U2zzZyIAAAAAAAD1MiIAAAAAAABFRgQAAAAAAKDIiAAAAAAAABQZEQAAAAAAgCIjAgAAAAAAUNRt+gAAAAAAACrT7zV9AQPyJgIAAAAAAFBkRAAAAAAAAIqMCAAAAAAAQJERAQAAAAAAKDIiAAAAAAAARd2mDwAAAAAAoDK9XtMXMCBvIgAAAAAAAEVGBAAAAAAAoMiIAAAAAAAAFBkRAAAAAACAIiMCAAAAAABQ1G36AAAAAAAAKtPvNX0BA/ImAgAAAAAAUGREAAAAAAAAiowIAAAAAABAkREBAAAAAAAoMiIAAAAAAABFRgQAAAAAAKCo2/QBAAAAAABUpjfZ9AUMyJsIAAAAAABAkREBAAAAAAAoMiIAAAAAAABFRgQAAAAAAKDIiAAAAAAAABR1mz4AAAAAAIDK9HtNX8CAjAg72cyXn9j0CSO1buXlTZ8wchOvO7fpEwCAp/jpk+ubPgEAeIo9xmc2fcLI+f9HgDbzcUYAAAAAAECREQEAAAAAACgyIgAAAAAAAEVGBAAAAAAAoMgPVgYAAAAAYLR6vaYvYEDeRAAAAAAAAIqMCAAAAAAAQJERAQAAAAAAKDIiAAAAAAAARUYEAAAAAACgyIgAAAAAAAAUdZs+AAAAAACAyvR7TV/AgLyJAAAAAAAAFBkRAAAAAACAIiMCAAAAAABQZEQAAAAAAACKjAgAAAAAAEBRt+kDAAAAAACoTK/X9AUMyJsIAAAAAABAkREBAAAAAAAoMiIAAAAAAABFRgQAAAAAAKDIiAAAAAAAABR1mz4AAAAAAIDK9HpNX8CAvIkAAAAAAAAUGREAAAAAAIAiIwIAAAAAAFBkRAAAAAAAAIqMCAAAAAAAQJERAQAAAAAAKOo2fQAAAAAAAHXp9yebPoEBeRMBAAAAAAAoMiIAAAAAAABFrRoROp1Orrry4tx154rc/oUbc8AB+zd90tDV1vz1f/9BTl+2PEnyre/+KG9fem1O+eAnsuQTN6fX6zV83fDU9pwTzTU019abaNbcXpo1t1VtzbX1Jpo1t1eNzVvMPvyQ3PLZ65s+YyRqfM41NsNUsMMjwsaNG4dxx04xf/5xGR+fkSPnvjmLFi/LZZcuafqkoaupefnn7sqFy1dkw6bNSZKrb1mZd8x/Xa5bfHo2bZrMnQ98u+ELh6em57yF5vY319abaNbcXpo1t1VtzbX1Jpo1t1eNzUnynoVn5CNXfDAzxmc0fcpI1Pica2yGqeBpR4QvfvGLecMb3pB58+blc5/73Na/fsYZZ4zksF/Eka+dk8/fdkeS5O577sthsw9p+KLhq6n5+Xv+av703Sdu/frgFzw3j61/Iv1+P+uf3JDpY616sebn1PSct9Dc/ubaehPNmttLs+a2qq25tt5Es+b2qrE5SR5++Hs59e3vbvqMkanxOdfYDFNB9+n+xtVXX52//du/Tb/fz8KFC7Nhw4a85S1vSb/fH+V9O2TW7hN5/LG1W7+enOxlbGwsk5Pt/UnfNTUf8+qXZs1/PLr16xfs9ex86PrP5toVd2Zit/EcfvD+zR03ZDU95y00t7+5tt5Ec6K5rTRrbqvammvrTTQnmtuqxuYk+fsVt+X5++3b9BkjU+NzrrG51Vr80eRt87QjwvTp07PHHnskST760Y/mlFNOyd57751OpzOy43bU2sfXZWLWxNavp02b1vp/idTYvMUln741yxedlgP3/bXc8A/35E9uuC2LTv6Nps8aihqfs+b2N9fWm2hONLeVZs1tVVtzbb2J5kRzW9XYXKMan3ONzTAVPO3nv+y7775ZtmxZfvazn2ViYiJXXnllli5dmoceemiU9+2QL33l3rzpuKOTJEfMmZ3Vq7/Z8EXDV2PzFs+auWsm/t/nHO75K7Py+M+eaPii4anxOWtuf3NtvYlmze2lWXNb1dZcW2+iWXN71dhcoxqfc43NMBU87ZsIH/rQh7JixYqtbx7svffe+dSnPpVrrrlmZMftqJtvvjXHvHFuVq28JZ1OJ6ef+d6mTxq6Gpu3+MBpb855H/ubjI1Ny/TuWJacekLTJw1Njc9Zc/uba+tNNGtuL82a26q25tp6E82a26vG5hrV+JxrbIapoNMf4g856O5Sz+fQ1WrdysubPmHkJl53btMnAAAAwJS1x/jMpk8YuZ8+ub7pExiBzRvXNH1Cqzzxj3/R9AmtsOvrTxv6n/G0H2cEAAAAAADUzYgAAAAAAAAUPe3PRAAAAAAAgKHo95q+gAF5EwEAAAAAACgyIgAAAAAAAEVGBAAAAAAAoMiIAAAAAAAAFBkRAAAAAACAom7TBwAAAAAAUJler+kLGJA3EQAAAAAAgCIjAgAAAAAAUGREAAAAAAAAiowIAAAAAABAkREBAAAAAAAo6jZ9AAAAAAAAlen3mr6AAXkTAQAAAAAAKDIiAAAAAAAARUYEAAAAAACgyIgAAAAAAAAUGREAAAAAAIAiIwIAAAAAAFDUbfoAAAAAAAAq0+s1fQED8iYCAAAAAABQZEQAAAAAAACKjAgAAAAAAECREQEAAAAAACgyIgAAAAAAAEXdpg8AAAAAAKAy/V7TFzAgbyIAAAAAAABFRgQAAAAAAKDIiAAAAAAAABQZEQAAAAAAgCI/WJlfysTrzm36hJFbv/qvmj5h5Ga+/MSmTwAAAHhG2mN8ZtMnjNxPn1zf9AkA7ERGBAAAAAAARqvXa/oCBuTjjAAAAAAAgCIjAgAAAAAAUGREAAAAAAAAiowIAAAAAABAkREBAAAAAAAoMiIAAAAAAABF3aYPAAAAAACgMr1e0xcwIG8iAAAAAAAARUYEAAAAAACgyIgAAAAAAAAUGREAAAAAAIAiIwIAAAAAAFDUbfoAAAAAAAAq0+81fQED8iYCAAAAAABQZEQAAAAAAACKjAgAAAAAAECREQEAAAAAACgyIgAAAAAAAEVGBAAAAAAAoKjb9AEAAAAAAFSm12v6AgbkTQQAAAAAAKDIiAAAAAAAABQZEQAAAAAAgCIjAgAAAAAAUGREAAAAAAAAirpNHwAAAAAAQGX6vaYvYEDeRAAAAAAAAIqMCAAAAAAAQJERAQAAAAAAKDIiAAAAAAAARUYEAAAAAACgqNv0AQAAAAAAVKbXa/oCBtSqNxE6nU6uuvLi3HXnitz+hRtzwAH7N33S0Gluf/PXH3wop11waZLkG9/5bn7rfRfllPMuzrJrPp1ei/9lW9tzTuprrq030ay5vTRrbqvammvrTTRrbr/Zhx+SWz57fdNnjESNz1lzHc0wFezQiPDkk09m48aNw7rllzZ//nEZH5+RI+e+OYsWL8tlly5p+qSh09zu5r+46db80RWfzIZNm5IkS6+6Ln9w5oJcd8n5mdht13xu5d0NXzg8NT3nLWprrq030ay5vTRrbqvammvrTTRrbrf3LDwjH7nig5kxPqPpU0aixuesuY5mmAq2OSJ8//vfzzvf+c4sWbIkX/7yl3P88cfn+OOPzx133DGq+3bIka+dk8/f9p+33X3PfTls9iENXzR8mtvd/Pzn7pkPL3rX1q8f+fGjOfQlByZJDn3JQfnnb3y7qdOGrqbnvEVtzbX1Jpo1t5dmzW1VW3NtvYlmze328MPfy6lvf3fTZ4xMjc9Zcx3NMBVsc0RYtGhRTj311LzqVa/K2WefnRtvvDE333xzrrnmmlHdt0Nm7T6Rxx9bu/XryclexsbGGrxo+DS3u3nerx+e7lPanvfcPfO1f3kwSbLynvvzxJMbmjpt6Gp6zlvU1lxbb6I50dxWmjW3VW3NtfUmmhPNbfb3K27Lpk2bmz5jZGp8zprraIapYJs/WHnz5s2ZM2dOkuTuu+/Os5/97P/8Td2p+fOY1z6+LhOzJrZ+PW3atExOTjZ40fBprqN5i6ULT8sl1/5lln/m1rzsoBdml+nTmz5paGp8zrU119abaE40t5VmzW1VW3NtvYnmRDPtUeNz1lxHM0wF23wT4YUvfGEWL16cXq+Xiy++OEny53/+53nOc54zkuN21Je+cm/edNzRSZIj5szO6tXfbPii4dNcR/MWq772QJaefWqu+sA5eWzturzmVS9t+qShqfE519ZcW2+iWXN7adbcVrU119abaNZMm9T4nDXX0QxTwTZfKbjooovyxS9+MdOm/dfWsNdee+Wkk04a+mG/iJtvvjXHvHFuVq28JZ1OJ6ef+d6mTxo6zXU0b7HfPnvlXRf+WcZn7JJXv+LgHHV4ez/7r8bnXFtzbb2JZs3tpVlzW9XWXFtvolkzbVLjc9ZcR3Or9XtNX8CAOv1+vz+sb97dZd9hfWtozPrVf9X0CSM38+UnNn0CAADAM9Ie4zObPmHkfvrk+qZPgKHYvHFN0ye0yhOf+VDTJ7TCrm9dNPQ/Y5sfZwQAAAAAANTLiAAAAAAAABQZEQAAAAAAgCIjAgAAAAAAUNRt+gAAAAAAACrT6zV9AQPyJgIAAAAAAFBkRAAAAAAAAIqMCAAAAAAAQJERAQAAAAAAKDIiAAAAAAAARd2mDwAAAAAAoDK9XtMXMCBvIgAAAAAAAEVGBAAAAAAAoMiIAAAAAAAAFBkRAAAAAACAIiMCAAAAAABQZEQAAAAAAACKuk0fAAAAAABAZfr9pi9gQN5EAAAAAAAAiowIAAAAAABAkREBAAAAAAAoMiIAAAAAAABFRgQAAAAAAKCo2/QBAAAAAABUptdr+gIG5E0EAAAAAACgyIgAAAAAAAAUGREAAAAAAIAiIwIAAAAAAFBkRAAAAAAAAIqMCAAAAAAAQFG36QMAAAAAAKhMr9f0BQzImwgAAAAAAECRNxFgB818+YlNnzBy61Ze3vQJIzfxunObPgEAAGiBnz65vukTAOCX4k0EAAAAAACgyIgAAAAAAAAUGREAAAAAAIAiPxMBAAAAAIDR6veavoABeRMBAAAAAAAoMiIAAAAAAABFRgQAAAAAAKDIiAAAAAAAABQZEQAAAAAAgKJu0wcAAAAAAFCZXq/pCxiQNxEAAAAAAIAiIwIAAAAAAFBkRAAAAAAAAIqMCAAAAAAAQJERAQAAAAAAKDIiAAAAAAAARd2mDwAAAAAAoDL9ftMXMCBvIgAAAAAAAEVGBAAAAAAAoMiIAAAAAAAAFBkRAAAAAACAIiMCAAAAAABQ1G36AAAAAAAAKtPrNX0BA/ImAgAAAAAAUGREAAAAAAAAiowIAAAAAABAkREBAAAAAABa6oEHHshJJ52UJPnJT36Ss846K7/927+dBQsW5Hvf+952f78frAwAAAAAAC107bXXZsWKFdl1112TJJdddllOOOGEHH/88fnqV7+ahx56KPvtt982v4c3EQAAAAAAGK1ez6+d8Ws79ttvv1xxxRVbv77vvvvyyCOP5NRTT83f/d3fZc6cOdv9HkYEAAAAAABooWOPPTbd7n99INGaNWuy++6755Of/GT23nvvXHvttdv9HkYEAAAAAACowB577JGjjz46SXL00Udn9erV2/09RgQAAAAAAKjAYYcdlpUrVyZJ7r333hx44IHb/T1GBAAAAAAAqMB5552XW265JQsWLMiqVavye7/3e9v9Pa0aETqdTq668uLcdeeK3P6FG3PAAfs3fdLQadbcRl//9x/k9GXLkyTf+u6P8val1+aUD34iSz5xc3oD/MCYZ6rannNtvYlmze2lWXNb1dZcW2+iWXN7adbcVjU2w87wvOc9L3/913+dJNl3332zfPny3HDDDfn4xz+eZz3rWdv9/QOPCD/5yU9+8StHZP784zI+PiNHzn1zFi1elssuXdL0SUOnWXPbLP/cXblw+Yps2LQ5SXL1LSvzjvmvy3WLT8+mTZO584FvN3zh8NT0nJP6ehPNmttLs+a2qq25tt5Es+b20qy5rWpshqngaUeEhx9++Od+nXXWWVv/56nqyNfOyedvuyNJcvc99+Ww2Yc0fNHwadbcNs/f81fzp+8+cevXB7/guXls/RPp9/tZ/+SGTB9r1QtUP6em55zU15to1txemjW3VW3NtfUmmjW3l2bNbVVjc6v1e37tjF8j0H26v/E7v/M7GR8fz6/92q+l3+/n4YcfzpIlS9LpdPKpT31qJMftqFm7T+Txx9Zu/XpyspexsbFMTk42eNVwadbcNse8+qVZ8x+Pbv36BXs9Ox+6/rO5dsWdmdhtPIcfvH9zxw1ZTc85qa830ZxobivNmtuqtubaehPNiea20qy5rWpshqngaf8rvTfddFMOPPDAvOMd78j111+fgw8+ONdff/2UHRCSZO3j6zIxa2Lr19OmTWv9v0Q0a267Sz59a5YvOi23XPyenPDaV+ZPbrit6ZOGprbnXFtvojnR3FaaNbdVbc219SaaE81tpVlzW9XYDFPB044Iz372s/ORj3wk//iP/5irr756lDf9wr70lXvzpuOOTpIcMWd2Vq/+ZsMXDZ9mzW33rJm7ZmJ8RpJkz1+Zlcd/9kTDFw1Pbc+5tt5Es+b20qy5rWprrq030ay5vTRrbqsam2EqeNqPM0qSbrebxYsX5zOf+Uz6/f6obvqF3XzzrTnmjXOzauUt6XQ6Of1dlXK9AAAgAElEQVTM9zZ90tBp1tx2HzjtzTnvY3+TsbFpmd4dy5JTT2j6pKGp7TnX1pto1txemjW3VW3NtfUmmjW3l2bNbVVjM0wFnf4Q14HuLvsO61sDI7Ru5eVNnzByE687t+kTAAAAgClk88Y1TZ/QKk98/H1Nn9AKu57xp0P/M7b5JgIAAAAAAOxs/d7U/+Qb/tPT/kwEAAAAAACgbkYEAAAAAACgyIgAAAAAAAAUGREAAAAAAIAiIwIAAAAAAFDUbfoAAAAAAAAq0+s1fQED8iYCAAAAAABQZEQAAAAAAACKjAgAAAAAAECREQEAAAAAACgyIgAAAAAAAEVGBAAAAAAAoKjb9AEAAAAAAFSm32v6AgbkTQQAAAAAAKDIiAAAAAAAABQZEQAAAAAAgCIjAgAAAAAAUGREAAAAAAAAirpNHwAAAAAAQGV6/aYvYEDeRAAAAAAAAIqMCAAAAAAAQJERAQAAAAAAKDIiAAAAAAAARUYEAAAAAACgyIgAAAAAAAAUdZs+AAAAAACAyvR6TV/AgLyJAAAAAAAAFBkRAAAAAACAIiMCAAAAAABQZEQAAAAAAACKjAgAAAAAAEBRt+kDgKlv4nXnNn3CyD3xw1VNnzByu+5zVNMnAAAAALXo9Zq+gAF5EwEAAAAAACgyIgAAAAAAAEVGBAAAAAAAoMiIAAAAAAAAFBkRAAAAAACAom7TBwAAAAAAUJl+v+kLGJA3EQAAAAAAgCIjAgAAAAAAUGREAAAAAAAAiowIAAAAAABAkREBAAAAAAAoMiIAAAAAAABF3aYPAAAAAACgMr1e0xcwIG8iAAAAAAAARUYEAAAAAACgyIgAAAAAAAAUGREAAAAAAIAiIwIAAAAAAFDUbfoAAAAAAAAq0+s3fQED8iYCAAAAAABQZEQAAAAAAACKjAgAAAAAAECREQEAAAAAACgyIgAAAAAAAEXdpg8AAAAAAKAy/V7TFzAgbyIAAAAAAABFRgQAAAAAAKDIiAAAAAAAABQZEQAAAAAAgCIjAgAAAAAAUGREAAAAAAAAirpNHwAAAAAAQGV6/aYvYEDeRAAAAAAAAIpaNSJ0Op1cdeXFuevOFbn9CzfmgAP2b/qkodOsua1qad60eXPOX3pZTj7r3Cw4Y2HuWPXVfO8HP8xJZ70/J591bpZedkV6vV7TZw5FLc/4qTRrbivNmtuqtubaehPNmttLs+a2qrEZpoKBR4Rer5dHHnlkSv+HWfPnH5fx8Rk5cu6bs2jxslx26ZKmTxo6zZrbqpbmv//8F7PH7rPyqY9dnqv/5I/zwQ9/NJf+rz/Pe848JZ/62OXp95MvrvpK02cORS3P+Kk0a24rzZrbqrbm2noTzZrbS7PmtqqxGaaCbY4IixYtSpI88MADOfbYY/Pud787v/mbv5n7779/JMftqCNfOyefv+2OJMnd99yXw2Yf0vBFw6dZc1vV0nzsG47Ke848eevX3bGxfOPB7+TVr3pFkuSo1xyer35tav4795dVyzN+Ks2a20qz5raqrbm23kSz5vbSrLmtamyGqWCbI8IPfvCDJMmHP/zhXHvttbnxxhuzfPnyXH755SM5bkfN2n0ijz+2duvXk5O9jI2NNXjR8GnW3Fa1NO+2266ZOXO3rF//s7x38QfznjNPTr/fT6fTSZLM3G3XrF23vuErh6OWZ/xUmjW3lWbNbVVbc229ieZEc1tp1txWNTbDVNAd5B8aGxvL/vvvnyTZa6+9puxHGq19fF0mZk1s/XratGmZnJxs8KLh06y5rWpq/tEj/5GFF/xxFrz1N/Ib//MN+dOPfmLr31v/syey+8TENn73M1dNz3gLzZrbSrPmtqqtubbeRHOiua00a26rGpvbrD9F/zNm/rttvomwdu3avPWtb82aNWty4403ZsOGDbnwwguzzz77jOq+HfKlr9ybNx13dJLkiDmzs3r1Nxu+aPg0a26rWpp//H8eze++d3He987fyVt/89gkycH/44Dcc9/XkySrvvK1zH7ly5o8cWhqecZPpVlzW2nW3Fa1NdfWm2jW3F6aNbdVjc0wFXT6/X5/W//Axo0b861vfSvj4+PZf//9c9NNN+Vtb3tbpk+fvt1v3t1l35126CA6nU6uvGJZDnnFS9LpdHL6me/Ngw/++0hvGDXNmtuq6eYnfrhqJH/Oso9cnf99+5154Quet/Wvnb/w93LxRz6WTZs254X7Pz8XnrdwJK9n7rrPUUP/M56q6WfcBM2a20qz5raqrbm23kSz5vbSrLmtmm7evHHNyP6sGqxfdkrTJ7TCzAuuG/qfsd0R4Zcx6hEBYGcZ1YgwlYx6RAAAAIBnEiPCzmVE2DlGMSJs8+OMAAAAAACAehkRAAAAAACAIiMCAAAAAABQ1G36AAAAAAAAKtMb2o/qZSfzJgIAAAAAAFBkRAAAAAAAAIqMCAAAAAAAQJERAQAAAAAAKDIiAAAAAAAARd2mDwAAAAAAoDL9XtMXMCBvIgAAAAAAAEVGBAAAAAAAoMiIAAAAAAAAFBkRAAAAAACAIiMCAAAAAABQ1G36AAAAAAAAKtPrN30BA/ImAgAAAAAAUGREAAAAAAAAiowIAAAAAABAkREBAAAAAAAoMiIAAAAAAABFRgQAAAAAAKCo2/QBAAAAAABUptdr+gIG5E0EAAAAAACgyIgAAAAAAAAUGREAAAAAAIAiIwIAAAAAAFBkRAAAAAAAAIq6TR8AAAAAAEBlev2mL2BA3kQAAAAAAACKjAgAAAAAAECREQEAAAAAACjyMxEACnbd56imTxi5J364qukTRq7G5wwAAACwI7yJAAAAAAAAFHkTAQAAAACA0er3mr6AAXkTAQAAAAAAKDIiAAAAAAAARUYEAAAAAACgyIgAAAAAAAAUGREAAAAAAIAiIwIAAAAAAFDUbfoAAAAAAAAq0+s3fQED8iYCAAAAAABQZEQAAAAAAACKjAgAAAAAAECREQEAAAAAACgyIgAAAAAAAEXdpg8AAAAAAKAu/V6v6RMYkDcRAAAAAACAIiMCAAAAAABQZEQAAAAAAACKjAgAAAAAAECREQEAAAAAACgyIgAAAAAAAEXdpg8AAAAAAKAyvX7TFzAgbyIAAAAAAABFRgQAAAAAAKDIiAAAAAAAABQZEQAAAAAAgCIjAgAAAAAAUNRt+gAAAAAAACrT6zd9AQPyJgIAAAAAAFBkRAAAAAAAAIqMCAAAAAAAQJERAQAAAAAAKDIiAAAAAAAARa0aETqdTq668uLcdeeK3P6FG3PAAfs3fdLQadbcVprb27xp8+acv/SynHzWuVlwxsLcseqr+d4PfpiTznp/Tj7r3Cy97Ir0er2mzxyKWp7xU/1f9u492O6yvvf4d+29ILedGHEQy0VgaJUoggaIYyQgKBIvEEvnqEUCQkgt1EjBVJHE9IBmEm7ikcRQGIsSUZBaCceCoEhD0EjwxFuUZooyWsF6pCC5cEmy1zp/nGaf2PO4s6JZ69k+z+s1s/9YCWR/3/P7R+bjL1uz5lJp1lyi2nojNGsul2bNpaqxuWjtlq/d8dUDRY0IM2ZMj9GjR8Uxx54SF89bFFdcviD3SV2nWXOpNJfb/OW7vh4TJ4yPG5ddGdde9ZFYePUn4/JPXBdzZp8ZNy67MtrtiK+vWp37zK6o5RnvSLPmUmnWXKLaeiM0ay6XZs2lqrEZRoJdGhGeeOKJaLfb3brl93bM1Clx1933RkTEA2vWxpGTD898Ufdp1lwqzeU2n3T8tJgz+4yhz83+/vjR+ofj6Fe9IiIipr3mqPjWt7+b67yuquUZ70iz5lJp1lyi2nojNGsul2bNpaqxGUaCYUeEL37xi7FkyZL44Q9/GNOnT4+zzjorpk+fHt/85jd7dd8uGT9hIDY8tXHo8+BgK/r7+zNe1H2aNZdKc7nNY8eOiXHjxsbmzU/HBfMWxpzZZ0S73Y5GoxEREePGjomNmzZnvrI7annGO9KsuVSaNZeott4IzRGaS6VZc6lqbIaRYNgR4XOf+1ycffbZcfnll8eyZctixYoVceONN8ZVV13Vq/t2ycYNm2Jg/MDQ576+vhgcHMx4Ufdp1lwqzWU3/+KXv4qz5lwUJ08/Id7yxuOjr68x9Hubn34mJgwMDPNv/+Gq6Rlvp1lzqTRrLlFtvRGaIzSXSrPmUtXYDCPBsCPCHnvsEWPHjo1x48bFAQccEBER++yzz9D/W3Sk+cbqB+NN00+IiIhXT5kc69Y9lPmi7tOsuVSay21+/Ikn4y8umBcXnndWnPrWkyIi4tCXHBJr1n4/IiJWrf52TD7i5TlP7JpanvGONGsulWbNJaqtN0Kz5nJp1lyqGpthJGi0h/khB9ddd1185zvfiZe85CWxbt26mDZtWqxatSomTZoUc+fO3ekf3txzv9167M40Go1Ycs2iOPwVk6LRaMSs2RfE+vU/7ukNvaZZc6k09775mcdW9eT7LPr4tfGVe+6Lgw/cf+jXLjr/L2Pxx5fF1q3b4uCDDohLPnh+T15JHbPvtK5/jx3lfsY5aNZcKs2aS1Rbb4RmzeXSrLlUuZu3bXm0Z9+rBpvmzsh9QhEGrlzR9e8x7IgQEbFmzZq4//7748knn4yJEyfGkUceGa973es6+sN7PSIA8Lvr1YgwkvR6RAAAAOAPlxFh99p04Sm5TyjCwMdu7/r3aO7sH5gyZUpMmTKl64cAAAAAAAAjy7A/EwEAAAAAAKiXEQEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIGmnP1gZAAAAAAB2p3arnfsEOuRNBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSmrkPAAAAAACgMq127gvokDcRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAEnN3AcAAAAAAFCZViv3BXTImwgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJDVzHwAAAAAAQGVa7dwX0CFvIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQ1Mx9AAAAAAAAlWm1c19Ah7yJAAAAAAAAJHkTAYCIiBiz77TcJ/TcM4+tyn1Cz9X4nAEAAIDfnTcRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSjAgAAAAAAECSH6wMAAAAAEBPtdvt3CfQIW8iAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJDUzH0AAAAAAACVabVzX0CHvIkAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJBkRAAAAAAAAJKMCAAAAAAAQJIRAQAAAAAASGrmPgAAAAAAgMq02rkvoEPeRAAAAAAAAJKMCAAAAAAAQJIRAQAAAAAASDIiAAAAAAAASUYEAAAAAAAgqZn7AAAAAAAA6tJutXOfQIe8iQAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkowIAAAAAABAUjP3AQAAAAAAVKbVzn0BHfImAgAAAAAAkGREAAAAAAAAkowIAAAAAABAUlEjQqPRiKVLFsf9990e93z11jjkkINyn9R1mjWXSnP5zbX0bt22LS669Io449y58c5zzo97V30rfvbzx2Lmue+PM86dG5decU20Wq3cZ3ZNLc95R5o1l0pz+c219UZo1lwuzZpLVWMzjARFjQgzZkyP0aNHxTHHnhIXz1sUV1y+IPdJXadZc6k0l99cS++X7/p6TJwwPm5cdmVce9VHYuHVn4zLP3FdzJl9Zty47MpotyO+vmp17jO7ppbnvCPNmkulufzm2nojNGsul2bNpaqxGUaCYUeETZs29eqO3eKYqVPirrvvjYiIB9asjSMnH575ou7TrLlUmstvrqX3pOOnxZzZZwx9bvb3x4/WPxxHv+oVEREx7TVHxbe+/d1c53VdLc95R5o1l0pz+c219UZo1lwuzZpLVWMzjATDjgivfe1r49Zbb+3VLb+38RMGYsNTG4c+Dw62or+/P+NF3adZc6k0l99cS+/YsWNi3LixsXnz03HBvIUxZ/YZ0W63o9FoRETEuLFjYuOmzZmv7J5anvOONGsulebym2vrjdAcoblUmjWXqsbmorV87ZavHhh2RDj00EPjoYceijPOOCPWrFnTm4t+Dxs3bIqB8QNDn/v6+mJwcDDjRd2nWXOpNJffXFPvL375qzhrzkVx8vQT4i1vPD76+hpDv7f56WdiwsDAMP/2H7aanvN2mjWXSnP5zbX1RmiO0FwqzZpLVWMzjATDjgijRo2KBQsWxN/8zd/E8uXL461vfWssXLgwbrzxxl7dt0u+sfrBeNP0EyIi4tVTJse6dQ9lvqj7NGsulebym2vpffyJJ+MvLpgXF553Vpz61pMiIuLQlxwSa9Z+PyIiVq3+dkw+4uU5T+yqWp7zjjRrLpXm8ptr643QrLlcmjWXqsZmGAka7Xa7/dt+c+bMmbF8+fKhzxs3bowHH3wwHnnkkZg1a9ZO//Dmnvvtnis71Gg0Ysk1i+LwV0yKRqMRs2ZfEOvX/7inN/SaZs2l0lx+80jofeaxVV3/Hos+fm185Z774uAD9x/6tYvO/8tY/PFlsXXrtjj4oAPikg+e37NXcMfsO60n32e7kfCce02z5lJpLr+5tt4IzZrLpVlzqXI3b9vyaM++Vw2emvn63CcU4XnL7+n69xh2RPjSl74Uf/qnf/o7/+G9HhEAYFf0YkQYaXo9IgAAAJTCiLB7GRF2j16MCMP+dUa/z4AAAAAAAAD8YWvmPgAAAAAAgLq0W7/1L8hhhBn2TQQAAAAAAKBeRgQAAAAAACDJiAAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkNTMfQAAAAAAAJVptXNfQIe8iQAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIauY+AAAAAACAyrRyH0CnvIkAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJBkRAAAAAAAAJKMCAAAAAAAQFIz9wEAAAAAANSl3WrnPoEOeRMBAAAAAABIMiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkNTMfQAAAAAAAJVp5T6ATnkTAQAAAAAASDIiAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkGREAAAAAAICkZu4DAEaiiaPH5T6h53797ObcJ/TcmH2n5T6h5zavuyX3CT037rB35D4BAACA/6Ldauc+gQ55EwEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACApGbuAwAAAAAAqEwr9wF0ypsIAAAAAABAkhEBAAAAAABIMiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQZEQAAAAAAgKRm7gMAAAAAAKhLu5X7AjrlTQQAAAAAACDJiAAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkpq5DwAAAAAAoDKt3AfQKW8iAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJDUzH0AAAAAAAB1abdyX0CnvIkAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJBkRAAAAAAAAJKMCAAAAAAAQJIRAQAAAAAASGrmPgAAAAAAgMq0ch9Ap4p6E6HRaMTSJYvj/vtuj3u+emsccshBuU/qOs2aS1Vjc0TE5KMOjxX/tDz3GT1R4zOurfn7638SZ3/o8oiI+NHDP43TLvxonPnBxbHo726KVqvc/7VY23OO0Ky5XLU119YboVlzuTRrLlWNzTASFDUizJgxPUaPHhXHHHtKXDxvUVxx+YLcJ3WdZs2lqrF5zvnnxMevWRijRo/KfUpP1PiMa2r++y/eGf/9mk/Hc1u3RkTEpUs/Ex+Y/c74zGUXxcDYMXHHygcyX9g9NT3n7TRrLlVtzbX1RmjWXC7NmktVYzOMBLs0ImzZsiWeffbZbt3yeztm6pS46+57IyLigTVr48jJh2e+qPs0ay5Vjc2PPPKzePfp7819Rs/U+Ixraj7gRXvH1Rf/1dDnXz7+ZLxy0h9HRMQrJ/1JfOdH/5rrtK6r6Tlvp1lzqWprrq03QrPmcmnWXKoam2EkGHZEeOSRR+J973tfvP/974/vfve7cfLJJ8db3vKWuOOOO3p13y4ZP2EgNjy1cejz4GAr+vv7M17UfZo1l6rG5i/ffnds3bot9xk9U+Mzrqn5xNceFc0d2vZ/0d7x7R+sj4iIlWu+G888+1yu07qupue8nWbNpaqtubbeCM0RmkulWXOpamyGkWDYH6z84Q9/OM4777zYuHFjvOc974nbb789xo8fH2eddVa8+c1v7tWNHdu4YVMMjB8Y+tzX1xeDg4MZL+o+zZpLVWNzbWp8xjU2b3fp+WfHZdd/Pm74xzvj5X9ycOy5xx65T+qaGp+zZs2lqq25tt4IzRGaS6VZc6lqbIaRYNg3EbZt2xZTp06NN77xjTFx4sTYZ599YuzYsdFsDrs9ZPON1Q/Gm6afEBERr54yOdateyjzRd2nWXOpamyuTY3PuMbm7VZ9+3tx6fveHUv/9q/jqY2b4jWvelnuk7qmxuesWXOpamuurTdCs+ZyadZcqhqbS9Zu+dodX70w7Bqw3377xQUXXBCDg4Mxbty4uPrqq2NgYCD23nvv3ly3i2677c54w+uPjVUrV0Sj0YhZsy/IfVLXadZcqhqba1PjM66xebsX77tP/NUl/yNGj9ozjn7FoTHtqHL/7tIan7NmzaWqrbm23gjNmsulWXOpamyGkaDRbrfbv+03t23bFitXroyDDjooxo0bF5/+9Kfjec97Xpx55pkxduzYnf7hzT33263HAvTKxNHjcp/Qc79+dnPuE+iBzetuyX1Cz4077B25TwAAAAqwbcujuU8oyq9OPC73CUXY+6sru/49hn0Todlsxutf//qhzxdddFHXDwIAAAAAAEaGYX8mAgAAAAAAUC8jAgAAAAAAkGREAAAAAAAAkob9mQgAAAAAALC7tVu5L6BT3kQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIKmZ+wAAAAAAAOrSbuW+gE55EwEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAAC91W742h1fHfje974XM2fOjIiIhx56KE477bSYOXNmzJo1Kx5//PGd/vtGBAAAAAAAKND1118f8+fPj+eeey4iIhYuXBgf/vCHY/ny5XHiiSfG9ddfv9M/w4gAAAAAAAAFevGLXxzXXHPN0OePfexjMWnSpIiIGBwcjFGjRu30zzAiAAAAAABAgU466aRoNptDn1/4whdGRMTatWvjs5/9bLz73e/e6Z/R3Ok/AQAAAAAAFOGOO+6IZcuWxXXXXRd77bXXTv95IwIAAAAAAFRgxYoVccstt8Ty5ctj4sSJHf07RgQAAAAAACjc4OBgLFy4MP7oj/4o5syZExERRx99dLzvfe8b9t8zIgAAAAAA0FPtVu4L6rH//vvHF77whYiIWLNmzS7/+36wMgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIMiIAAAAAAABJzdwHAAAAAABQl3arkfsEOuRNBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJD8TASDh189uzn0CdMW4w96R+4Se27Tyytwn9NTAcXNznwAAUJ2Jo8flPqHn/Hcz1MObCAAAAAAAQJI3EQAAAAAA6Kl2K/cFdMqbCAAAAAAAQJIRAQAAAAAASDIiAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkGREAAAAAAICkZu4DAAAAAACoS7vdyH0CHfImAgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIMiIAAAAAAABJzdwHAAAAAABQl3Yr9wV0ypsIAAAAAABAkhEBAAAAAABIMiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQ1cx8AAAAAAEBd2q1G7hPokDcRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAEnN3AcAAAAAAFCXdjv3BXTKmwgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIKmoEaHRaMTSJYvj/vtuj3u+emsccshBuU/qOs2aS6W5/ObaeiM019D8/R//PGYtuiEiIv7lp7+I0y+9Ps5c+KlY8KnbotVqZb6ue2p7zhGaNZeptt4IzZrLpbmO5oiIyUcdHiv+aXnuM3qm1ucMuRU1IsyYMT1Gjx4Vxxx7Slw8b1FccfmC3Cd1nWbNpdJcfnNtvRGaS2++4Y7745Ibbo/ntm6LiIhrV6yM98w4Lj4zb1Zs3ToY933vXzNf2D01PeftNGsuUW29EZo1l0tzHc1zzj8nPn7Nwhg1elTuU3qmxudcsnar4Ws3fPVCxyNCu93u5h27xTFTp8Rdd98bEREPrFkbR04+PPNF3adZc6k0l99cW2+E5tKbD9h7r/jYe98x9PnQA18UT21+Jtrtdmx+9rnYo7+o/+/Gb6jpOW+nWXOJauuN0Ky5XJrraH7kkZ/Fu09/b+4zeqrG5wwjwbD/Nfuzn/0sZs2aFccff3wcdthh8fa3vz3e//73x69+9ate3bdLxk8YiA1PbRz6PDjYiv7+/owXdZ9mzaXSXH5zbb0RmiPKbn7D0S+L5g5DwYH7vCAuu+nOeNuHlsR/bNgcRx16UL7juqym57ydZs0lqq03QnOE5lJprqP5y7ffHVv/8y3YWtT4nGEkGHZEuOSSS2L+/Plx7733xk033RRTp06Ns846K+bNmzbUnXgAACAASURBVNer+3bJxg2bYmD8wNDnvr6+GBwczHhR92nWXCrN5TfX1huhOaKO5u0uu+nOuOHis2PF4jlx8tQj4qqb7859UtfU+Jw1ay5Rbb0RmiM0l0pzHc018pwhj2FHhE2bNsXBBx8cERGvfOUrY+3atXHYYYfFhg0benLcrvrG6gfjTdNPiIiIV0+ZHOvWPZT5ou7TrLlUmstvrq03QnMtzds9b9yYGPjPv5927+ePjw1PP5P5ou6p8Tlr1lyi2nojNGsul+Y6mmvkOUMezeF+c//9948FCxbEscceG//8z/8ckyZNirvvvjvGjBnTq/t2yW233RlveP2xsWrlimg0GjFr9gW5T+o6zZpLpbn85tp6IzTX0rzd3559Snxw2T9Ef39f7NHsjwXvPjn3SV1T43PWrLlEtfVGaNZcLs11NNfIc4Y8Gu1hfmLyli1b4tZbb42HH344Jk2aFH/2Z38WP/jBD+LAAw+M5z//+Tv9w5t77rdbjwUA2FWbVl6Z+4SeGjhubu4TAACqM3H0uNwn9Nyvn92c+4Se27bl0dwnFOWnk9+Q+4QiHLj2a13/HsO+ibDnnnvGu971rt/4tVe+8pVdPQgAAAAAgLK1W43cJ9ChYX8mAgAAAAAAUC8jAgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIauY+AAAAAACAurTbuS+gU95EAAAAAAAAkowIAAAAAABAkhEBAAAAAABIMiIAAAAAAABJRgQAAAAAACCpmfsAAAAAAADq0m41cp9Ah7yJAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEhq5j4AAAAAAIC6tNuN3CfQIW8iAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJDUzH0AAAAAAAB1abdyX0CnvIkAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJBkRAAAAAAAAJKMCAAAAAAAQFIz9wEAAAAAANSl1W7kPoEOeRMBAAAAAABI8iYCAFC0gePm5j6hp555bFXuE3puzL7Tcp8AAFTu189uzn0CQNd4EwEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJPnBygAAAAAA9FS73ch9Ah3yJgIAAAAAAJBkRAAAAAAAAJKMCAAAAAAAQJIRAQAAAAAASDIiAAAAAAAASc3cBwAAAAAAUJd2q5H7BDrkTQQAAAAAACDJiAAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkowIAAAAAABAUjP3AQAAAAAA1KXdzn0BnfImAgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIMiIAAAAAAABJzdwHAAAAAABQl3arkfsEOuRNBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSmrkPAAAAAACgLq12I/cJdMibCAAAAAAAQJIRAQAAAAAASDIiAAAAAAAASUWNCI1GI5YuWRz333d73PPVW+OQQw7KfVLXadZcKs3lN9fWG6FZc1m2btsWF116RZxx7tx45znnx72rvhU/+/ljMfPc98cZ586NS6+4JlqtVu4zu6aW57wjzeU319YboVlzuTRrLlWNzTASFDUizJgxPUaPHhXHHHtKXDxvUVxx+YLcJ3WdZs2l0lx+c229EZo1l+XLd309Jk4YHzcuuzKuveojsfDqT8bln7gu5sw+M25cdmW02xFfX7U695ldU8tz3pHm8ptr643QrLlcmjWXqsZmGAmKGhGOmTol7rr73oiIeGDN2jhy8uGZL+o+zZpLpbn85tp6IzRrLstJx0+LObPPGPrc7O+PH61/OI5+1SsiImLaa46Kb337u7nO67panvOONJffXFtvhGbN5dKsuVQ1NsNIUNSIMH7CQGx4auPQ58HBVvT392e8qPs0ay6V5vKba+uN0ByhuSRjx46JcePGxubNT8cF8xbGnNlnRLvdjkajERER48aOiY2bNme+sntqec470lx+c229EZojNJdKs+ZS1dhcsna74Ws3fPVCc2f/wNe+9rVYvXp1bNy4MSZMmBBHHnlkTJ8+feg/EEeSjRs2xcD4gaHPfX19MTg4mPGi7tOsuVSay2+urTdCc4Tm0vzil7+K8z/0kXjnqW+Jt7zx+PjYJz819Hubn34mJgwMDPNv/2Gr6Tlvp7n85tp6IzRHaC6VZs2lqrEZRoJh30S45JJLYtWqVTF16tQ49dRT4zWveU1861vfivnz5/fqvl3yjdUPxpumnxAREa+eMjnWrXso80Xdp1lzqTSX31xbb4RmzWV5/Ikn4y8umBcXnndWnPrWkyIi4tCXHBJr1n4/IiJWrf52TD7i5TlP7KpanvOONJffXFtvhGbN5dKsuVQ1NsNI0Gi32+3f9punn356fPazn/3/fv2d73xn3HzzzTv9w5t77vf7XbeLGo1GLLlmURz+iknRaDRi1uwLYv36H/f0hl7TrLlUmstvrq03QrPm3njmsVU9+T6LPn5tfOWe++LgA/cf+rWLzv/LWPzxZbF167Y4+KAD4pIPnt+T18vH7Dut69/jv8r9nHPQXH5zbb0RmjWXS7PmUuVu3rbl0Z59rxr84OCTc59QhFc88j+7/j2GHRFOO+20uPDCC+Ooo44a+rUHH3wwPvGJT8Ty5ct3+of3ekQAAKhdr0aEkSTHiAAAQH2MCLuXEWH36MWIMOzPRFi8eHEsWrQoLrzwwmi329HX1xcve9nL4iMf+UjXDwMAAAAAAPIadkR48YtfHMuWLevVLQAAAAAAVOC3//04jDTDjggzZ86MrVu3Jn+vk5+JAAAAAAAA/OEadkSYO3duzJ8/P5YuXdqTH4oHAAAAAACMHMOOCEcccUTMmDEj1q9fHyeeeGKvbgIAAAAAAEaAYUeEiIhzzjmnF3cAAAAAAAAjTF/uAwAAAAAAgJFpp28iAAAAAADA7tRqN3KfQIe8iQAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIauY+AAAAAACAurTbjdwn0CFvIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQ1Mx9AAAAAAAAdWm3c19Ap7yJAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEhq5j4AAAAAAIC6tNqN3CfQIW8iAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkP1gZAKAgY/adlvuEntu47M9zn9Bz48/9fO4TAACAShgRAAAAAADoqXa7kfsEOuSvMwIAAAAAAJKMCAAAAAAAQJIRAQAAAAAASDIiAAAAAAAASUYEAAAAAAAgqZn7AAAAAAAA6tJqN3KfQIe8iQAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIauY+AAAAAACAurRzH0DHvIkAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJBkRAAAAAAAAJKMCAAAAAAAQFIz9wEAAAAAANSl1W7kPoEOeRMBAAAAAABIMiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQZEQAAAAAAgKRm7gMAAAAAAKhLu93IfQId8iYCAAAAAACQZEQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIKmZ+wAAAAAAAOrSyn0AHSvqTYRGoxFLlyyO+++7Pe756q1xyCEH5T6p6zRrLpXm8ptr643QrLlctTX/4LEnY9bnvxkREU9sfi7++h/XxNmf+0acedP98W9Pbs58XffU9pwj6muurTdCs+ZyadZcqhqbYSQoakSYMWN6jB49Ko459pS4eN6iuOLyBblP6jrNmkulufzm2nojNGsuV03NNzzwcFzyle/Flm2DERFx9cofxZtetn/8/Wmvjfcec2g88sSmzBd2T03PebvammvrjdCsuVyaNZeqxmYYCYoaEY6ZOiXuuvveiIh4YM3aOHLy4Zkv6j7Nmkulufzm2nojNGsuV03NB0wcG1e97aihz9/9+ZPxvzc+E++5ZXXc8aNH4+gDXpDxuu6q6TlvV1tzbb0RmjWXS7PmUtXYDCNBUSPC+AkDseGpjUOfBwdb0d/fn/Gi7tOsuVSay2+urTdCc4TmUtXU/IaX7hvN/v/3P6F/seHpGD96j/i7d7wmXjRhTNzwwMMZr+uump7zdrU119YboTlCc6k0ay5Vjc0wEhQ1ImzcsCkGxg8Mfe7r64vBwcGMF3WfZs2l0lx+c229EZojNJeqxubtnjdmz3jdH78oIiKO++N94oe/fCrzRd1T43Ourbm23gjNEZpLpVlzqWpshpFg2BHhlltu+a1fI9E3Vj8Yb5p+QkREvHrK5Fi37qHMF3WfZs2l0lx+c229EZo1l6vG5u1etd9ecf9PfhkREf/r3/4jDnnB+MwXdU+Nz7m25tp6IzRrLpdmzaWqsblk7Wj42g1fvdAc7jd/8pOfxL333hunnHJKT475fd12253xhtcfG6tWrohGoxGzZl+Q+6Su06y5VJrLb66tN0Kz5nLV2Lzdhce/LC75yvfiC9/5aYwf1YxFJ0/OfVLX1Pica2uurTdCs+ZyadZcqhqbYSRotNvt9nD/wOzZs2POnDlx+OG7/oNKmnvu9zsfBgAAndi47M9zn9Bz48/9fO4TAACqs23Lo7lPKMp9L/pvuU8owrH/fmvXv8ewbyJERFx22WXx9NNPd/0QAAAAAABgZNnpiLDXXnvFXnvt1YtbAAAAAACAEWTYEWHmzJmxdevW3/i1drsdjUYjbr755q4eBgAAAAAA5DXsiDB37tyYP39+LF26NPr7+3t1EwAAAAAABWsN+5N6GUmGHRGOOOKImDFjRqxfvz5OPPHEXt0EAAAAAACMADv9mQjnnHNOL+4AAAAAAABGmL7cBwAAAAAAACOTEQEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIGmnP1gZAAAAAAB2p1Y0cp9Ah7yJAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSjAgAAAAAAEBSM/cBAAAAAADUpR2N3CfQIW8iAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJBkRAAAAAAAAJKauQ8AAAAAAKAurdwH0DFvIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQ1Mx9AAAAAAAAdWlHI/cJdMibCAAAAAAAQJIRAQAAAAAASPLXGQEA8Adt/Lmfz31Cz21aeWXuE3pu4Li5uU8AAIAqeRMBAAAAAABIMiIAAAAAAABJ/jojAAAAAAB6qpX7ADrmTQQAAAAAACDJiAAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkowIAAAAAABAUjP3AQAAAAAA1KWV+wA65k0EAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJBkRAAAAAAAAJKauQ8AAAAAAKAu7WjkPoEOeRMBAAAAAABIMiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQZEQAAAAAAgKRm7gMAAAAAAKhLq5H7AjrlTQQAAAAAACDJiAAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkowIAAAAAABAUjP3AQAAAAAA1KUVjdwn0CFvIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACApKJGhEajEUuXLI7777s97vnqrXHIIQflPqnrNGsulebym2vrjdCsuVyay2/+/o9/HrMW3RAREf/y01/E6ZdeH2cu/FQs+NRt0Wq1Ml/XPbU959p6IzRrLpdmzaWqsRlGgqJGhBkzpsfo0aPimGNPiYvnLYorLl+Q+6Su06y5VJrLb66tN0Kz5nJpLrv5hjvuj0tuuD2e27otIiKuXbEy3jPjuPjMvFmxdetg3Pe9f818YffU9Jwj6uuN0Ky5XJo1l6rG5pK1fe2Wr14oakQ4ZuqUuOvueyMi4oE1a+PIyYdnvqj7NGsulebym2vrjdCsuVyay24+YO+94mPvfcfQ50MPfFE8tfmZaLfbsfnZ52KP/qL+k+I31PScI+rrjdCsuVyaNZeqxmYYCYr6X/zjJwzEhqc2Dn0eHGxFf39/xou6T7PmUmkuv7m23gjNEZpLpbns5jcc/bJo7jAUHLjPC+Kym+6Mt31oSfzHhs1x1KEH5Tuuy2p6zhH19UZojtBcKs2aS1VjM4wEw44ITzzxRCxevDiuvvrqePLJJ4d+fcmSJV0/7HexccOmGBg/MPS5r68vBgcHM17UfZo1l0pz+c219UZojtBcKs11NG932U13xg0Xnx0rFs+Jk6ceEVfdfHfuk7qmtudcW2+E5gjNpdKsuVQ1NsNIMOyI8IEPfCAOPvjgeOELXxinn356PProoxERsWbNmp4ct6u+sfrBeNP0EyIi4tVTJse6dQ9lvqj7NGsulebym2vrjdCsuVya62je7nnjxsTA6FEREbH388fHhqefyXxR99T2nGvrjdCsuVyaNZeqxmYYCZrD/eaWLVviHe/4v3//6aRJk+K8886L5cuXR7vdqx/ZsGtuu+3OeMPrj41VK1dEo9GIWbMvyH1S12nWXCrN5TfX1huhWXO5NNfRvN3fnn1KfHDZP0R/f1/s0eyPBe8+OfdJXVPbc66tN0Kz5nJp1lyqGpthJGi0h1kE3vWud8WCBQvipS99aURE3HHHHXHTTTfF008/HV/60pd2+oc399xv910KAABERMSmlVfmPqHnBo6bm/sEAKBy27Y8mvuEotz2otNyn1CEt/3757r+PYb964zmz58fH/3oR+Pxxx+PiIg3v/nN8fa3vz0ee+yxrh8GAAAAAECZWr52y1cvDPsmwm/TarWir2/Y/SEivIkAAADd4E0EAIDe8ybC7vWP3kTYLU7twZsIw/5MhJkzZ8bWrVuTv3fzzTd35SAAAAAAAGBkGHZEmDt3bsyfPz+WLl0a/f39vboJAAAAAAAYAYYdEY444oiYMWNGrF+/Pk488cRe3QQAAAAAAIwAw44IERHnnHNOL+4AAAAAAABGmJ2OCAAAAAAAsDu1Go3cJ9ChvtwHAAAAAAAAI5MRAQAAAAAASDIiAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkNXMfAAAAAABAXdq5D6Bj3kQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIMmIAMD/Ye/ug+wg63uB/87uAfKyCS8tUwa04qTtGFTSBsQpN8BImxoGcat3OryU5TXUWuECZSuRxBSDmQBBipAIl15FpEgqpQNIRVDEECwCDpcqle5VrmINTlsx5o23zZ5z/2iTiXceNie45zzL83w+zM5wssk53+88f8Dy5TkHAAAAAJKauQMAAAAAAFCXVu4AdMxNBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSmrkDAAAAAABQl1YjdwI65SYCAAAAAACQZEQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAEnN3AEAAAAAAKhLKxq5I9AhIwIAALzODBwznDtCz7343LrcEXpu6oFH5Y4AAADezggAAAAAAEgzIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACApGbuAAAAAAAA1KWdOwAdcxMBAAAAAABIMiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQZEQAAAAAAgKRm7gAAAAAAANSl1cidgE4ZEQAAAAAAoDCjo6OxaNGiWL9+ffT19cVll10Ws2bN2u3n8XZGAAAAAABQmLVr18a2bdtizZo18aEPfSiuueaa1/Q8RgQAAAAAACjMm9/85hgbG4tWqxVbtmyJZvO1vTGRtzMCAAAAAIDCTJs2LdavXx/HHXdcbNiwIW644YbX9DxuIgAAAAAAQGE++9nPxrx58+K+++6Lu+66KxYtWhQvv/zybj+PmwgAAAAAAFCYmTNnxh577BEREXvvvXds27YtxsbGdvt5jAgAAAAAAPRUK3eACpxxxhlxySWXxCmnnBKjo6Nx4YUXxrRp03b7eYwIAAAAAABQmOnTp8cnP/nJX/p5fCYCAAAAAACQZEQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEjywcoAAAAAAPRUO3cAOuYmAgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIMiIAAAAAAABJzdwBAAAAAACoS6uROwGdchMBAAAAAABIMiIAAAAAAABJRY0IjUYjVq+6PB5+6O544Cu3x6xZB+eO1HU661wqncvvXFvfCJ11LpfOOpdkdNu2WLRsZZz2weE4aeH58eC6b8aPfvxcDH3wojjtg8OxbOV10Wq1csfsilrOeGc661wqnXUuVY2dYTIoakQYHFwQU6bsFfOOfm9csnhFrLxyae5IXaezzqXSufzOtfWN0Fnncumsc0nuue9rsc/MGfG566+KGz5xWSz/q0/FldfeGOedc3p87vqrot2O+Nq6R3LH7IpaznhnOutcKp11LlWNnWEyKGpEmHfkEXHf/Q9GRMSjjz0Rh809NHOi7tNZ51LpXH7n2vpG6KxzuXTWuSTvftdRcd45p+143Ozvj++OfD/e8Ttvj4iIo3738Pjmt57MFa+rajnjnemsc6l01rlUNXaGyaCoEWHGzIHYtHHzjsdjY63o7+/PmKj7dNa5VDqX37m2vhE6R+hcKp11Lsm0aVNj+vRpsXXrC3Hh4uVx3jmnRbvdjkajERER06dNjc1btmZO2R21nPHOdNa5VDrrXKoaO8NkMO6I0G6346tf/Wo8+eSTsXHjxli0aFFccskl8dOf/rRX+XbL5k1bYmDGwI7HfX19MTY2ljFR9+msc6l0Lr9zbX0jdI7QuVQ661yan/zbf8SZ5y2KExYcG8f/wbuir6+x43tbX3gxZg4MjPOnX79qOuPtdNa5VDrrXKoaO5es5WtCvnph3BHhsssuiwceeCBWrVoVZ599dhx22GExb968WLJkSY/i7Z5vPPJ4HLfg2IiIeOcRc+Opp57OnKj7dNa5VDqX37m2vhE661wunXUuyU9/tiH+5MLF8ed/dma8/z3vjoiIt/zWrHjsiW9HRMS6R74Vc+e8NWfErqnljHems86l0lnnUtXYGSaDRrvdbr/aN0855ZT4/Oc/H6+88kqccMIJcd9990VExOmnnx4333zzLp+8uedBE5e0A41GI1ZdtyIOffvsaDQacfY5F8bIyDM9zdBrOutcKp3L71xb3widdS6Xzjr3wovPrevJ66y45ob48gMPxZvf9IYdv7bo/D+Ny6+5PkZHt8WbD35jfOzi83vy1glTDzyq66+xs9xnnIPOOpdKZ51LlbvztlfW9+y1avDXbzg1d4QinPPjv+n6a+xyRLjooovisMMOi+eeey4OPPDAePbZZ2PRokVx22237fLJez0iAAAAZerViDCZ9HpEAADGZ0SYWEaEidGLEWHctzNatmxZfOYzn4l2ux0HHnhgRERcfvnl8eEPf7jrwQAAAAAAgLzGvYnwy3ITAQAAmAhuIgAAubmJMLHcRJgYvbiJ0Bzvm0NDQzE6Opr83po1a7oSCAAAAACAsrVyB6Bj444Iw8PDsWTJkli9enVPPjgMAAAAAACYPMYdEebMmRODg4MxMjIS8+fP71UmAAAAAABgEhh3RIiIWLhwYS9yAAAAAAAAk0xf7gAAAAAAAMDkZEQAAAAAAACSdvl2RgAAAAAAMJHajdwJ6JSbCAAAAAAAQJIRAQAAAAAASDIiAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkGREAAAAAAICkZu4AAAAAAADUpZU7AB1zEwEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACApGbuAAAAAAAA1KWVOwAdcxMBAAAAAABIMiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQZEQAAAAAAgKRm7gAAAAAAANSlnTsAHXMTAQAAAAAASDIiAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAk+WBlAABg0pt64FG5I/Tci8+tyx2h52o8ZwCAyc5NBAAAAAAAIMlNBAAAAAAAeqrVyJ2ATrmJAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSjAgAAAAAAEBSM3cAAAAAAADq0sodgI65iQAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIauYOAAAAAABAXVq5A9AxNxEAAAAAAIAkIwIAAAAAAJBkRAAAAAAAAJKMCAAAAAAAQJIRAQAAAAAASGrmDgAAAAAAQF3auQPQMTcRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEhq5g4AAAAAAEBdWo3cCeiUmwgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACApKJGhEajEatXXR4PP3R3PPCV22PWrINzR+o6nXUulc7ld66tb4TOOpdLZ51LVUvn0W3bYtGylXHaB4fjpIXnx4Prvhk/+vFzMfTBi+K0Dw7HspXXRavVyh2zK2o5453prHOpdNaZ15+Wrwn56oWiRoTBwQUxZcpeMe/o98Yli1fEyiuX5o7UdTrrXCqdy+9cW98InXUul846l6qWzvfc97XYZ+aM+Nz1V8UNn7gslv/Vp+LKa2+M8845PT53kNY10wAAIABJREFU/VXRbkd8bd0juWN2RS1nvDOddS6VzjoD3VPUiDDvyCPivvsfjIiIRx97Ig6be2jmRN2ns86l0rn8zrX1jdBZ53LprHOpaun87ncdFeedc9qOx83+/vjuyPfjHb/z9oiIOOp3D49vfuvJXPG6qpYz3pnOOpdKZ52B7ilqRJgxcyA2bdy84/HYWCv6+/szJuo+nXUulc7ld66tb4TOETqXSmedS1VL52nTpsb06dNi69YX4sLFy+O8c06LdrsdjUYjIiKmT5sam7dszZyyO2o5453prHOpdNYZ6J7dGhFWrFjRrRwTYvOmLTEwY2DH476+vhgbG8uYqPt01rlUOpffuba+ETpH6FwqnXUuVU2df/Jv/xFnnrcoTlhwbBz/B++Kvr7Gju9tfeHFmDkwMM6ffv2q6Yy301nnUumsM9A9444IJ5100o6vE088Me64444djyejbzzyeBy34NiIiHjnEXPjqaeezpyo+3TWuVQ6l9+5tr4ROutcLp11LlUtnX/6sw3xJxcujj//szPj/e95d0REvOW3ZsVjT3w7IiLWPfKtmDvnrTkjdk0tZ7wznXUulc46A93TaLfb7Vf75he/+MW44447YvHixTF16tS46KKL4uqrr46IiIMOOmiXT97cc9e/ZyI1Go1Ydd2KOPTts6PRaMTZ51wYIyPP9DRDr+msc6l0Lr9zbX0jdNa5XDrrXKrcnV98bl1PXmfFNTfElx94KN78pjfs+LVF5/9pXH7N9TE6ui3efPAb42MXn9+Tt4uYeuBRXX+NneU+4xx01rlUOuvcC9teWd+z16rBijedmjtCET7y7N90/TXGHREiIp5++um4+uqr4yMf+Uhceuml8bnPfa7jJ+/1iAAAAFCKXo0Ik0mvRwQA2B1GhIllRJgYvRgRdvmZCLNnz44rr7wyPvGJT8SGDRu6HggAAAAAAJgcmp38pn333Teuu+66+Od//udu5wEAAAAAACaJcUeEoaGhGB0d/YVfa7fb0Wg0Ys2aNV0NBgAAAAAA5DXuiDA8PBxLliyJ1atX9+RDtAAAAAAAgMlj3BFhzpw5MTg4GCMjIzF//vxeZQIAAAAAoGCtaOeOQId2+ZkICxcu7EUOAAAAAABgkunLHQAAAAAAAJicjAgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIKmZOwAAAAAAAHVp5Q5Ax9xEAAAAAAAAkowIAAAAAABAkhEBAAAAAABIMiIAAAAAAABJRgQAAAAAACCpmTsAAAAAAAB1aecOQMfcRAAAAAAAAJKMCAAAAAAAQJIRAQAAAAAASDIiAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkNXMHAAAAAACgLq3cAeiYmwgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJDVzBwAAAAAAoC6tRu4EdMpNBAAAAAAAIMlNBICEfaZMzx2h537+0tbcEQCAnUw98KjcEXpu61N/mztCz01/24m5IwAAjMtNBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJJ+JAAAAAABAT7WinTsCHXITAQAAAAAASDIiAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJDUzB0AAAAAAIC6tHMHoGNuIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQ1MwdAAAAAACAurRyB6BjbiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkNTMHQAAAAAAgLq0op07Ah1yEwEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQ1MwdAAAAAACAurRzB6BjbiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQVNSI0Go1YveryePihu+OBr9wes2YdnDtS1+msc6lq7BwRMffwQ+Ouf7gld4yeqPGMdda5VDrrXKraOtfW99sj/zfO+siVERHx3e8/G6f8+cfj9IsvjxX/89ZotVqZ03VPbeccobPO5dK5js4wGRQ1IgwOLogpU/aKeUe/Ny5ZvCJWXrk0d6Su01nnUtXY+bzzF8Y11y2PvabslTtKT9R4xjrrXCqddS5VbZ1r6vuZO+6NS6/7bLw8OhoREctW3xwfPuekuPmKRTEwbWp8ae2jmRN2T03nvJ3OOpdK5zo6w2RQ1Igw78gj4r77H4yIiEcfeyIOm3to5kTdp7POpaqx8w9+8KM449Rzc8fomRrPWGedS6WzzqWqrXNNfd94wP7xV5d8aMfjf/vphvjt2b8RERG/Pfs3439/93u5onVdTee8nc46l0rnOjqXrOVrQr56oagRYcbMgdi0cfOOx2Njrejv78+YqPt01rlUNXa+5+77Y3R0W+4YPVPjGeusc6l01rlUtXWuqe/8/3Z4NHfq9oYD9o9vfWckIiLWPvZkvPjSy7midV1N57ydzjqXSuc6OsNkMO6IcO+990ZExAsvvBBXXHFFnHnmmXHVVVfF1q1bexJud23etCUGZgzseNzX1xdjY2MZE3WfzjqXqsbOtanxjHXWuVQ661yq2jrX1ndny84/K/7X330pPvSxa2K/fWbGPjNn5I7UNTWes846l0rnOjrDZDDuiHDbbbdFRMTy5ctj7733jiVLlsQBBxwQS5dOzvcb+8Yjj8dxC46NiIh3HjE3nnrq6cyJuk9nnUtVY+fa1HjGOutcKp11LlVtnWvru7N13/qnWPY/zojVf3lBbNy8JX73dw7JHalrajxnnXUulc51dIbJoNnJb3r22Wdj+fLlERExa9asuP/++7sa6rW688574/d/7+hYt/auaDQacfY5F+aO1HU661yqGjvXpsYz1lnnUumsc6lq61xb3539+oG/Fh/62Cdjyl57xjve/pY46vBy32O7xnPWWedS6VxHZ5gMGu12u/1q3zz66KPjrLPOiq9//evx4Q9/OA455JD4zne+E8uXL481a9bs8smbex40oWEBemWfKdNzR+i5n780Od+qDgCox9an/jZ3hJ6b/rYTc0cAoEPbXlmfO0JRhg8+OXeEIlz1w9u6/hrjvp3RDTfcENOnT4+DDz44RkZGYvPmzXHZZZdN2rczAgAAAAAAJs64b2d0yCGHxCGHHBJ/9Ed/tOPXvvCFL3Q9FAAAAAAA5WrFq75BDpPMuCPC0NBQjI6OJr/XydsZAQAAAAAAr1/jjgjDw8OxZMmSWL16dfT39/cqEwAAAAAAMAmMOyLMmTMnBgcHY2RkJObPn9+rTAAAAAAAwCQw7ogQEbFw4cJe5AAAAAAAACaZvtwBAAAAAACAyWmXNxEAAAAAAGAitXMHoGNuIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQ1MwdAAAAAACAurRyB6BjbiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkpq5AwAAAAAAUJd2tHNHoENuIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQ1MwdAAAAAACAurRyB6BjbiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkNTMHQAAAAAAgLq0op07Ah0yIgAk/PylrbkjAABUZ/rbTswdoee2rL0qd4SeGzhmOHcEAGA3eDsjAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJBkRAAAAAAAAJKauQMAAAAAAFCXdu4AdMxNBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSmrkDAAAAAABQl1a0c0egQ24iAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJDUzB0AAAAAAIC6tHIHoGNuIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSmrkDAAAAAABQl3a0c0egQ24iAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJDUzB0AAAAAAIC6tHIHoGNuIgAAAAAAAElFjQiNRiNWr7o8Hn7o7njgK7fHrFkH547UdTrrXCqdy+9cW98InXUul846l6q2zrX1jaiv87ef+XGcveKmiIj4l2d/Eqcu++s4ffmnY+mn74xWq9z/H7S2c47QWedy1dgZJoOiRoTBwQUxZcpeMe/o98Yli1fEyiuX5o7UdTrrXCqdy+9cW98InXUul846l6q2zrX1jair801fejg+dtPd8fLotoiIuOGutfGBwWPi5sVnx+joWDz0T9/LnLB7ajrn7XTWuVQ1dobJoKgRYd6RR8R99z8YERGPPvZEHDb30MyJuk9nnUulc/mda+sbobPO5dJZ51LV1rm2vhF1dX7j/vvF1eeeuOPxW950QGzc+mK02+3Y+tLLsUd/Uf954BfUdM7b6axzqWrsDJNBUf+WMGPmQGzauHnH47GxVvT392dM1H0661wqncvvXFvfCJ0jdC6VzjqXqrbOtfWNqKvz77/jkGjuNBS86dd+Ja649d74w4+siuc3bY3D33JwvnBdVtM5b6ezzqWqsTNMBkWNCJs3bYmBGQM7Hvf19cXY2FjGRN2ns86l0rn8zrX1jdA5QudS6axzqWrrXFvfiDo7b3fFrffGTZecFXddfl6ccOSc+MSa+3NH6poaz1lnnUtVY2eYDMYdEf71X/811q5dGy+99FJce+218YEPfCBWrlwZmzdvHu+PZfONRx6P4xYcGxER7zxibjz11NOZE3WfzjqXSufyO9fWN0Jnnculs86lqq1zbX0j6uy83d7Tp8bAlL0iImL/fWfEphdezJyoe2o8Z511LlWNnUvW9teE/NULjXa7/aqvdMopp8T5558f99xzTxxwwAFx7LHHxuOPPx4PP/xw3Hjjjbt88uaeB01o2F1pNBqx6roVcejbZ0ej0Yizz7kwRkae6WmGXtNZ51LpXH7n2vpG6KxzuXTWuVS1da6tb8Tk6Lxl7VU9e631/7EhLr7+7+Jvlp4TT/yfZ+OTX/hq9Pf3xR7N/lh6xglx0P779iTHwDHDPXmd7SbDOfeazjqXKnfnba+s79lr1eDMg/977ghFuOmHd3T9NcYdEYaGhuKWW26JM888M2666aYdv37yySfHbbfdtssn7/WIAAAAAK8nvRwRJotejwgAE8WIMLGMCBOjFyPCuG9nNGPGjPjyl78cxxxzTNx5552xcePGuPvuu2Pq1KldDwYAAAAAAOTVHO+bH//4x2PlypXxxBNPxPr162OfffaJww47LD7+8Y/3Kh8AAAAAAJDJuCPCfvvtFytWrOhVFgAAAAAAYBIZd0QYGhqK0dHR5PfWrFnTlUAAAAAAAJStlTsAHRt3RBgeHo4lS5bE6tWro7+/v1eZAAAAAACASWDcEWHOnDkxODgYIyMjMX/+/F5lAgAAAAAAJoFxR4SIiIULF/YiBwAAAAAAMMn05Q4AAAAAAABMTkYEAAAAAAAgaZdvZwQAAAAAABOp1W7njkCH3EQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJDVzBwAAAAAAoC7t3AHomJsIAAAAAABAkhEBAAAAAABIMiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQ1cwcAAAAAAKAurWjnjkCH3EQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIKmZOwAAAAAAAHVpRzt3BDrkJgIAAAAAAJBkRAAAAAAAAJKMCAAAAAAAQJIRAQAAAAAASPLBygAAAJDJwDHDuSP03PojfzN3hJ466B+/lzsCAPxS3EQAAAAAAACS3EQAAAAAAKCnWrkD0DE3EQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIauYOAAAAAABAXVrRzh2BDrmJAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEhq5g4AAAAAAEBd2tHOHYEOuYkAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJBkRAAAAAAAAJKMCAAAAAAAQFIzdwAAAAAAAOrSyh2AjrmJAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSjAgAAAAAAEBSM3cAAAAAAADq0m63c0egQ24iAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJBU1IjQaDRi9arL4+GH7o4HvnJ7zJp1cO5IXaezzqXSufzOtfWN0Fnncumsc6lq61xb3wida+jcnD079r3mmv/8+9/4jdj32mtj32uuiX2uvDL69t03c7ruqe2cI3TWGeimokaEwcEFMWXKXjHv6PfGJYtXxMorl+aO1HU661wqncvvXFvfCJ11LpfOOpeqts619Y3QufTO0046KWb+xV9E7LlnRETMOPfc2HzttbHhggvi5XXrYtrJJ2dO2D01nfN2OuvM608r2r4m4KsXihoR5h15RNx3/4MREfHoY0/EYXMPzZyo+3TWuVQ6l9+5tr4ROutcLp11LlVtnWvrG6Fz6Z3HnnsuNn70ozseb1y2LLZ9//v/+aC/P+KVVzIl676aznk7nXUGuqeoEWHGzIHYtHHzjsdjY63o7+/PmKj7dNa5VDqX37m2vhE6R+hcKp11LlVtnWvrG6FzRNmdX37ooWiPje143PrZzyIiYo+3vjWmve99sfX223NF67qaznk7nXUGuqeZO8BE2rxpSwzMGNjxuK+vL8Z2+heGEumsc6l0Lr9zbX0jdI7QuVQ661yq2jrX1jdC54g6Ou9sr3e9K6afemr8fNGiaG/cmDtO19R4zjrrDHTPuDcRLrroonj++ed7leWX9o1HHo/jFhwbERHvPGJuPPXU05kTdZ/OOpdK5/I719Y3Qmedy6WzzqWqrXNtfSN0rqXzdlPmz49p73tfbLjgghj7yU9yx+mqGs9ZZ52B7mm02+1X/fSFY489Nvbee+849dRT4/3vf380Go3devLmngf90gF3R6PRiFXXrYhD3z47Go1GnH3OhTEy8kxPM/SazjqXSufyO9fWN0Jnnculs86lqq1zbX0jdM7Vef2Rv9mz1+o74IDYe+nS2HDuubH/nXfG2L//e7S3bImIiFeefDK2fvazXc9w0D9+r+uv8f+bDOfcazrr3AvbXlnfs9eqweCvvyd3hCLc9aN7uv4a444IQ0NDsXr16rj22mvj0Ucfjfe85z1x9NFHxxvf+MYYGBh4tT+2Q69HBAAAAGBy6+WIMBnkGBGA7jAiTKwTjAgT4os9GBHGfTujRqMRM2fOjCVLlsTNN98cM2bMiE996lNx8skndz0YAAAAAACQ17gjwq/+6q/u+Pv99tsvTjnllLjuuuvii1/8YteDAQAAAAAAv5znn38+jjnmmHjmmdf29l/jjghXX331a3pSAAAAAAAgr9HR0Vi6dGlMmTLlNT9Hc7xvDg0Nxejo6C/8WrvdjkajEWvWrHnNLwoAAAAAAHTXFVdcESeddFLceOONr/k5xh0RhoeHY8mSJbF69ero7+9/zS8CAAAAAAD0zt///d/HfvvtF0cddVT3RoQ5c+bE4OBgjIyMxPz581/ziwAAAAAAwHbtaOeOULw77rgjGo1GPPLII/H000/HxRdfHNdff33sv//+u/U8444IERELFy58zSEBAAAAAIDeu/XWW3f8/dDQUFx66aW7PSBE7OKDlQEAAAAAgHrt8iYCAAAAAADw+nXLLbe85j/rJgIAAAAAAJBkRAAAAAAAAJKMCAAAAAAAQJLPRAAAAAAAoKda0c4dgQ65iQAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkowIAAAAAABAUjN3AAAAAAAA6tJut3NHoENuIgAAAAAAAElGBAAAAAAAIMmIAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSmrkDAAAAAABQl1buAHTMTQQAAAAAACDJiAAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkpq5AwAAAAAAUJd2tHNHoENuIgAAAAAAAEluIkywfaZMzx2hp37+0tbcEQAAAF63avsZMiLioH/8Xu4IPbVl7VW5I/TcwDHDuSMAMIHcRAAAAAAAAJKMCAAAAAAAQJIRAQAAAAAASPKZCAAAAAAA9FQr2rkj0CE3EQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIMiIAAAAAAABJzdwBAAAAAACoS7vdzh2BDrmJAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSjAgAAAAAAEBSM3cAAAAAAADq0op27gh0yE0EAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkIwIAAAAAAJBkRAAAAAAAAJKauQMAAAAAAFCXdrRzR6BDbiIAAAAAAABJRgQAAAAAACDJiAAAAAAAACQZEQAAAAAAgCQjAgAAAAAAkGREAAAAAAAAkpq5AwAAAAAAUJdWu507Ah1yEwEAAAAAAEgyIgAAAAAAAElGBAAAAAAAIKmoEaHRaMTqVZfHww/dHQ985faYNevg3JF6Zu7hh8Zd/3BL7hg9UeM566xziWrrG6GzzuXSWedS1da5tr4RdXbezs+Q5fr2Mz+Os1fcFBER//LsT+LUZX8dpy//dCz99J3RarUyp+ue2s45QudaOsNkUNSIMDi4IKZM2SvmHf3euGTxilh55dLckXrivPMXxjXXLY+9puyVO0pP1HjOOutcotr6Ruisc7l01rlUtXWurW9EnZ0j/AxZ8jnf9KWH42M33R0vj26LiIgb7lobHxg8Jm5efHaMjo7FQ//0vcwJu6emc95O5zo6w2RQ1Igw78gj4r77H4yIiEcfeyIOm3to5kS98YMf/CjOOPXc3DF6psZz1lnnEtXWN0Jnnculs86lqq1zbX0j6uwc4WfIks/5jfvvF1efe+KOx2950wGxceuL0W63Y+tLL8ce/UX9Z6BfUNM5b6dzHZ1L1vY1IV+9UNQ/PWbMHIhNGzfveDw21or+/v6MiXrjnrvvj9H/+r8MalDjOeusc4lq6xuhc4TOpdJZ51LV1rm2vhF1do7wM2TJ5/z77zgkmjsNBW/6tV+JK269N/7wI6vi+U1b4/C3HJwvXJfVdM7b6VxHZ5gMdjkifP3rX4+HH344XnnllVi2bFkMDw/Hc88914tsu23zpi0xMGNgx+O+vr4YGxvLmIhuqPGcdda5RLX1jdA5QudS6axzqWrrXFvfiDo716jmc77i1nvjpkvOirsuPy9OOHJOfGLN/bkjdU2N56xzHZ1hMhh3RFi8eHHcc889ceutt8bQ0FDMmjUrFixYEB/96Ed7lW+3fOORx+O4BcdGRMQ7j5gbTz31dOZEdEON56yzziWqrW+EzjqXS2edS1Vb59r6RtTZuUY1n/Pe06fGwH999sX++86ITS+8mDlR99R4zjrX0Rkmg+Z43/zhD38Yt956a7Tb7Tj++OPjj//4jyMi4uabb+5JuN115533xu//3tGxbu1d0Wg04uxzLswdiS6o8Zx11rlEtfWN0Fnncumsc6lq61xb34g6O9eo5nP+y7PeGxdf/3fR398XezT7Y+kZJ+SO1DU1nrPOdXSGyaDRbrdf9fMXTjzxxDj33HNjw4YNsXz58vj85z8fAwMDccEFF8Rtt922yydv7nnQhIZ9PdhnyvTcEXrq5y9tzR0BAADgdau2nyEj6vs5csvaq3JH6LmBY4ZzR4Cu2PbK+twRinLUQb+XO0IR1q1/oOuvMe5NhEsvvTRWr14ds2fPjqVLl8bQ0FDss88+cdlll3U9GAAAAAAAZWrFq/6/7Uwy444Is2fPjlWrVu14fPzxx3c9EAAAAAAAMDmMOyIMDQ3F6Oho8ntr1qzpSiAAAAAAAGByGHdEGB4ejiVLlsTq1aujv7+/V5kAAAAAAIBJYNwRYc6cOTE4OBgjIyMxf/78XmUCAAAAAAAmgXFHhIiIhQsX9iIHAAAAAAAwyfTlDgAAAAAAAExOu7yJAAAAAAAAE6kV7dwR6JCbCAAAAAAAQJIRAQAAAAAASDIiAAAAAAAASUYEAAAAAAAgyYgAAAAAAAAkNXMHAAAAAACgLu12O3cEOuQmAgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIMiIAAAAAAABJRgQAAAAAACCpmTsAAAAAAAB1aUU7dwQ65CYCAAAAAACQZEQAAAAAAACSjAgAAAAAAECSEQEAAAAAAEgyIgAAAAAAAEnN3AEAAAAAAKhLO9q5I9AhNxEAAAAAAIAkIwIAAAAAAJBkRAAAAAAAAJKMCAAAAAAAQJIRAQAAAAAASGrmDlCan7+0NXcEAAAAXif8DFm+gWOGc0foua1P/W3uCD03/W0n5o4Arzvtdjt3BDrkJgIAAAAAAJBkRAAAAAAAAJKMCAAAAAAAQJIRAQAAAAAASDIiAAAAAAAASUYEAAAAAAAgqZk7AAAAAAAAdWlFO3cEOuQmAgAAAAAAkGREAAAAAAAAkowIAAAAAABAkhEBAAAAAABIMiIAAAAAAABJzdwBAAAAAACoS7vdzh2BDrmJAAAAAAAAJBkRAAAAAACAJCMCAAAAAACQZEQAAAAAAACSjAgAAAAAAEBSM3cAAAAAAADq0op27gh0yE0EAAAAAAAgyYgAAAAAAAAkGREAAAAAAIAkIwLCuS0DAAAf50lEQVQAAPD/2rv3aC3rAl/g3w0b5LJVulgxhIaaRpoa3soUGy+TThfSGLkYyEB6nOWkoqWCiqBcNEtzeQlzaeZliZUO6lHT0QzUHK9R4m0iTNdxOiw1FEEU2Ps9f3TY43AeDDu8+2Ge5/NxsZYv5Ob7XQ/t/fJ+9+95AQAAChkRAAAAAACAQkYEAAAAAACgUGvZAQAAAAAAqJdGGmVHYAM5iQAAAAAAABQyIgAAAAAAAIWMCAAAAAAAQCEjAgAAAAAAUMiIAAAAAAAAFGotOwAAAAAAAPXS0WiUHYEN5CQCAAAAAABQqFIjQktLSy695Nw8MP/W3PuvP812232s7EhNp7POVaVz9TvXrW+is87VpbPOVVW3znXrm+isc3XVrfNvn1uc8ZO+kyR5etELGX3S9Bx16rmZdfn16ejoKDld89TtOif17AybgkqNCMOGHZJevTbLvkO/ksmnz8r535lSdqSm01nnqtK5+p3r1jfRWefq0lnnqqpb57r1TXTWubrq1Pmqm+7M1IuvzturVydJzr70xznl6JH58Xmnpa1P79wx7+GSEzZPna7zWnXsDJuCSo0I++6zV+66+74kycOPPJHdh+xScqLm01nnqtK5+p3r1jfRWefq0lnnqqpb57r1TXTWubrq1HngR7bKhZOP63y85JWl2W3w9kmS3QZ/PL9++ndlRWu6Ol3nterYGTYFlRoRNt+iLctef6PzcXt7R7p3715ioubTWeeq0rn6nevWN9E50bmqdNa5qurWuW59E50TnauqTp0P/tweaX1Ht49+ZKs89uRzSZJ5jyzIyrfeLita09XpOq9Vx86wKWj9S/+D2267LY8//nhWrlyZ973vfdlnn30ydOjQrsj2nr2xbHnaNm/rfNytW7e0t7eXmKj5dNa5qnSufue69U10TnSuKp11rqq6da5b30TnROeqqmPntc4+YXzOu+KG/OjmO7PTxwelZ48eZUdqmjpe5zp2hk3Bu55EmD59ehYvXpwDDjggffr0SVtbW+bPn5/vf//7XZXvPXnwoUdz6CEHJEn23mtIFi58puREzaezzlWlc/U7161vorPO1aWzzlVVt85165vorHN11bHzWvc/9pucffy4XHrWiXn9jeX57Kc/WXakpqnjda5j5ypr+Gej/NMV3vUkwrPPPpvrrrsuSTJ06NAce+yxmT17dkaNGtUl4d6ruXPvzEEHDs39825JS0tLJhw9sexITaezzlWlc/U7161vorPO1aWzzlVVt85165vorHN11bHzWlv/zYdz3LSL0muzntnzU5/IfntU9575dbzOdewMm4KWRqOx3rniH/7hH3LGGWdk1113zWOPPZbZs2dn1qxZOfroozN37ty/+MFbew7YqGEBAAAA2LStWHhj2RG6XN+dR5QdgS6wZtVLZUeolJ0+vHfZESrhqSUPN/33eNeTCFOnTs2UKVOyZMmSDBw4MDNnzsztt9+eE044oenBAAAAAACAcr3riLDTTjvlpptu+i8/N2jQoKYGAgAAAAAANg3vOiKMGTMmq1evLvy1OXPmNCUQAAAAAACwaXjXEeFb3/pWzjjjjFx66aXp3r17V2UCAAAAAKDCOtb/Vr1sYt51RNh1110zbNiwPPfcczn44IO7KhMAAAAAALAJeNcRIUm+8Y1vdEUOAAAAAABgE9Ot7AAAAAAAAMCmyYgAAAAAAAAUMiIAAAAAAACF/uJ7IgAAAAAAwMbUSKPsCGwgJxEAAAAAAIBCRgQAAAAAAKCQEQEAAAAAAChkRAAAAAAAAAoZEQAAAAAAgEJGBAAAAAAAoFBr2QEAAAAAAKiXjkaj7AhsICcRAAAAAACAQkYEAAAAAACgkBEBAAAAAAAoZEQAAAAAAAAKGREAAAAAAIBCrWUHAAAAAACgXhpplB2BDeQkAgAAAAAAUMiIAAAAAAAAFDIiAAAAAAAAhYwIAAAAAABAISMCAAAAAABQqLXsAAAAAAAA1EtHo1F2BDaQkwgAAAAAAEAhIwIAAAAAAFDIiAAAAAAAABTynggAAAAAbDR9dx5RdoQut2LhjWVH6HJ1vM5QV04iAAAAAAAAhYwIAAAAAABAIbczAgAAAACgSzXSKDsCG8hJBAAAAAAAoJARAQAAAAAAKGREAAAAAAAAChkRAAAAAACAQkYEAAAAAACgUGvZAQAAAAAAqJdGo6PsCGwgJxEAAAAAAIBCRgQAAAAAAKCQEQEAAAAAAChkRAAAAAAAAAoZEQAAAAAAgEJGBAAAAAAAoFBr2QEAAAAAAKiXjjTKjsAGchIBAAAAAAAoZEQAAAAAAAAKGREAAAAAAIBCRgQAAAAAAKCQEQEAAAAAACjUWnYAAAAAAADqpdFolB2BDeQkAgAAAAAAUMiIAAAAAAAAFDIiAAAAAAAAhYwIAAAAAABAISMCAAAAAABQqLXsAAAAAAAA1EtHGmVHYAM5iQAAAAAAABQyIgAAAAAAAIWMCAAAAAAAQCEjAgAAAAAAUMiIAAAAAAAAFKrUiNDS0pJLLzk3D8y/Nff+60+z3XYfKztS0+msc1XpXP3Odeub6Kxzdemsc1XVrXPd+iY661xdOle/82+fW5zxk76TJHl60QsZfdL0HHXquZl1+fXp6OgoOV3z1O06w6aiUiPCsGGHpFevzbLv0K9k8umzcv53ppQdqel01rmqdK5+57r1TXTWubp01rmq6ta5bn0TnXWuLp2r3fmqm+7M1IuvzturVydJzr70xznl6JH58Xmnpa1P79wx7+GSEzZPna5zHTQaDT82wo+uUKkRYd999spdd9+XJHn4kSey+5BdSk7UfDrrXFU6V79z3fomOutcXTrrXFV161y3vonOOleXztXuPPAjW+XCycd1Pl7yytLsNnj7JMlugz+eXz/9u7KiNV2drjNsSlrf7RfvueeePPTQQ3njjTeyxRZbZPfdd88hhxySlpaWrsr3nmy+RVuWvf5G5+P29o5079497e3tJaZqLp11riqdq9+5bn0TnROdq0pnnauqbp3r1jfROdG5qnSudueDP7dHXlrySufjj35kqzz25HPZ41M7Zt4jC7LyrbdLTNdcdbrOsClZ74gwbdq0dHR0ZOjQoenbt29WrFiR+fPn54EHHsiMGTO6MuMGe2PZ8rRt3tb5uFu3bpX/JKKzzlWlc/U7161vonOic1XprHNV1a1z3fomOic6V5XO9ei81tknjM95V9yQH918Z3b6+KD07NGj7EhNU+frDGVa7+2Mfve732XatGk58MAD85nPfCYHHnhgpk2blt///vddme89efChR3PoIQckSfbea0gWLnym5ETNp7POVaVz9TvXrW+is87VpbPOVVW3znXrm+isc3XpXI/Oa93/2G9y9vHjculZJ+b1N5bns5/+ZNmRmqbO1xnKtN6TCB0dHXnssceyxx57dP7co48+mh6b8Jo5d+6dOejAobl/3i1paWnJhKMnlh2p6XTWuap0rn7nuvVNdNa5unTWuarq1rlufROdda4unevRea2t/+bDOW7aRem1Wc/s+alPZL89qvs+AXW+zlCmlsZ63sL5xRdfzKxZs/L000+n0WikW7duGTx4cE488cTsuOOOG/TBW3sO2KhhAQAAAGBTs2LhjWVH6HJ9dx5RdoQut2bVS2VHqJT+/ap7aqYr/fG1p5v+e6z3JMKiRYvy7LPPpkePHpk4cWK++MUvJknGjh2ba665punBAAAAAACAcq13RJg9e3bmzp2bjo6OnHDCCVm1alUOO+ywrOfgAgAAAAAAUDHrHRF69OiRLbfcMkly2WWX5aijjkr//v3T0tLSZeEAAAAAAIDydFvfLwwYMCCzZs3Km2++mba2tlxyySU5++yzs3jx4q7MBwAAAAAAlGS9I8LMmTOz4447dp486N+/f6655poceuihXRYOAAAAAAAoT0ujiW9y0NpzQLM+NAAAAABsElYsvLHsCF2u784jyo7Q5daseqnsCJXykX6Dy45QCf/7tWea/nus9yQCAAAAAABQb0YEAAAAAACgkBEBAAAAAAAoZEQAAAAAAAAKGREAAAAAAIBCRgQAAAAAAKBQa9kBAAAAAACol0ajUXYENpCTCAAAAAAAQCEjAgAAAAAAUMiIAAAAAAAAFDIiAAAAAAAAhYwIAAAAAABAodayAwAAAAAAUC8daZQdgQ3kJAIAAAAAAFDIiAAAAAAAABQyIgAAAAAAAIWMCAAAAAAAQCEjAgAAAAAAUKi17AAAAAAAANRLo9EoOwIbyEkEAAAAAACgkBEBAAAAAAAoZEQAAAAAAAAKGREAAAAAAIBCRgQAAAAAAKCQEQEAAAAAACjUWnYAAAAAAADqpaPRKDsCG8iIAAAAbPL69epbdoQu99pbK8qOAMAG6rvziLIjdLnl875bdgSgi7idEQAAAAAAUMiIAAAAAAAAFDIiAAAAAAAAhYwIAAAAAABAIW+sDAAAAABAl2o0GmVHYAM5iQAAAAAAABQyIgAAAAAAAIWMCAAAAAAAQCEjAgAAAAAAUMiIAAAAAAAAFDIiAAAAAAAAhVrLDgAAAAAAQL10pFF2BDaQkwgAAAAAAEAhIwIAAAAAAFDIiAAAAAAAABQyIgAAAAAAAIWMCAAAAAAAQKHWsgMAAAAAAFAvjUaj7AhsICcRAAAAAACAQkYEAAAAAACgkBEBAAAAAAAoZEQAAAAAAAAKGREAAAAAAIBCrWUHAAAAAACgXjoajbIjsIGcRAAAAAAAAAoZEQAAAAAAgEJGBAAAAAAAoJARAQAAAAAAKGREAAAAAAAAChkRAAAAAACAQq1lBwAAAAAAoF4aaZQdgQ3kJAIAAAAAAFDIiAAAAAAAABSq1IjQ0tKSSy85Nw/MvzX3/utPs912Hys7UtPprHNV6Vz9znXrm+isc3XprHOVDdljl9xy+7Vlx+gSdbzGOutcVTrrXDW//f3/yoRZP0qSPPvCH/P1s6/IUTOuzJQr56ajo6PkdFB9lRoRhg07JL16bZZ9h34lk0+flfO/M6XsSE2ns85VpXP1O9etb6KzztWls85V9c0TvpHvXzwjm/XarOwoXaKO11hnnatKZ52r5Ed3PJBpP7o1b69ekySZfcu8/I9h++fHp0/I6tXtmf+b35WcEKqvUiPCvvvslbvuvi9J8vAjT2T3IbuUnKj5dNa5qnSufue69U101rm6dNa5qp5//sWM+/o/lx2jy9TxGuusc1XprHOVDNzq/bngn0d0Pv7ENh/J6ytWptFoZMVbb6dH90q9vAmbpNayA2xMm2/RlmWvv9H5uL29I927d097e3uJqZpLZ52rSufqd65b30TnROeq0lnnqvqft96dgVsPKDtGl6njNdZZ56rSWecqOWjPT+all5d2Pt7mwx/IzGtvzxW3zk9bn17Z4xMfKy8c/186Go2yI7CB1jsi3Hjjjev9j0aMGLHeXyvTG8uWp23zts7H3bp1q9wnznXprHNV6Vz9znXrm+ic6FxVOutMNdTxGuusc1XprHOVnXf9nfnR5PHZfsCHMueeR/K9OXdn8tgvlh0LKm29530WL16cK6+8Mi+//PL/82NT9eBDj+bQQw5Ikuy915AsXPhMyYmaT2edq0rn6neuW99EZ52rS2edqYY6XmOdda4qnXWusi379k7b/32/oq3et3mWvbmy5ERQfes9iTBp0qQsXrw4Q4cOzS67/Pe4p9rcuXfmoAOH5v55t6SlpSUTjp5YdqSm01nnqtK5+p3r1jfRWefq0llnqqGO11hnnatKZ52r7KzxX8mpP/hZunfvlh6t3TNl3JfLjgSV19JorP/mU0uXLs2bb76ZAQP+8z6gq1atSs+ePTfog7f2rM/9QwEAgObp16tv2RG63GtvrSg7AgCs1/J53y07Qpfr9dlRZUeolN69tyk7QiWsXPlC03+P9d7O6Be/+EUOP/zwjBs3LnfccUfnz3/jG99oeigAAAAAAKB8672d0ezZs/Mv//IvaTQaOeGEE/L222/nsMMOy7scXAAAAAAAgL/I68z/fax3ROjRo0f69euXJLnsssty1FFHpX///mlpaemycAAAAAAAQHnWezujAQMGZNasWXnzzTfT1taWSy65JGeffXYWL17clfkAAAAAAICSrHdEmDlzZnbcccfOkwf9+/fPNddck0MPPbTLwgEAAAAAAOVpaTTx5lOtPQc060MDAAA10q9X37IjdLnX3lpRdgQAWK/l875bdoQu1+uzo8qOUCm9em1ddoRKeOutF5v+e6z3JAIAAAAAAFBvRgQAAAAAAKBQa9kBAAAAAACol0aadpd9NjInEQAAAAAAgEJGBAAAAAAAoJARAQAAAAAAKGREAAAAAAAAChkRAAAAAACAQq1lBwAAAAAAoF4ajUbZEdhATiIAAAAAAACFjAgAAAAAAEAhIwIAAAAAAFDIiAAAAAAAABQyIgAAAAAAAIWMCAAAAAAAQKHWsgMAAAAAAFAvjUaj7AhsICcRAAAAAACAQkYEAAAAAACgkBEBAAAAAAAoZEQAAAAAAAAKGREAAAAAAIBCrWUHAAAAAACgXhplB2CDOYkAAAAAAAAUMiIAAAAAAACF3M4IAAAAAAAqpqOjI1OnTs1zzz2Xnj17Zvr06dlmm23e88dxEgEAAAAAACrmnnvuyapVq3LjjTfm5JNPzrnnnvtXfRwjAgAAAAAAVMzjjz+e/fbbL0my2267ZeHChX/Vx2nq7YzWrHqpmR8eAAAAAID/hrx23HzLly9PW1tb5+Pu3btnzZo1aW19b7OAkwgAAAAAAFAxbW1tWbFiRefjjo6O9zwgJEYEAAAAAAConCFDhmT+/PlJkgULFmSHHXb4qz5OS6PRaGzMYAAAAAAAQLk6OjoyderU/Pu//3sajUZmzpyZ7bbb7j1/HCMCAAAAAABQyO2MAAAAAACAQkYEAAAAAACgkBEBAAAAAAAoVKkRoaOjI1OmTMmIESMyZsyYvPDCC2VH6jK/+c1vMmbMmLJjdInVq1fn29/+dkaPHp3hw4fn3nvvLTtS07W3t2fSpEkZOXJkjjzyyLz44otlR+oSr776avbff//8/ve/LztKl/nqV7+aMWPGZMyYMZk0aVLZcZru8ssvz4gRI3L44Yfnpz/9adlxmu7mm2/uvL5HHHFEPvWpT2XZsmVlx2qq1atX5+STT87IkSMzevToWvz/edWqVTn55JNzxBFHZPz48fnDH/5QdqSmeudzkBdeeCGjRo3K6NGjc9ZZZ6Wjo6PkdM1R9Lxr5syZueGGG0pK1Hzv7PzMM89k9OjRGTNmTCZMmJBXXnml5HQb3zv7Llq0KKNGjcrIkSMzderUtLe3l5yuOYr+XN92220ZMWJESYma752dn3rqqey3336dX6fvuOOOktM1xzs7v/rqq/mnf/qnHHnkkRk5cmRl/47xzs4TJ07svMYHHHBAJk6cWHK65lj3c/YRRxyRUaNGZdKkSbX42vzUU09l+PDhGT16dM4555zKdS56TaTqz8He7XWgqj8Hg01Fa9kBNqZ77rknq1atyo033pgFCxbk3HPPzQ9+8IOyYzXdFVdckVtvvTW9e/cuO0qXuPXWW9OvX7+cf/75Wbp0aQ477LAceOCBZcdqqvvuuy9JMmfOnDz88MOZNWtW5f9sr169OlOmTEmvXr3KjtJl3n777STJtddeW3KSrvHwww/n17/+dW644YasXLkyV111VdmRmu7www/P4YcfniSZNm1avva1r2WLLbYoOVVzzZs3L2vWrMmcOXPy4IMP5vvf/34uvvjismM11U9+8pP06dMnP/nJT7J48eKcc845ufLKK8uO1RTrPgeZNWtWTjzxxOy9996ZMmVK7r333hx88MElp9y41u38pz/9Kaecckr+8Ic/ZMKECSWna451O8+YMSNnnnlmBg8enDlz5uSKK66o1PC9bt8LLrggJ510Uvbcc8+cdtpp+cUvflH5P9fJn194/NnPfpZGo1FisuZZt/PTTz+df/zHf8z48eNLTtY863Y+//zz8+Uvfzl///d/n3/7t3/L4sWLs/XWW5eccuNat/OFF16YJHn99dczduzYSn3uWmvdzpdcckmOO+647L///jn55JPzy1/+MgcccEDJKTeudTufeeaZOeOMMzJkyJBceOGFue222zJs2LCSU248Ra+JfOITn6j0c7Cizp/+9Kcr/xwMNiWVOonw+OOPZ7/99kuS7Lbbblm4cGHJibrG1ltvXfkXZN7pkEMOyQknnND5uHv37iWm6RoHHXRQzjnnnCTJf/zHf+SDH/xgyYma77zzzsvIkSPzoQ99qOwoXebZZ5/NypUrM378+IwdOzYLFiwoO1JTPfDAA9lhhx1y3HHH5dhjj83nP//5siN1mSeffDKLFi2q9Hd3rjVo0KC0t7eno6Mjy5cvT2trpb5/odCiRYsydOjQJMm2225b6dMX6z4Heeqpp7LXXnslSYYOHZpf/epXZUVrmnU7r1ixIt/85jcr9eLEutbtfMEFF2Tw4MFJ/nxacrPNNisrWlOs2/fiiy/OnnvumVWrVuXll1/OBz7wgRLTNce6nZcuXZrvfve7mTx5compmmvdzgsXLswvf/nLHHnkkZk8eXKWL19eYrrmWLfzE088kSVLlmTcuHG57bbbOj9/V8n6/q588cUX5+tf/3ol/66xbufBgwfntddeS6PRyIoVKyr5XGzdzkuWLMmQIUOSJEOGDMnjjz9eVrSmKHpNpOrPwYo61+E5GGxKKjUiLF++PG1tbZ2Pu3fvnjVr1pSYqGt84QtfqOQTgfXp27dv2trasnz58hx//PE58cQTy47UJVpbW3PqqafmnHPOyRe+8IWy4zTVzTffnPe///2do2Bd9OrVKxMmTMiVV16ZadOm5Vvf+lalP4ctXbo0CxcuzEUXXdTZt6rf7biuyy+/PMcdd1zZMbpEnz598tJLL+XQQw/NmWeeWYtb7w0ePDj33XdfGo1GFixYkCVLllT29ifrPgdpNBppaWlJ8uev12+88UZZ0Zpm3c4DBw7MrrvuWmKi5lu389oX3Z544olcd911GTduXEnJmmPdvt27d89LL72UL33pS1m6dGkGDRpUYrrmeGfn9vb2nH766Zk8eXL69u1bcrLmWfc677LLLjnllFNy/fXXZ+DAgbn00ktLTNcc63Z+6aWXssUWW+Tqq69O//79c8UVV5SYrjmK/q786quv5qGHHuo8HVo163b+2Mc+lhkzZuTQQw/Nq6++mr333rvEdM1R9LX5kUceSfLnU/0rV64sK1pTFL0mUvXnYEWd6/AcDDYllRoR2trasmLFis7HHR0dtXpxvU7++Mc/ZuzYsRk2bFi+/OUvlx2ny5x33nm56667cuaZZ+bNN98sO07T3HTTTfnVr36VMWPG5Jlnnsmpp56al19+uexYTTdo0KB85StfSUtLSwYNGpR+/fpVune/fv2y7777pmfPntl2222z2Wab5U9/+lPZsZpu2bJlWbx4cT7zmc+UHaVLXH311dl3331z11135ZZbbslpp53Weeuuqvra176Wtra2jB07Nvfdd1922mmnWpyaS5Ju3f7zqeWKFSsqf7uuOrvjjjty1lln5Yc//GHe//73lx2n6QYMGJC77747o0aNyrnnnlt2nKZ66qmn8sILL2Tq1Kk56aSTsmjRosyYMaPsWE138MEHZ+edd+7896effrrkRM3Xr1+/ztvaHHDAAbU5yf/zn/88X/rSl2rztXnGjBm5/vrr8/Of/zxf/epXK/85LPnzPfIvv/zyHHPMMfnABz6Q973vfWVH2ujWfU2kDs/B6vo6EGwqKjUiDBkyJPPnz0+SLFiwIDvssEPJiWiGV155JePHj8+3v/3tDB8+vOw4XWLu3Lm5/PLLkyS9e/dOS0tLpZ/0Xn/99bnuuuty7bXXZvDgwTnvvPOy1VZblR2r6X72s591PqlfsmRJli9fXuneu+++e+6///40Go0sWbIkK1euTL9+/cqO1XSPPvpo9tlnn7JjdJktttgim2++eZJkyy23zJo1ayr7XflrPfnkk9l9991z7bXX5qCDDsrAgQPLjtRlPvnJT+bhhx9OksyfPz977LFHyYlohltuuaXz63Qd/nwfe+yxnW+Q3rdv3//yQk0V7bLLLrn99ttz7bXX5oILLsj222+f008/vexYTTdhwoT89re/TZI89NBD2WmnnUpO1Hy777575s2bl+TPz0+23377khN1jYceeqjztoN1sOWWW3beseFDH/pQli1bVnKi5ps3b15mzpyZH/7wh3nttdfyuc99ruxIG1XRayJVfw5Wx9eBYFNTqW/TP/jgg/Pggw9m5MiRaTQamTlzZtmRaILZs2dn2bJlueyyy3LZZZcl+fMbKVX5DXj/7u/+LpMmTcqRRx6ZNWvWZPLkyZW7/zDJ8OHDM2nSpIwaNSotLS2ZOXNmpU9T/e3f/m0effTRDB8+PI1GI1OmTKn0OLbW888/n49+9KNlx+gy48aNy+TJkzN69OisXr06EydOTJ8+fcqO1VTbbLNNLrroolx11VXZfPPNa/EdvGudeuqpOfPMM3PBBRdk2223rfzt9+qovb09M2bMSP/+/fPNb34zSbLnnnvm+OOPLzlZ8xxzzDE57bTT0qNHj/Tu3TvTp08vOxJNMHXq1Jxzzjnp0aNHPvjBD3a+H1mVnXrqqTnjjDMyZ86ctLW15Xvf+17ZkbrE888/X4sBdK3p06dn4sSJaW1tTY8ePWrxZ3ubbbbJMccck969e2fvvffO/vvvX3akjaroNZHTTz8906dPr+xzsDq+DgSbmpZGXW5ADQAAAAAAvCfVPosLAAAAAAD81YwIAAAAAABAISMCAAAAAABQyIgAAAAAAAAUMiIAAAAAAACFjAgAAAAAAEAhIwIAAAAAAFDo/wCyJXclLxnWFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2160x2160 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(cm_task5, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Now you will make use of Unsupervised Representation Learning as studied in class. You have been provided with a pretrained autoencoder (just the encoder part) and you will use it to obtain deep features for the modified UC Merced Land Use dataset. You will have to:\n",
    "- Obtain predictions for the entire dataset\n",
    "- Save then in an appropriate fashion\n",
    "\n",
    "*Keep in mind that this model takes input of shape 256X256X3 so you need to resize the images before feeding them into this model*\n",
    "\n",
    "*Try to think about how you could use the generator from Task4 to create another generator which would yield encoded features along with labels instead of raw images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 20) 2960        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 20) 80          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 20) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 64) 11584       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 1344        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 64) 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 64) 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 64) 256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 128, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 64) 36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 128, 64) 0           add_1[0][0]                      \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 64) 256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 64) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 128)  73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 128)  8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 128)  147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 128)  0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 128)  0           add_3[0][0]                      \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 256)  295168      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 256)  33024       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 256)  590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 256)  0           conv2d_14[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 256)  1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 256)  590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 256)  1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 256)  590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 256)  0           add_5[0][0]                      \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 256)  1024        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 256)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 128)  295040      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 128)  32896       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 128)  0           conv2d_19[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 128)  147584      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 128)  0           add_7[0][0]                      \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 128)  512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 20)     23060       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 20)     80          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 20)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 20)     2580        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 20)     3620        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 20)     0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 20)     80          add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 20)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 20)     3620        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 20)     80          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 20)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 20)     3620        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 20)     0           add_9[0][0]                      \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 20)     80          add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 20)     0           batch_normalization_21[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 3,566,836\n",
      "Trainable params: 3,562,028\n",
      "Non-trainable params: 4,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "encoder_pretained = load_model('encoder_gt.h5')\n",
    "encoder_pretained.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "encoder_pretained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_generator(path_all_images, class_labels, batch_size = 64):\n",
    "    total_pictures = len(path_all_images)\n",
    "    \n",
    "    indexes = np.arange(0,total_pictures,batch_size) #setting start index of each batch\n",
    "    \n",
    "    if total_pictures % batch_size != 0:\n",
    "        indexes = indexes[:-1]  #dropping last index if last batch does not complete the batch size requirement\n",
    "\n",
    "    while True:\n",
    "        np.random.shuffle(indexes) #shuffles indexes so order of data given to model in each epoch is different\n",
    "        for index in indexes:\n",
    "            path = path_all_images[index : index + batch_size]\n",
    "            labels = class_labels[index : index + batch_size]\n",
    "            \n",
    "            x_array = np.zeros((batch_size,256,256,3))\n",
    "            batch_labels = to_categorical(labels, num_classes = 22)\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                img = cv2.imread(path[i])\n",
    "                x_array[i] = cv2.resize(img,(256,256))\n",
    "                \n",
    "            resized_images = x_array  \n",
    "            labels = np.array(batch_labels)\n",
    "            \n",
    "            encoded_output = encoder_pretained.predict(resized_images,verbose=0)\n",
    "            encoded_output_reshaped = np.reshape(encoded_output, (encoded_output.shape[0],\n",
    "                                                                 encoded_output.shape[1]*encoded_output.shape[2],\n",
    "                                                                 encoded_output.shape[3]))\n",
    "        \n",
    "            yield encoded_output_reshaped, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_all_images_task6 = []\n",
    "labels_to_all_images_task6 = []\n",
    "\n",
    "for i in range(len(paths_to_images)):\n",
    "    for j in range(len(paths_to_images[i])):\n",
    "        paths_to_all_images_task6.append(paths_to_images[i][j])\n",
    "        labels_to_all_images_task6.append(labels_total[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_task6 = encoder_generator(paths_to_all_images_task6, labels_to_all_images_task6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_predictions_task6 = []\n",
    "labels_encoded_predictions_task6 = []\n",
    "\n",
    "#33 iterations\n",
    "for i in range(len(paths_to_all_images_task6)//batch_size):\n",
    "    gen = next(gen_task6)\n",
    "    encoded_predictions_task6.append(gen[0])\n",
    "    labels_encoded_predictions_task6.append(gen[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 19s 303ms/step\n",
      "64/64 [==============================] - 18s 287ms/step\n",
      "64/64 [==============================] - 18s 277ms/step\n",
      "64/64 [==============================] - 18s 276ms/step\n",
      "64/64 [==============================] - 19s 302ms/step\n",
      "64/64 [==============================] - 19s 297ms/step\n",
      "64/64 [==============================] - 22s 339ms/step\n",
      "64/64 [==============================] - 20s 313ms/step\n",
      "64/64 [==============================] - 17s 264ms/step\n",
      "64/64 [==============================] - 19s 302ms/step\n",
      "64/64 [==============================] - 23s 353ms/step\n",
      "64/64 [==============================] - 24s 371ms/step\n",
      "64/64 [==============================] - 19s 296ms/step\n",
      "64/64 [==============================] - 20s 319ms/step\n",
      "64/64 [==============================] - 17s 267ms/step\n",
      "64/64 [==============================] - 17s 264ms/step\n",
      "64/64 [==============================] - 20s 308ms/step\n",
      "64/64 [==============================] - 19s 300ms/step\n",
      "64/64 [==============================] - 19s 300ms/step\n",
      "64/64 [==============================] - 19s 297ms/step\n",
      "64/64 [==============================] - 19s 297ms/step\n",
      "64/64 [==============================] - 18s 289ms/step\n",
      "64/64 [==============================] - 18s 286ms/step\n",
      "64/64 [==============================] - 19s 292ms/step\n",
      "64/64 [==============================] - 18s 285ms/step\n",
      "64/64 [==============================] - 18s 285ms/step\n",
      "64/64 [==============================] - 18s 288ms/step\n",
      "64/64 [==============================] - 18s 283ms/step\n",
      "64/64 [==============================] - 18s 284ms/step\n",
      "64/64 [==============================] - 18s 286ms/step\n",
      "64/64 [==============================] - 18s 284ms/step\n",
      "64/64 [==============================] - 18s 284ms/step\n",
      "64/64 [==============================] - 18s 286ms/step\n"
     ]
    }
   ],
   "source": [
    "encoded_predictions_task6 = []\n",
    "labels_encoded_predictions_task6 = []\n",
    "\n",
    "#33 iterations\n",
    "for i in range(len(paths_to_all_images_task6)//batch_size):\n",
    "    gen = next(gen_task6)\n",
    "    encoded_predictions_task6.append(gen[0])\n",
    "    labels_encoded_predictions_task6.append(gen[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "\n",
    "Now you will train a classifier from scratch to discriminate the 22 classes based on the deep features you extracted in Task6. You will:\n",
    "- Train a classifier with the following architecture\n",
    "> 1D conv 3x1 -> 1D conv 3x1 -> FC 256 -> FC 22\n",
    "- Construct a multiclass confusion matrix and visualize it as a heatmap\n",
    "- Compare this confusion matrix with the one made in Task5\n",
    "\n",
    "*The input to this model will be the deep feature tensor obtained in Task6, so use appropriate input shape*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  1554\n",
      "Validation samples:  173\n",
      "Testing samples:  432\n",
      "Testing samples:  2159\n"
     ]
    }
   ],
   "source": [
    "x_train_task7 = input_train_for_generator\n",
    "x_val_task7 = input_val_for_generator \n",
    "x_test_task7 = input_test_for_generator \n",
    "y_train_task7 = label_train_for_generator\n",
    "y_val_task7 = label_val_for_generator \n",
    "y_test_task7 = label_test_for_generator \n",
    "\n",
    "print (\"Training samples: \", len(x_train_task7))\n",
    "print (\"Validation samples: \", len(x_val_task7))\n",
    "print (\"Testing samples: \", len(x_test_task7))\n",
    "print (\"Testing samples: \", len(y_test_task7) + len(y_val_task7) + len(y_train_task7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_im (InputLayer)        (None, 64, 20)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 64, 100)           2100      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 64, 100)           10100     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1638656   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 22)                5654      \n",
      "=================================================================\n",
      "Total params: 1,656,510\n",
      "Trainable params: 1,656,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (64,20)\n",
    "#  --> input shape is chosen as 64,20 \n",
    "#  --> 20 is the number of channels (features) which will remain the same at the input layer\n",
    "#  --> we get 60 by multiplying the rows and columns (8*8 = 64). This we we are able to use all\n",
    "#  the data from image and we also get a 2D tensor, which is needed in order to run a 1D conv\n",
    "\n",
    "\n",
    "input_im = Input(shape=(input_shape), name='input_im')\n",
    "conv1 = Conv1D(100,1)(input_im)\n",
    "conv2 = Conv1D(100,1)(conv1)\n",
    "flat = Flatten()(conv2)\n",
    "dense1 = Dense(256, activation='relu')(flat)\n",
    "output_class = Dense(22, activation='softmax')(dense1)\n",
    "\n",
    "decoder_model = Model(inputs=input_im, outputs=output_class)\n",
    "\n",
    "decoder_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=0.0001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_task7 = encoder_generator(x_train_task7, y_train_task7)\n",
    "val_gen_task7 = encoder_generator(x_val_task7, y_val_task7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 475s 20s/step - loss: 4.5610 - acc: 0.0495 - val_loss: 3.3190 - val_acc: 0.0781\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 428s 18s/step - loss: 3.1444 - acc: 0.0658 - val_loss: 3.0884 - val_acc: 0.1094\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 426s 18s/step - loss: 3.0219 - acc: 0.1152 - val_loss: 3.0029 - val_acc: 0.0625\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 431s 18s/step - loss: 2.9004 - acc: 0.1374 - val_loss: 2.9346 - val_acc: 0.0938\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 443s 18s/step - loss: 2.7841 - acc: 0.1888 - val_loss: 2.9108 - val_acc: 0.1250\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 578s 24s/step - loss: 2.7116 - acc: 0.2142 - val_loss: 2.8979 - val_acc: 0.1484\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 429s 18s/step - loss: 2.6443 - acc: 0.2298 - val_loss: 2.7660 - val_acc: 0.1641\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 432s 18s/step - loss: 2.5395 - acc: 0.2773 - val_loss: 2.7702 - val_acc: 0.1797\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 430s 18s/step - loss: 2.4840 - acc: 0.2806 - val_loss: 2.7978 - val_acc: 0.1406\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 437s 18s/step - loss: 2.3999 - acc: 0.3177 - val_loss: 2.6683 - val_acc: 0.1953\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 446s 19s/step - loss: 2.3138 - acc: 0.3620 - val_loss: 2.6552 - val_acc: 0.2031\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 444s 18s/step - loss: 2.2664 - acc: 0.3607 - val_loss: 2.6556 - val_acc: 0.2500\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 445s 19s/step - loss: 2.1957 - acc: 0.3848 - val_loss: 2.6767 - val_acc: 0.2734\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 430s 18s/step - loss: 2.1678 - acc: 0.3893 - val_loss: 2.6340 - val_acc: 0.2734\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 432s 18s/step - loss: 2.0901 - acc: 0.4460 - val_loss: 2.5997 - val_acc: 0.2812\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 445s 19s/step - loss: 2.0269 - acc: 0.4590 - val_loss: 2.5472 - val_acc: 0.3359\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 435s 18s/step - loss: 1.9575 - acc: 0.5039 - val_loss: 2.5436 - val_acc: 0.3438\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 434s 18s/step - loss: 1.9130 - acc: 0.4948 - val_loss: 2.5737 - val_acc: 0.2578\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 435s 18s/step - loss: 1.8586 - acc: 0.5306 - val_loss: 2.5933 - val_acc: 0.2500\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 446s 19s/step - loss: 1.8063 - acc: 0.5397 - val_loss: 2.5313 - val_acc: 0.3047\n"
     ]
    }
   ],
   "source": [
    "#training 3\n",
    "# 100 filters + lr = 0.0001\n",
    "model_name = 'decoder_task7_2'\n",
    "\n",
    "task7_train2 = decoder_model.fit_generator(train_gen_task7, epochs=30,\n",
    "                                          steps_per_epoch=len(y_train_task7)//batch_size,\n",
    "                                          validation_data=val_gen_task7,\n",
    "                                          validation_steps=len(y_val_task7)//batch_size,\n",
    "                                          callbacks=callbacks, verbose=1)\n",
    "\n",
    "decoder_model.save(model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ = load_model(('decoder_task7_2.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_task7 = encoder_generator(x_train_task7, y_train_task7, batch_size)\n",
    "val_gen_task7 = encoder_generator(x_val_task7, y_val_task7, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further training, 10 more epochs\n",
    "epoch_ = 10\n",
    "for i in range(epoch_):\n",
    "    for i in range(len(y_train_task7)//batch_size):\n",
    "        x,y = next(train_gen_task7)\n",
    "        decoder_.train_on_batch(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "64/64 [==============================] - 0s 6ms/step\n",
      "1\n",
      "64/64 [==============================] - 0s 396us/step\n",
      "2\n",
      "64/64 [==============================] - 0s 303us/step\n",
      "3\n",
      "64/64 [==============================] - 0s 254us/step\n",
      "4\n",
      "64/64 [==============================] - 0s 267us/step\n",
      "5\n",
      "64/64 [==============================] - 0s 254us/step\n"
     ]
    }
   ],
   "source": [
    "test_gen_task7 = encoder_generator(x_test_task7, y_test_task7)\n",
    "\n",
    "predictions_task7 = []\n",
    "actual_values_task7 = []\n",
    "\n",
    "#6 iterations\n",
    "for i in range(len(x_test_task7)//batch_size):\n",
    "    x, y = next(test_gen_task7)\n",
    "    print(i)\n",
    "    pred = decoder_.predict(x ,verbose = 1)\n",
    "    actual_values_task7.append(y)\n",
    "    predictions_task7.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_total_task7 = []\n",
    "labels_total_task7 = []\n",
    "\n",
    "for epoch in predictions_task7:\n",
    "    for val in epoch:\n",
    "        preds_total_task7.append(val)\n",
    "        \n",
    "for epoch in actual_values_task7:\n",
    "    for val in epoch:\n",
    "        labels_total_task7.append(val)        \n",
    "\n",
    "preds_total_task7 = np.array(preds_total_task7)\n",
    "labels_total_task7 = np.array(labels_total_task7)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  1,  0,  0,  0,  0,  0,  0,  2,  0,  2,  0,  0,  0,  0,\n",
       "         0,  2,  0,  0,  0,  0],\n",
       "       [ 0,  5,  0,  0,  0,  1,  0,  0,  2,  1,  0,  0,  0,  3,  2,  2,\n",
       "         0,  0,  0,  0,  0,  3],\n",
       "       [ 3,  0,  6,  0,  1,  0,  0,  0,  0,  1,  1,  0,  0,  0,  0,  1,\n",
       "         0,  2,  0,  2,  0,  0],\n",
       "       [ 0,  0,  0,  2,  0,  0,  0,  0,  1,  4,  2,  3,  0,  0,  0,  0,\n",
       "         1,  0,  0,  2,  0,  3],\n",
       "       [ 0,  0,  1,  0,  9,  0,  1,  0,  0,  3,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  1,  2,  1],\n",
       "       [ 0,  0,  1,  0,  0,  6,  1,  0,  5,  2,  0,  0,  0,  1,  0,  1,\n",
       "         0,  0,  0,  0,  0,  1],\n",
       "       [ 4,  0,  1,  0,  0,  0,  3,  0,  0,  2,  0,  0,  0,  2,  1,  1,\n",
       "         0,  3,  0,  2,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  5,  0,  4,  1,  1,  0,  1,  0,  1,\n",
       "         1,  1,  0,  3,  0,  2],\n",
       "       [ 0,  0,  1,  0,  0,  0,  1,  0, 12,  1,  0,  0,  0,  0,  0,  3,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0,  0,  0,  9,  0,  0,  0,  1,  0,  1,\n",
       "         1,  0,  0,  1,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 17,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  2,  0,  0,  0,  2,  0,  1,  4,  1,  5,  0,  0,  1,  1,\n",
       "         1,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  1,  1,  0,  0,  0,  0,  1,  2,  0,  2,  5,  0,  0,  0,\n",
       "         1,  2,  0,  1,  0,  1],\n",
       "       [ 0,  0,  2,  0,  0,  0,  0,  0,  0,  1,  0,  1,  0,  8,  0,  1,\n",
       "         0,  1,  0,  1,  0,  2],\n",
       "       [ 0,  0,  1,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  1,  4,  2,\n",
       "         0,  0,  1,  1,  0,  2],\n",
       "       [ 1,  0,  0,  0,  1,  1,  0,  0,  5,  1,  2,  0,  1,  0,  0,  1,\n",
       "         1,  0,  0,  0,  0,  3],\n",
       "       [ 1,  0,  1,  0,  0,  0,  0,  0,  0,  3,  2,  2,  0,  1,  0,  0,\n",
       "         3,  0,  0,  2,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,\n",
       "         0, 10,  0,  0,  0,  1],\n",
       "       [ 0,  0,  1,  1,  0,  0,  0,  0,  3,  0,  7,  0,  0,  0,  0,  1,\n",
       "         0,  0,  5,  0,  0,  2],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  0,  0,  2,  0,  0,\n",
       "         0,  0,  0, 14,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  2,  6,  0,  0,  0,  0,  0,  0,\n",
       "         0,  2,  0,  0,  4,  5],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  0,  1,  2,  1,  0,  2,  0,  0,  0,\n",
       "         0,  2,  0,  0,  0, 10]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_task7 = confusion_matrix(labels_total_task7.argmax(axis=1), preds_total_task7.argmax(axis=1))\n",
    "cm_task7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a422be550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2160 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(cm_task7, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This model is less accurate as compared to the one in task5. The one in task 5 had much higher values on the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "\n",
    "Now you will explore another use of the deep features extracted in Task6. Content Based Image Retrieval (CBIR) is the task of searching for visually similar images from a dataset. *Think Google image search.* This concept can obviously be applied on other forms of data like text, audio or video as well. In this task you will:\n",
    "- Implement a function which will take three inputs and returns a list of visually similar images. The inputs would be\n",
    "> An image from the dataset `im` <br />\n",
    "The number of search results to return `n` (no more than 5) <br />\n",
    "A string representing the distance metric used for comparisons `dist`\n",
    "- Visualize search result images, by looking for the appropriate image\n",
    "- Use some images to compare the effects of these distance metrics on the output\n",
    "> Euclidean <br />\n",
    "Cosine <br />\n",
    "Mahalanobis\n",
    "\n",
    "*Make sure the query image is the first search result for your function*\n",
    "\n",
    "*Look up the documentation for Scipy's `spatial.distance` module. It is your best friend in this task.*\n",
    "\n",
    "*If you made a generator in Task6, you can very easily use it in this task as well*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2159"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_to_all_images_task8 = paths_to_all_images_task6\n",
    "labels_to_all_images_task8 = labels_to_all_images_task6\n",
    "len(labels_to_all_images_task8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_generator_part8(path_all_images, class_labels, batch_size = 64):\n",
    "    total_pictures = len(path_all_images)\n",
    "    \n",
    "    indexes = np.arange(0,total_pictures,batch_size) #setting start index of each batch\n",
    "    \n",
    "    if total_pictures % batch_size != 0:\n",
    "        indexes = indexes[:-1]  #dropping last index if last batch does not complete the batch size requirement\n",
    "\n",
    "    while True:\n",
    "        np.random.shuffle(indexes) #shuffles indexes so order of data given to model in each epoch is different\n",
    "        for index in indexes:\n",
    "            path = path_all_images[index : index + batch_size]\n",
    "            labels = class_labels[index : index + batch_size]\n",
    "            \n",
    "            x_array = np.zeros((batch_size,256,256,3))\n",
    "            batch_labels = to_categorical(labels, num_classes = 22)\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                img = cv2.imread(path[i])\n",
    "                x_array[i] = cv2.resize(img,(256,256))\n",
    "                \n",
    "            resized_images = x_array  \n",
    "            labels = np.array(batch_labels)\n",
    "            \n",
    "            encoded_output = encoder_pretained.predict(resized_images,verbose=0)\n",
    "            encoded_output_reshaped = np.reshape(encoded_output, (encoded_output.shape[0],\n",
    "                                                                 encoded_output.shape[1]*encoded_output.shape[2],\n",
    "                                                                 encoded_output.shape[3]))\n",
    "        \n",
    "            yield encoded_output_reshaped, path\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbir(im, n, dist='Euclidean'):\n",
    "    #get all images encoded versions\n",
    "    #encode im\n",
    "    #compute distance of all points\n",
    "    #compare mean\n",
    "\n",
    "    real_image_paths = []\n",
    "    dist_each_point = []\n",
    "    mean_distance_from_each_image = []\n",
    "    sorted_indexes = []\n",
    "    \n",
    "    im_encoded = encoder_pretained.predict(im, verbose = 0)\n",
    "    im_encoded = np.reshape(im_encoded, (im_encoded.shape[1]*im_encoded.shape[2],\n",
    "                                        im_encoded.shape[3]))\n",
    "\n",
    "    \n",
    "    gen_task8 = encoder_generator_part8(paths_to_all_images_task8, labels_to_all_images_task8, 64)\n",
    "    \n",
    "    for i in range(len(paths_to_all_images_task8)//batch_size):\n",
    "        encoded_image, real_image_path = next(gen_task8)\n",
    "        for i in range(len(encoded_image)):\n",
    "            if dist == 'Euclidean':\n",
    "                dist =  cdist(im_encoded, encoded_image[i], 'euclidean')\n",
    "            elif dist == 'Cosine':\n",
    "                dist =  cdist(im_encoded, encoded_image[i], 'cosine')\n",
    "            elif dist == 'Mahalanobis':\n",
    "                dist =  cdist(im_encoded, encoded_image[i], 'mahalanobis', VI=None)   \n",
    "            dist_each_point.append(dist)\n",
    "            real_image_paths.append(real_image_path[i])\n",
    "    \n",
    "    dist_each_point = np.array(dist_each_point) #shape = (batchsize,64,64)\n",
    "    \n",
    "    for dist in dist_each_point:\n",
    "        mean = np.mean(dist)\n",
    "        mean_distance_from_each_image.append(mean)\n",
    "        \n",
    "    mean_distance_from_each_image = np.array(mean_distance_from_each_image) #shape = (batchsize,)\n",
    "    \n",
    "    if dist == 'Euclidean':\n",
    "        sorted_indexes = np.argsort(mean_distance_from_each_image)\n",
    "    elif dist == 'Cosine':\n",
    "        sorted_indexes = np.argsort(-mean_distance_from_each_image)\n",
    "    elif dist == 'Mahalanobis':\n",
    "        sorted_indexes = np.argsort(mean_distance_from_each_image)\n",
    "    \n",
    "    #print im \n",
    "#     im = np.reshape(im, (256,256,3))\n",
    "#     im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "#     plt.title(\"Query Image\")\n",
    "#     plt.imshow(im)\n",
    "#     plt.show()\n",
    "    \n",
    "    #print closest n-images\n",
    "    for i in range(n):\n",
    "        paths = real_image_paths[sorted_indexes[i]]\n",
    "        img = plt.imread(paths)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(paths_to_all_images_task8[1])\n",
    "im = np.reshape(im, (1,256,256,3))\n",
    "                \n",
    "cbir(im, 5,'Cosine')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
